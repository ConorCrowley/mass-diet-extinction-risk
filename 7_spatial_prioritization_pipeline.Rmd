

---
title: "7_spatial_prioritization_pipeline"
output: html_document
---

```{r eval=FALSE, include=FALSE}
# =============================================================================
# spatial_prioritization_pipeline (initializer for NEW codebase)
#
# Inputs produced upstream:
#   - Data/Clean/species_table.csv                 (from Untitled4)
#   - Data/Clean/Patches/<scientificName>.tif      (from Untitled5)
#   - Data/Clean/all_patch_lookup.rds              (from Untitled5)
#   - Data/Clean/all_connectivity.rds              (from Untitled5)
#
# Outputs created here (initializer outputs only):
#   - Spatial/patch_stack.tif
#   - Spatial/global_orchestrator_init.rds
#
# Downstream pipeline (prune/frag/distance/orchestrator) remains unchanged.
# =============================================================================

library(data.table)
library(terra)

# ---------------------------
# User switches (taxon gating)
# ---------------------------
INCLUDE_MAMMALS <- TRUE
INCLUDE_BIRDS   <- FALSE

stopifnot(is.logical(INCLUDE_MAMMALS), length(INCLUDE_MAMMALS) == 1L)
stopifnot(is.logical(INCLUDE_BIRDS),   length(INCLUDE_BIRDS)   == 1L)
if (!INCLUDE_MAMMALS && !INCLUDE_BIRDS) stop("Both INCLUDE_MAMMALS and INCLUDE_BIRDS are FALSE.")

# ---------------------------------------
# Model/parameter switch: Gompertz curve
# ---------------------------------------
GOMPERTZ_CURVE <- "q50"  # must match columns alpha_<curve>, beta_<curve>
STOP_IF_MISSING_GOMPERTZ <- TRUE

# ---------------------------------------
# IO paths
# ---------------------------------------
paths <- list(
  species_csv  = file.path("Data", "Clean", "species_table.csv"),
  patch_dir    = file.path("Data", "Clean", "Patches"),
  patch_lookup = file.path("Data", "Clean", "all_patch_lookup.rds"),
  connectivity = file.path("Data", "Clean", "all_connectivity.rds"),
  spatial_dir  = "Spatial"
)

dir.create(paths$spatial_dir, showWarnings = FALSE, recursive = TRUE)

# ---------------------------
# Helpers
# ---------------------------
species_id_from_scientific <- function(sci) {
  x <- stringr::str_squish(as.character(sci))
  x <- stringr::str_replace_all(x, "\\s+", "_")
  x <- stringr::str_replace_all(x, "[/\\\\:<>\"|?*]+", "_")
  x <- stringr::str_replace_all(x, "[^A-Za-z0-9_]+", "_")
  x <- stringr::str_replace_all(x, "_+", "_")
  x <- stringr::str_replace_all(x, "^_|_$", "")
  x
}

# Connectivity names are "<scientificName>|<pu_id>" in the new codebase
rename_key_to_species_id <- function(key) {
  parts <- strsplit(key, "\\|", fixed = FALSE)[[1]]
  sci   <- parts[1L]
  pu    <- parts[2L]
  paste0(species_id_from_scientific(sci), "|", pu)
}

# =============================================================================
# 1) Load species_table and build params (NO target list filtering)
# =============================================================================
if (!file.exists(paths$species_csv)) stop("Missing: ", paths$species_csv)

sp0 <- data.table::fread(paths$species_csv)

# Required columns from Untitled4 output (minimal for prioritization pipeline)
alpha_col <- paste0("alpha_", GOMPERTZ_CURVE)
beta_col  <- paste0("beta_",  GOMPERTZ_CURVE)

need_cols <- c(
  "scientificName", "className",
  "density", "dispersal_dist",
  "min_patch_size", "min_pop_size",
  alpha_col, beta_col
)

missing_cols <- setdiff(need_cols, names(sp0))
if (length(missing_cols)) {
  stop("species_table.csv is missing required column(s): ",
       paste(missing_cols, collapse = ", "))
}

sp0[, class_lc := tolower(trimws(as.character(className)))]
keep_tax <- (INCLUDE_MAMMALS & sp0$class_lc == "mammalia") | (INCLUDE_BIRDS & sp0$class_lc == "aves")
sp <- sp0[keep_tax]

if (!nrow(sp)) {
  stop("No rows remain after INCLUDE_MAMMALS/INCLUDE_BIRDS filtering.")
}

sp[, species := species_id_from_scientific(scientificName)]

# Build params table in the schema expected downstream
params <- sp[, .(
  species           = as.character(species),
  min_patch_size    = as.numeric(min_patch_size),
  min_patch_size500 = as.numeric(min_pop_size),      # NEW mapping
  a_pred            = as.numeric(get(alpha_col)),    # NEW mapping
  b_pred            = as.numeric(get(beta_col)),     # NEW mapping
  density           = as.numeric(density),
  dispersal_dist    = as.numeric(dispersal_dist)
)]

# Fail-fast sanitation
if (any(!nzchar(params$species))) stop("Empty species IDs after sanitization.")
if (anyDuplicated(params$species)) stop("Duplicate species IDs after sanitization.")

# Gompertz availability guard
bad_gomp <- which(!is.finite(params$a_pred) | !is.finite(params$b_pred) | params$a_pred <= 0 | params$b_pred <= 0)
if (length(bad_gomp)) {
  msg <- paste0(
    "Non-finite or non-positive Gompertz parameters in params for ",
    length(bad_gomp), " species (curve=", GOMPERTZ_CURVE, ")."
  )
  if (STOP_IF_MISSING_GOMPERTZ) stop(msg) else warning(msg)
  if (!STOP_IF_MISSING_GOMPERTZ) params <- params[-bad_gomp]
}

data.table::setkey(params, species)

# =============================================================================
# 2) Patch rasters -> patch_stack
# =============================================================================
patch_files <- file.path(paths$patch_dir, paste0(params$species, ".tif"))

missing_pf <- patch_files[!file.exists(patch_files)]
if (length(missing_pf)) {
  stop("Missing patch raster(s) for selected species. Examples: ",
       paste(utils::head(basename(missing_pf), 10), collapse = ", "))
}

# Load as per-layer rasters (sets names per layer without global renaming)
layers <- lapply(seq_along(patch_files), function(i) {
  r <- terra::rast(patch_files[i])
  names(r) <- params$species[i]
  r
})
patch_stack <- terra::rast(layers)

template_rast <- patch_stack[[1]]

# Per-cell area (km^2), aligned to raster cell order
cs_vals <- as.numeric(terra::values(terra::cellSize(template_rast, unit = "km"), mat = TRUE)[, 1])

# Rook adjacency pairs over the full grid
rook_pairs_all <- terra::adjacent(
  template_rast,
  cells      = seq_len(terra::ncell(template_rast)),
  directions = 4,
  pairs      = TRUE
)

# =============================================================================
# 3) Patch lookup -> patch_dt
# =============================================================================
if (!file.exists(paths$patch_lookup)) stop("Missing: ", paths$patch_lookup)

patch_lookup_raw <- readRDS(paths$patch_lookup)
patch_dt <- data.table::as.data.table(patch_lookup_raw)

need_patch_cols <- c("scientificName", "patch_id", "pu_id", "patch_area_km2")
missing_patch_cols <- setdiff(need_patch_cols, names(patch_dt))
if (length(missing_patch_cols)) {
  stop("all_patch_lookup.rds is missing required column(s): ",
       paste(missing_patch_cols, collapse = ", "))
}

patch_dt[, species := species_id_from_scientific(scientificName)]
patch_dt <- patch_dt[
  species %in% params$species,
  .(
    species        = as.character(species),
    patch_id       = as.integer(patch_id),
    pu_id          = as.integer(pu_id),
    patch_area_km2 = as.numeric(patch_area_km2)
  )
]

data.table::setkey(patch_dt, species, patch_id)

if (!nrow(patch_dt)) stop("patch_dt is empty after filtering to selected species.")

# =============================================================================
# 4) Connectivity -> state_env (CSR conversion for downstream expectations)
# =============================================================================
# ============================================================
# CSR symmetrizer (enforce undirected adjacency)
# Assumes:
#   row_ptr: 0-based offsets, length N+1
#   col_idx: 1-based node indices in 1..N
# Returns:
#   list(row_ptr = ..., col_idx = ...) with:
#     - no self loops
#     - sorted, unique neighbors per row
#     - symmetric adjacency
# ============================================================

csr_symmetrize_undirected <- function(row_ptr, col_idx) {
  row_ptr <- as.integer(row_ptr)
  col_idx <- as.integer(col_idx)

  N <- length(row_ptr) - 1L
  if (N <= 0L) stop("CSR has no rows (N<=0).", call. = FALSE)

  deg <- as.integer(diff(row_ptr))
  if (sum(deg) != length(col_idx)) {
    stop("CSR malformed: sum(diff(row_ptr)) != length(col_idx).", call. = FALSE)
  }

  # Build directed edge list (u -> v) from CSR
  from <- rep.int(seq_len(N), deg)
  to   <- col_idx

  # Drop invalid + self loops defensively
  ok <- is.finite(to) & to >= 1L & to <= N & (from != to)
  from <- from[ok]
  to   <- to[ok]

  # Add reverse edges to enforce symmetry
  from2 <- c(from, to)
  to2   <- c(to, from)

  # Deduplicate directed edges using integer key
  key <- from2 + (to2 - 1L) * N
  o   <- order(key)
  key <- key[o]
  from2 <- from2[o]
  to2   <- to2[o]

  keep <- !duplicated(key)
  from2 <- from2[keep]
  to2   <- to2[keep]

  # Build adjacency list per row
  adj <- split(to2, from2)

  adj_full <- vector("list", N)
  lens     <- integer(N)

  for (u in seq_len(N)) {
    v <- adj[[as.character(u)]]
    if (is.null(v)) {
      adj_full[[u]] <- integer(0)
      lens[u] <- 0L
    } else {
      v <- sort(unique(as.integer(v)))
      adj_full[[u]] <- v
      lens[u] <- length(v)
    }
  }

  row_ptr_new <- as.integer(c(0L, cumsum(lens)))
  col_idx_new <- as.integer(unlist(adj_full, use.names = FALSE))

  list(row_ptr = row_ptr_new, col_idx = col_idx_new)
}

if (!file.exists(paths$connectivity)) stop("Missing: ", paths$connectivity)

conn_all <- readRDS(paths$connectivity)
if (!is.list(conn_all) || !length(conn_all)) stop("all_connectivity.rds is empty or not a list.")

# Optional but recommended: enforce expected CSR attributes
csr_v <- attr(conn_all, "csr_version", exact = TRUE)
col_base <- attr(conn_all, "col_idx_base", exact = TRUE)
col_space <- attr(conn_all, "col_idx_space", exact = TRUE)

if (!is.null(csr_v) && csr_v != 2L) stop("Unexpected csr_version: ", csr_v)
if (!is.null(col_base) && col_base != "0-based") stop("Unexpected col_idx_base: ", col_base)
if (!is.null(col_space) && col_space != "pu_local_index") stop("Unexpected col_idx_space: ", col_space)

old_names <- names(conn_all)
new_names <- vapply(old_names, rename_key_to_species_id, character(1L))

state_env <- vector("list", length(conn_all))
names(state_env) <- new_names

for (i in seq_along(conn_all)) {
  e <- conn_all[[i]]

  spid <- species_id_from_scientific(e$species)

  # Convert CSR to expected format (R indices)
  id2patch <- as.integer(e$patch_ids)
  col_idx  <- as.integer(e$col_idx) + 1L
  row_ptr  <- as.integer(e$row_ptr)
  
  # Enforce undirected symmetry (fixes the diagnostic failure)
  sym <- csr_symmetrize_undirected(row_ptr = row_ptr, col_idx = col_idx)
  row_ptr <- sym$row_ptr
  col_idx <- sym$col_idx
  
  state_env[[i]] <- list(
    species  = spid,
    pu_id    = as.integer(e$pu_id),
    id2patch = id2patch,
    row_ptr  = row_ptr,
    col_idx  = col_idx
  )
}

# Keep only state_env entries for species we are actually running
sp_in_state <- sub("\\|.*$", "", names(state_env))
state_env <- state_env[sp_in_state %in% params$species]

if (!length(state_env)) stop("state_env is empty after filtering to selected species.")

# =============================================================================
# 5) Initial alive-species count per cell
# =============================================================================
patch_vals_all <- terra::values(patch_stack, mat = TRUE)
count_alive <- rowSums(!is.na(patch_vals_all))

rm(patch_vals_all)
gc(verbose = FALSE)

# =============================================================================
# 6) Save initializer outputs
# =============================================================================
patch_stack_file <- file.path(paths$spatial_dir, "patch_stack.tif")
terra::writeRaster(patch_stack, filename = patch_stack_file, overwrite = TRUE)

orchestrator_init <- list(
  params           = params,
  patch_dt         = patch_dt,
  state_env        = state_env,
  cs_vals          = cs_vals,
  rook_pairs_all   = rook_pairs_all,
  count_alive      = count_alive,
  patch_stack_file = patch_stack_file,
  meta             = list(
    include_mammals = INCLUDE_MAMMALS,
    include_birds   = INCLUDE_BIRDS,
    gompertz_curve  = GOMPERTZ_CURVE,
    species_csv     = paths$species_csv
  )
)

# Stamp build info so you can tell if you’re reading a stale file
orchestrator_init$meta$build_time <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
orchestrator_init$meta$connectivity_mtime <- as.character(file.info(paths$connectivity)$mtime)

# Hard-stop if any CSR entry is asymmetric
check_csr_symmetric <- function(row_ptr, col_idx) {
  N <- length(row_ptr) - 1L
  for (u in seq_len(N)) {
    s <- row_ptr[u] + 1L
    e <- row_ptr[u + 1L]
    if (e < s) next
    nb <- col_idx[s:e]
    for (v in nb) {
      s2 <- row_ptr[v] + 1L
      e2 <- row_ptr[v + 1L]
      if (e2 < s2) return(FALSE)
      nb2 <- col_idx[s2:e2]
      if (!(u %in% nb2)) return(FALSE)
    }
  }
  TRUE
}

bad_keys <- character()
for (k in names(state_env)) {
  ok <- check_csr_symmetric(state_env[[k]]$row_ptr, state_env[[k]]$col_idx)
  if (!ok) bad_keys <- c(bad_keys, k)
}
if (length(bad_keys)) stop("Initializer produced asymmetric CSR for: ",
                           paste(head(bad_keys, 10), collapse=", "),
                           call. = FALSE)

saveRDS(orchestrator_init, file = file.path(paths$spatial_dir, "global_orchestrator_init.rds"))

message("Initializer complete: wrote Spatial/patch_stack.tif and Spatial/global_orchestrator_init.rds")
```

# Shared static setup (used by both runs)

```{r}
library(fasterRaster)  
faster(grassDir = "C:/Program Files/GRASS GIS 8.4")
```

```{r}
library(data.table)
library(terra)
library(sf)

# Optional: logging helper
.log_console <- function(tag, fmt, ...) {
  ts  <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
  msg <- if (length(list(...))) sprintf(fmt, ...) else fmt
  cat(sprintf("[%s] [%s] %s\n", ts, tag, msg), sep = "")
}

# Use great-circle distances for sf::st_distance()
sf::sf_use_s2(TRUE)

# ------------------------------------------------------------
# Load shared, static parameters used by BOTH orchestrator runs
# ------------------------------------------------------------
orchestrator_init <- readRDS(
  file.path("Spatial", "global_orchestrator_init.rds")
)

# Only keep the static/shared bits here
params         <- orchestrator_init$params
cs_vals        <- orchestrator_init$cs_vals
rook_pairs_all <- orchestrator_init$rook_pairs_all

rm(orchestrator_init)
gc(verbose = FALSE)
```

```{r}
## ---- hotfix_strip_patch_area_from_state_env ---------------------------------
## TEMP HOTFIX (no rerun): remove legacy `patch_area` stored inside state_env CSR entries
## Writes a patched copy in-place (with timestamped backup).

strip_patch_area_state_env <- function(state_env_obj) {
  stopifnot(is.list(state_env_obj))
  n_before <- sum(vapply(state_env_obj, function(o) !is.null(o$patch_area), logical(1)))
  if (n_before == 0L) return(list(state_env = state_env_obj, n_stripped = 0L))

  state_env_obj <- lapply(state_env_obj, function(o) {
    o$patch_area <- NULL
    o
  })
  list(state_env = state_env_obj, n_stripped = as.integer(n_before))
}

hotfix_strip_patch_area_in_init <- function(init_path = file.path("Spatial", "global_orchestrator_init.rds"),
                                            make_backup = TRUE) {
  if (!file.exists(init_path)) stop("Missing initializer RDS: ", init_path, call. = FALSE)

  init <- readRDS(init_path)

  if (is.null(init$state_env) || !is.list(init$state_env) || !length(init$state_env)) {
    stop("Initializer has no usable $state_env list at: ", init_path, call. = FALSE)
  }
  if (is.null(init$patch_dt) || !data.table::is.data.table(init$patch_dt)) {
    # allow plain data.frame too
    if (!is.data.frame(init$patch_dt)) stop("Initializer has no usable $patch_dt at: ", init_path, call. = FALSE)
  }
  if (!("patch_area_km2" %in% names(init$patch_dt))) {
    stop("Initializer $patch_dt is missing patch_area_km2 (required if patch_area is removed from state_env).",
         call. = FALSE)
  }

  out <- strip_patch_area_state_env(init$state_env)

  if (out$n_stripped == 0L) {
    .log_console("HOTFIX", "No $patch_area found in state_env inside %s (nothing to patch).", init_path)
    return(invisible(list(n_stripped = 0L, backup = NA_character_)))
  }

  backup_path <- NA_character_
  if (isTRUE(make_backup)) {
    ts <- format(Sys.time(), "%Y%m%d_%H%M%S")
    backup_path <- paste0(init_path, ".bak_", ts)
    ok <- file.copy(init_path, backup_path, overwrite = FALSE)
    if (!isTRUE(ok)) stop("Failed to create backup at: ", backup_path, call. = FALSE)
  }

  init$state_env <- out$state_env

  # Stamp meta so you can tell you’re on the patched file
  if (is.null(init$meta) || !is.list(init$meta)) init$meta <- list()
  init$meta$hotfix_strip_patch_area_time  <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
  init$meta$hotfix_strip_patch_area_nkeys <- out$n_stripped
  if (isTRUE(make_backup)) init$meta$hotfix_backup_file <- basename(backup_path)

  saveRDS(init, init_path)

  .log_console("HOTFIX",
               "Stripped $patch_area from %d state_env entries and overwrote %s%s",
               out$n_stripped, init_path,
               if (isTRUE(make_backup)) paste0(" | backup=", backup_path) else "")

  invisible(list(n_stripped = out$n_stripped, backup = backup_path))
}

# Run the patch once per session (idempotent if already clean)
hotfix_strip_patch_area_in_init()
rm(strip_patch_area_state_env, hotfix_strip_patch_area_in_init)
gc(verbose = FALSE)
```

# DIAGNOSTIC CHUNK A (run AFTER "Shared static setup")

```{r eval=FALSE, include=FALSE}
# ============================================================
# DIAGNOSTIC CHUNK A (run AFTER "Shared static setup")
# Purpose:
#   - Reload Spatial/global_orchestrator_init.rds (fresh),
#   - Validate structure/invariants of:
#       params, patch_dt, state_env, patch_stack_file, cs_vals, rook_pairs_all,
#   - Verify CSR format expected by downstream code:
#       row_ptr is 0-based offsets, col_idx is 1-based node indices into id2patch.
# ============================================================

diag_assert <- function(ok, msg) if (!isTRUE(ok)) stop(msg, call. = FALSE)

# ---- Required packages (these are used by your pipeline code paths)
pkgs_needed <- c("data.table", "terra", "sf", "fasterRaster", "fastmatch", "Rfast")
pkgs_missing <- pkgs_needed[!vapply(pkgs_needed, requireNamespace, logical(1), quietly = TRUE)]
diag_assert(
  length(pkgs_missing) == 0,
  paste0(
    "Missing required package(s): ", paste(pkgs_missing, collapse = ", "), "\n",
    "Install them before running diagnostics.\n",
    "Note: prune_step_minimal depends on fastmatch + Rfast."
  )
)

suppressPackageStartupMessages({
  library(data.table)
  library(terra)
  library(sf)
})

sf::sf_use_s2(TRUE)

init_path <- file.path("Spatial", "global_orchestrator_init.rds")
diag_assert(file.exists(init_path), paste0("Missing initializer RDS: ", init_path))

md5_before <- as.character(tools::md5sum(init_path))
mtime_before <- file.info(init_path)$mtime

init <- readRDS(init_path)

md5_after <- as.character(tools::md5sum(init_path))
mtime_after <- file.info(init_path)$mtime

if (!identical(md5_before, md5_after) || !identical(mtime_before, mtime_after)) {
  stop("global_orchestrator_init.rds changed while being read (concurrent writer).", call. = FALSE)
}

need_fields <- c(
  "params", "patch_dt", "state_env", "cs_vals", "rook_pairs_all", "count_alive", "patch_stack_file"
)
missing_fields <- setdiff(need_fields, names(init))
diag_assert(
  length(missing_fields) == 0,
  paste0("global_orchestrator_init.rds missing field(s): ", paste(missing_fields, collapse = ", "))
)

# ---- Load patch_stack from file (do not assume it's already in env)
ps_file <- init$patch_stack_file
diag_assert(is.character(ps_file) && length(ps_file) == 1L, "init$patch_stack_file must be a single character path.")
diag_assert(file.exists(ps_file), paste0("patch_stack_file does not exist: ", ps_file))

patch_stack0 <- terra::rast(ps_file)
diag_assert(terra::nlyr(patch_stack0) >= 1L, "patch_stack has zero layers.")
diag_assert(terra::ncell(patch_stack0) >= 1L, "patch_stack has zero cells.")

template0 <- patch_stack0[[1]]
ncell0    <- terra::ncell(template0)

# ---- Basic vector lengths
diag_assert(length(init$cs_vals) == ncell0, paste0("cs_vals length mismatch: got ", length(init$cs_vals), " expected ", ncell0))
diag_assert(is.matrix(init$rook_pairs_all) && ncol(init$rook_pairs_all) == 2L, "rook_pairs_all must be an integer matrix with 2 columns.")
diag_assert(nrow(init$rook_pairs_all) > 0L, "rook_pairs_all has zero rows.")
diag_assert(length(init$count_alive) == ncell0, paste0("count_alive length mismatch: got ", length(init$count_alive), " expected ", ncell0))

# ---- params checks
params0 <- data.table::as.data.table(init$params)
diag_assert(all(c("species","min_patch_size","min_patch_size500","a_pred","b_pred","density","dispersal_dist") %in% names(params0)),
            "params missing required columns (species, min_patch_size, min_patch_size500, a_pred, b_pred, density, dispersal_dist).")
diag_assert(!any(!nzchar(params0$species)), "params contains empty species IDs.")
diag_assert(anyDuplicated(params0$species) == 0L, "params has duplicate species IDs.")
data.table::setkey(params0, species)

# ---- patch_dt checks
patch_dt0 <- data.table::as.data.table(init$patch_dt)
diag_assert(all(c("species","patch_id","pu_id","patch_area_km2") %in% names(patch_dt0)),
            "patch_dt missing required columns (species, patch_id, pu_id, patch_area_km2).")
diag_assert(anyDuplicated(patch_dt0[, .(species, patch_id)]) == 0L, "patch_dt has duplicate (species, patch_id) rows.")
diag_assert(all(is.finite(patch_dt0$patch_area_km2)), "patch_dt has non-finite patch_area_km2.")
diag_assert(all(patch_dt0$patch_area_km2 >= -1e-10), "patch_dt has negative patch_area_km2 (beyond tolerance).")

# ---- patch_stack layer name alignment
layers0 <- names(patch_stack0)
diag_assert(all(nzchar(layers0)), "patch_stack has empty layer name(s).")

# Your initializer should have enforced this:
diag_assert(
  setequal(layers0, params0$species),
  paste0(
    "Mismatch between patch_stack layer names and params$species.\n",
    "layers not in params: ", paste(setdiff(layers0, params0$species), collapse = ", "), "\n",
    "params not in layers: ", paste(setdiff(params0$species, layers0), collapse = ", ")
  )
)

# ---- CSR / state_env checks
state_env0 <- init$state_env
diag_assert(is.list(state_env0) && length(state_env0) > 0L, "state_env is empty or not a list.")
diag_assert(!is.null(names(state_env0)) && all(nzchar(names(state_env0))), "state_env must be a *named* list with non-empty names.")

# Helper: extract neighbors for node u (1-based node index), CSR with:
#   row_ptr = 0-based offsets into col_idx
#   col_idx = 1-based node indices
.csr_neighbors <- function(row_ptr, col_idx, u) {
  s <- row_ptr[u] + 1L
  e <- row_ptr[u + 1L]
  if (e < s) return(integer(0L))
  as.integer(col_idx[s:e])
}

# Validate a single CSR entry (structural + consistency against patch_dt)
.check_one_state_env <- function(key, obj, patch_dt_ref) {
  parts <- strsplit(key, "\\|", fixed = FALSE)[[1]]
  diag_assert(length(parts) == 2L, paste0("Bad state_env key (expected 'species|pu'): ", key))
  sp <- parts[1L]
  pu <- suppressWarnings(as.integer(parts[2L]))
  diag_assert(nzchar(sp), paste0("Empty species in key: ", key))
  diag_assert(is.finite(pu), paste0("Non-integer/invalid pu in key: ", key))

  diag_assert(identical(obj$species, sp), paste0("Key/species mismatch for ", key, " | obj$species=", obj$species))
  diag_assert(as.integer(obj$pu_id) == pu, paste0("Key/pu_id mismatch for ", key, " | obj$pu_id=", obj$pu_id))

  id2patch <- as.integer(obj$id2patch)
  row_ptr  <- as.integer(obj$row_ptr)
  col_idx  <- as.integer(obj$col_idx)

  N <- length(id2patch)
  diag_assert(N >= 1L, paste0("CSR has zero nodes for ", key))
  diag_assert(length(row_ptr) == N + 1L, paste0("row_ptr length != N+1 for ", key))
  diag_assert(row_ptr[1L] == 0L, paste0("row_ptr[1] must be 0 (0-based) for ", key))
  diag_assert(all(diff(row_ptr) >= 0L), paste0("row_ptr must be non-decreasing for ", key))
  diag_assert(row_ptr[N + 1L] == length(col_idx), paste0("row_ptr[end] must equal length(col_idx) for ", key))

  if (length(col_idx)) {
    diag_assert(all(is.finite(col_idx)), paste0("col_idx contains non-finite values for ", key))
    diag_assert(min(col_idx) >= 1L, paste0("col_idx must be 1-based indices (min>=1) for ", key))
    diag_assert(max(col_idx) <= N,  paste0("col_idx out of range (>N) for ", key))
  }

  # Consistency with patch_dt: patches in PU should match id2patch
  pid_dt <- patch_dt_ref[species == sp & pu_id == pu, as.integer(patch_id)]
  diag_assert(length(pid_dt) > 0L, paste0("patch_dt has no rows for ", key, " (species+pu missing)"))
  diag_assert(
    setequal(id2patch, pid_dt),
    paste0(
      "id2patch != patch_dt patch list for ", key, "\n",
      "In CSR not in patch_dt: ", paste(setdiff(id2patch, pid_dt), collapse = ", "), "\n",
      "In patch_dt not in CSR: ", paste(setdiff(pid_dt, id2patch), collapse = ", ")
    )
  )

  # Light symmetry spot-check: for a few sampled nodes, ensure u->v implies v->u
  # (expected for undirected PU graphs).
  if (N >= 2L && length(col_idx) > 0L) {
    set.seed(1)
    u_samp <- sample.int(N, size = min(10L, N))
    for (u in u_samp) {
      nb <- .csr_neighbors(row_ptr, col_idx, u)
      if (!length(nb)) next
        v_samp <- nb[sample.int(length(nb), size = min(5L, length(nb)))]
      for (v in v_samp) {
        nb_v <- .csr_neighbors(row_ptr, col_idx, v)
        if (!(u %in% nb_v)) {
          cat("\n--- CSR ASYMMETRY DUMP ---\n")
          cat("key:", key, "\n")
          cat("N:", N, "\n")
          cat("u(row):", u, " v(row):", v, "\n")
          cat("row_ptr[u:u+1]:", row_ptr[u], row_ptr[u+1L], "\n")
          cat("row_ptr[v:v+1]:", row_ptr[v], row_ptr[v+1L], "\n")
          cat("nbr(u):", paste(nb, collapse = ", "), "\n")
          cat("nbr(v):", paste(nb_v, collapse = ", "), "\n")
        
          # Helpful: show what these rows correspond to in patch-id space
          cat("patch(u):", id2patch[u], " patch(v):", id2patch[v], "\n")
          cat("nbr(u) as patch IDs:", paste(id2patch[nb], collapse = ", "), "\n")
          cat("nbr(v) as patch IDs:", paste(id2patch[nb_v], collapse = ", "), "\n")
        
          # Quick semantic sniff: are col_idx values actually patch IDs?
          cat("col_idx_all_in_id2patch?:", all(col_idx %in% id2patch), "\n")
          cat("id2patch_is_identity_1..N?:", identical(id2patch, seq_len(N)), "\n")
        
          stop("CSR asymmetry detected (see dump above).", call. = FALSE)
        }
      }
    }
  }

  TRUE
}

# --- Safety: detect duplicate names up front (important on Windows/R where [[name]] grabs first match)
if (anyDuplicated(names(state_env0))) {
  dupn <- unique(names(state_env0)[duplicated(names(state_env0))])
  stop("state_env has duplicate names. Examples: ", paste(head(dupn, 10), collapse = ", "), call. = FALSE)
}

# Deterministic asymmetry finder (same CSR semantics as .csr_neighbors)
find_first_asymmetry <- function(row_ptr, col_idx) {
  N <- length(row_ptr) - 1L
  for (u in seq_len(N)) {
    nb_u <- .csr_neighbors(row_ptr, col_idx, u)
    if (!length(nb_u)) next
    for (v in nb_u) {
      nb_v <- .csr_neighbors(row_ptr, col_idx, v)
      if (!(u %in% nb_v)) return(c(u = u, v = v))
    }
  }
  NULL
}

# Sample *indices* so key/object can never mismatch
set.seed(1)
idx_samp <- sample.int(length(state_env0), size = min(50L, length(state_env0)))

for (idx in idx_samp) {
  k   <- names(state_env0)[idx]
  obj <- state_env0[[idx]]

  # run your existing structural checks first
  .check_one_state_env(k, obj, patch_dt0)

  # then run deterministic asymmetry check for this CSR (if it ever fails, print the proof)
  a <- find_first_asymmetry(as.integer(obj$row_ptr), as.integer(obj$col_idx))
  if (!is.null(a)) {
    u <- a["u"]; v <- a["v"]
    cat("\nASYMMETRY CONFIRMED IN:", k, "\n")
    cat("N =", length(obj$id2patch), "\n")
    cat("u node:", u, "patch_id:", obj$id2patch[u], "\n")
    cat("v node:", v, "patch_id:", obj$id2patch[v], "\n")
    cat("nbr(u):", paste(.csr_neighbors(obj$row_ptr, obj$col_idx, u), collapse = ", "), "\n")
    cat("nbr(v):", paste(.csr_neighbors(obj$row_ptr, obj$col_idx, v), collapse = ", "), "\n")
    stop("CSR asymmetry confirmed deterministically (see printout above).", call. = FALSE)
  }
}

# ---- Check a critical assumption for prune_step_minimal:
# .compute_log_val assumes pu_area_km2 > min_patch_size500 (strictly greater).
pu_area0 <- patch_dt0[, .(pu_area_km2 = sum(patch_area_km2, na.rm = TRUE)), by = .(species, pu_id)]
pu_chk0  <- params0[pu_area0, on = .(species)]
bad_delta <- pu_chk0[pu_area_km2 <= (min_patch_size500 + 1e-12)]

if (nrow(bad_delta) > 0L) {
  warning(
    paste0(
      "Found PU(s) with pu_area_km2 <= min_patch_size500 (or extremely close).\n",
      "This can break .compute_log_val because it takes log(A - c_th).\n",
      "Example rows:\n",
      paste(capture.output(print(head(bad_delta, 10))), collapse = "\n")
    )
  )
}

# ---- Quick sanity: count_alive range
max_possible <- terra::nlyr(patch_stack0)
diag_assert(all(init$count_alive >= 0L), "count_alive contains negative values.")
diag_assert(max(init$count_alive, na.rm = TRUE) <= max_possible, "count_alive exceeds #layers in patch_stack.")

cat(
  sprintf(
    "PRE-FLIGHT OK\n  layers=%d | cells=%d | PUs=%d | patches=%d | max_count_alive=%d\n",
    terra::nlyr(patch_stack0),
    terra::ncell(patch_stack0),
    length(state_env0),
    nrow(patch_dt0),
    max(init$count_alive, na.rm = TRUE)
  )
)

rm(init, patch_stack0, patch_dt0, params0, state_env0, template0, pu_area0, pu_chk0, bad_delta)
gc(verbose = FALSE)
```

# prune_step_minimal

```{r}
# ------------------------------------------------------------
# Connected components in a PU connectivity graph (CSR format)
# ------------------------------------------------------------
.compute_components <- function(row_ptr, col_idx, alive, patch_area) {
  # row_ptr, col_idx: CSR adjacency for one PU
  #   - nodes are patches
  #   - row_ptr[i]..row_ptr[i+1]-1 index into col_idx for neighbors of node i
  # alive: logical vector of length N indicating which nodes remain in the PU
  # patch_area: numeric vector of per-node areas (aligned with alive)

  N       <- length(alive)          # total number of nodes (patches) in this PU
  comp_id <- integer(N)             # component label for each node (0 = unlabeled)
  q       <- integer(N)             # preallocated BFS queue (max N entries)
  lab     <- 0L                     # current component label (we increment this)

  # We want to find connected components **only among alive nodes**.
  # This is needed so we can later:
  #   - compute each component's total area
  #   - decide which components survive the PU-area threshold.
  # We use a BFS over alive nodes for O(N + E) time, which is optimal for this graph task.

  # Iterate only over alive nodes; dead nodes are ignored entirely.
  for (u in which(alive)) {
    # If this node already has a component label, it was visited in a previous BFS.
    if (comp_id[u] != 0L) next

    # Start a new component: increment label and seed BFS at u.
    lab <- lab + 1L
    comp_id[u] <- lab

    # Initialize BFS queue with this node.
    qs <- 1L      # queue start index (head)
    qe <- 1L      # queue end index (tail)
    q[1L] <- u

    # Standard BFS: traverse along alive neighbors, labelling them with 'lab'.
    while (qs <= qe) {
      v <- q[qs]; qs <- qs + 1L

      # Neighbor slice for node v in CSR representation is:
      #   col_idx[row_ptr[v] + 1L .. row_ptr[v+1L]]
      s <- row_ptr[v] + 1L
      e <- row_ptr[v + 1L]

      # Only proceed if there is at least one neighbor.
      if (e >= s) {
        # Examine all neighbor indices for v
        for (idx in s:e) {
          w <- col_idx[idx]
          # Only traverse neighbors that are alive and not yet labeled:
          # this ensures we:
          #   - restrict components to alive nodes
          #   - avoid revisiting nodes, so BFS stays O(N + E).
          if (alive[w] && comp_id[w] == 0L) {
            comp_id[w] <- lab
            qe <- qe + 1L
            q[qe] <- w
          }
        }
      }
    }
  }

  # After BFS, comp_id[i] > 0 means node i is in some component.
  ok <- comp_id > 0L

  # We now need the **area per component**, because the PU update logic
  # uses component area to decide which components survive (>= thr) or are dropped.
  # rowsum() gives a fast vectorised group-sum over components.
  comp_area <- as.numeric(
    rowsum(patch_area[ok], comp_id[ok], reorder = FALSE)
  )

  # comp_id: component label per node
  # comp_area: total area per component label (index by component ID, 1..max label)
  list(comp_id = comp_id, comp_area = comp_area)
}

# ------------------------------------------------------------
# Rebuild a CSR graph restricted to a subset of nodes
# ------------------------------------------------------------
.rebuild_csr <- function(row_ptr, col_idx, keep_idx) {
  # We want the **induced subgraph** on the node subset keep_idx.
  # This is needed after dropping patches / components so that the
  # connectivity structure of each surviving component is still valid.
  #
  # This function:
  #   - remaps the original node indices to new compact indices 1..K
  #   - rebuilds CSR arrays (row_ptr, col_idx) for just those K nodes.

  N <- length(row_ptr) - 1L         # original number of nodes
  K <- length(keep_idx)             # number of nodes we keep in the subgraph

  # 'map' converts old node index -> new node index (0 = dropped)
  map           <- integer(N)
  map[keep_idx] <- seq_len(K)

  # New row_ptr will have K+1 entries (standard CSR convention).
  row_new <- integer(K + 1L)

  # ------------------------
  # First pass: count edges
  # ------------------------
  # We compute how many edges each kept node will have in the new graph.
  # This lets us compute row_new (cumulative counts), and then size col_new exactly.

  for (ii in seq_len(K)) {
    i <- keep_idx[ii]              # original node index
    s <- row_ptr[i] + 1L
    e <- row_ptr[i + 1L]

    if (e >= s) {
      neigh <- col_idx[s:e]        # neighbors in old indexing
      nn    <- map[neigh]          # map neighbors to new indexing
      nn    <- nn[nn > 0L]         # drop neighbors that were not kept
      # row_new[ii+1] = row_new[ii] + number of kept neighbors
      row_new[ii + 1L] <- row_new[ii] + length(nn)
    } else {
      # No neighbors for this node: just propagate the cumulative count.
      row_new[ii + 1L] <- row_new[ii]
    }
  }

  # Total number of edges in the new graph is row_new[K+1].
  col_new <- integer(row_new[K + 1L])

  # Write pointer into col_new
  wp      <- 1L

  # -------------------------
  # Second pass: fill edges
  # -------------------------
  # Now that we know the edge counts and row_new offsets, we can fill col_new.

  for (ii in seq_len(K)) {
    i <- keep_idx[ii]
    s <- row_ptr[i] + 1L
    e <- row_ptr[i + 1L]

    if (e >= s) {
      neigh <- col_idx[s:e]
      nn    <- map[neigh]
      nn    <- nn[nn > 0L]
      len   <- length(nn)
      if (len > 0L) {
        # Fill contiguous slice of col_new for node ii
        col_new[wp:(wp + len - 1L)] <- nn
        wp <- wp + len
      }
    }
  }

  # Return CSR arrays for the restricted graph
  list(row_ptr = row_new, col_idx = col_new)
}

# ------------------------------------------------------------
# Update components of a PU after some patches die
# ------------------------------------------------------------
.update_pu_components <- function(conn, alive_nodes, patch_area, thr, next_pu_id) {
  # conn: a CSR PU connectivity object:
  #   - conn$pu_id    : current PU ID
  #   - conn$id2patch : vector mapping node index -> patch_id
  #   - conn$row_ptr, conn$col_idx: CSR adjacency
  # alive_nodes: logical vector indicating which nodes (patches) survived in this PU
  # patch_area: numeric vector of per-node areas (aligned with alive_nodes)
  # thr: PU-level area threshold (min_patch_size500)
  # next_pu_id: next available PU ID for splitting components into new PUs
  #
  # Goal:
  #   - Split the PU into connected components of surviving patches
  #   - Drop any component whose total area < thr
  #   - Assign PU IDs to surviving components and rebuild their CSR graphs
  #   - Return:
  #       csr_list     : list of component CSR objects that survive
  #       drop_patches : patch_ids to be removed because they belong to
  #                      sub-threshold components
  #       next_pu_id   : updated next-pu counter for downstream calls

  n_alive <- sum(alive_nodes)

  # Case 1: no surviving patches → the PU disappears completely.
  # We don't drop any additional patches here (they are already "dead" by alive_nodes).
  if (n_alive == 0L) {
    return(list(
      csr_list     = list(),        # no surviving components
      drop_patches = integer(0L),   # nothing new to drop; all dead already
      next_pu_id   = next_pu_id
    ))
  }

  # Case 2: exactly one surviving patch
  # This is a special, very cheap case:
  #   - no connectivity edges are needed (1-node graph)
  #   - we just check the PU-threshold on that patch's area.
  if (n_alive == 1L) {
    idx_alive  <- which(alive_nodes)[1L]   # index of surviving node
    area_alive <- patch_area[idx_alive]

    # If the area of that single patch is below the PU threshold,
    # the whole component (i.e., this last patch) should be dropped.
    if (area_alive < thr) {
      return(list(
        csr_list     = list(),                  # PU disappears
        drop_patches = conn$id2patch[idx_alive],# drop that patch at PU level
        next_pu_id   = next_pu_id
      ))
    }

    # Otherwise, keep it as a 1-node PU with no edges (row_ptr = c(0, 0)).
    csr_obj <- list(
      pu_id    = conn$pu_id,
      id2patch = conn$id2patch[idx_alive],
      row_ptr  = c(0L, 0L),
      col_idx  = integer(0L)
    )

    return(list(
      csr_list     = list(csr_obj),  # one surviving component
      drop_patches = integer(0L),    # nothing further to drop
      next_pu_id   = next_pu_id
    ))
  }

  # Case 3: general multi-node case
  # We have multiple surviving patches; they may form one or more
  # connected components. Some components may be sub-threshold in area.

  # Compute per-node component labels and per-component areas.
  comps     <- .compute_components(conn$row_ptr, conn$col_idx, alive_nodes, patch_area)
  comp_id   <- comps$comp_id   # component label for each node (0 if dead)
  comp_area <- comps$comp_area # area per component label (1..max label)

  # Identify labels of components that survive (<-> keep) and those that drop.
  keep_labels <- which(comp_area >= thr)
  drop_labels <- which(comp_area <  thr)

  k_keep   <- length(keep_labels)
  csr_list <- vector("list", k_keep)  # will store CSR objects for surviving components

  if (k_keep > 0L) {
    base_pu_id <- conn$pu_id

    # If there is more than one surviving component, we need to assign new PU IDs.
    # Convention: first component keeps the original pu_id, additional components
    # get new ones from next_pu_id, next_pu_id+1, ...
    if (k_keep > 1L) {
      pu_ids     <- c(base_pu_id, next_pu_id + seq_len(k_keep - 1L))
      next_pu_id <- pu_ids[k_keep]      # advance counter
    } else {
      pu_ids <- base_pu_id              # only one component, keep pu_id
    }

    # For each surviving component, rebuild a CSR graph restricted to its nodes.
    for (j in seq_along(keep_labels)) {
      lab       <- keep_labels[j]
      nodes_lab <- which(comp_id == lab)             # original node indices for this component

      newg <- .rebuild_csr(conn$row_ptr, conn$col_idx, nodes_lab)

      csr_list[[j]] <- list(
        pu_id    = pu_ids[j],
        id2patch = conn$id2patch[nodes_lab],         # patch IDs in this component
        row_ptr  = newg$row_ptr,
        col_idx  = newg$col_idx
      )
    }
  }

  # Nodes in dropped components (labels in drop_labels) correspond
  # to patch IDs that must be removed from patch_dt and from the grid.
  drop_nodes   <- which(comp_id %in% drop_labels)
  drop_patches <- conn$id2patch[drop_nodes]

  list(
    csr_list     = csr_list,
    drop_patches = drop_patches,
    next_pu_id   = next_pu_id
  )
}

# ------------------------------------------------------------
# Compute PU-level log-values for scoring edge cells
# ------------------------------------------------------------
.compute_log_val <- function(pu_dt, params) {
  # pu_dt: data.table with at least (species, pu_id, pu_area_km2)
  # params: species-level parameters (joined by 'species'):
  #   - density
  #   - a_pred, b_pred    (shape parameters for the persistence model)
  #   - min_patch_size500 (c_th: effective threshold for PU area)
  #
  # Output:
  #   data.table(species, pu_id, log_val)
  # where log_val = log(∂S / ∂A_i) for the PU's contribution to multi-species persistence.
  #
  # This function is performance-critical because it is called every pruning step
  # and touches all PUs. We keep it fully vectorised:
  #   - no per-PU loops
  #   - minimal allocations
  #   - all math done in one pass.

  # Join species-level params onto each PU row.
  # This gives us a wide table with species, pu_id, area, and all model params.
  pu_data <- params[pu_dt, on = .(species)]

  # Shorthand vectors for readability and to avoid repeated $ lookups
  A    <- pu_data$pu_area_km2       # PU areas
  dens <- pu_data$density           # species density
  a    <- pu_data$a_pred            # model parameter a
  b    <- pu_data$b_pred            # model parameter b
  c_th <- pu_data$min_patch_size500 # PU threshold c_th
  sp   <- pu_data$species           # species ID for each PU

  # Assume all inputs are valid: A > c_th, dens > 0, etc.
  # This lets us skip checks and guard branches, which reduces overhead.

  # delta = A - c_th : margin above the PU-area threshold.
  delta    <- A - c_th
  logdelta <- log(delta)

  # log(a * dens^{-b})
  # Precompute this shared factor to avoid repeated log/exp in downstream expressions.
  log_a2 <- log(a) - b * log(dens)

  # y = log(a * dens^{-b} * delta^{-b})
  #    = log(a * dens^{-b}) - b * log(delta)
  y   <- log_a2 - b * logdelta
  e_y <- exp(y)                     # exp(y) is reused a few times

  # PU-level persistence probability:
  #   P_i = exp(-exp(y)) = exp(-e_y)
  P_i    <- exp(-e_y)
  log1mP <- log1p(-P_i)             # log(1 - P_i)

  # Sum log(1 - P_j) per species across all its PUs:
  #   sum_log1mP[species s] = Σ_j log(1 - P_j) over PUs j of species s
  # tapply is vectorised and fast enough here.
  sum_log1mP <- tapply(log1mP, sp, sum)

  # For PU i of species s, define:
  #   log Q_i = log ∏_{j≠i} (1 - P_j)
  #           = Σ_j log(1 - P_j) - log(1 - P_i)
  #           = sum_log1mP[s]    - log1mP[i]
  log_Qi <- sum_log1mP[sp] - log1mP

  # log dP_i/dA:
  # For your analytic form, we derived:
  #   dP_i/dA = a * dens^{-b} * b * delta^{-(b+1)} * exp(-exp(y)) * (stuff)
  # After simplifying, the log-derivative collapses to:
  #   log_dP = log(a * dens^{-b}) + log(b) - (b + 1)*log(delta) - e^y
  log_dP <- log_a2 + log(b) - (b + 1) * logdelta - e_y

  # Multi-species marginal loss:
  #   ∂S/∂A_i = (dP_i/dA) * Q_i
  # So on the log scale:
  #   log(∂S/∂A_i) = log_dP + log_Qi
  log_val <- log_dP + log_Qi

  # *** Single allowed sanity check ***
  # If anything goes non-finite, we stop hard, because this function is
  # central to scoring and we don't want to silently continue with NaNs.
  if (any(!is.finite(log_val))) {
    warning(".compute_log_val produced non-finite values in log_val.")
    stop("Non-finite log_val in .compute_log_val.")
  }

  # Return one row per PU, ready to join in prune_step_minimal().
  data.table(
    species = sp,
    pu_id   = pu_data$pu_id,
    log_val = log_val
  )
}
```

```{r}
prune_step_minimal <- function(
  iter,         # pruning iteration index within this stage
  n_remove,      # number of cells to remove in this pruning step
  patch_dt,      # patch table: (species, patch_id, pu_id, patch_area_km2)
  state_env,     # list of PU connectivity graphs (CSR), keyed by "species|pu_id"
  count_alive,   # integer vector: number of species present in each cell
  cs_vals,       # numeric vector: area (km^2) of each cell, aligned with count_alive
  params,        # species-level parameters (min_patch_size, min_patch_size500, etc.)
  vals_env,      # env: get(sp, vals_env)[cell] = patch_id (or NA) for species sp
  index_env,     # env: get(sp, index_env) = list(pid = sorted patch_ids, cell = matching cell indices)
  rook_pairs_all # matrix [n_pairs x 2]: rook-adjacent cell index pairs
) {
  # Keep a stable species ordering for loops.
  # (vals_env contains one vector per species, named by the species/layer.)
  species_layers <- sort(ls(envir = vals_env, all.names = TRUE))

  # Step B helper: get all cells belonging to one patch_id using the compact index.
  .get_cells_for_pid <- function(index, pid) {
    # Binary-search range for pid in sorted index$pid (integer-like ids)
    lo <- findInterval(pid - 0.5, index$pid) + 1L
    hi <- findInterval(pid + 0.5, index$pid)
    if (lo <= hi) index$cell[lo:hi] else integer(0L)
  }

  # ------------------------------------------------------------------
  # 1) Identify edge cells (frontier)
  # ------------------------------------------------------------------
  # "alive" is TRUE where at least one species is present. This is the base
  # occupancy mask used for everything else.
  alive     <- count_alive > 0L

  # Indices of alive cells. Working in index space (rather than full vectors)
  # is both clearer and slightly faster.
  alive_idx <- which(alive)

  # alive_pos maps global cell index -> position in alive_idx (0 means not alive).
  # This lets us work in a compact "alive-space" when counting neighbors,
  # which is *much* faster than inspecting each cell's 4 neighbors in R loops.
  alive_pos            <- integer(length(alive))
  alive_pos[alive_idx] <- seq_along(alive_idx)

  # For every rook-adjacent pair (i, j), mark where *both* ends are alive.
  # This is vectorised across all adjacency pairs for speed.
  both_alive <- alive[rook_pairs_all[, 1]] & alive[rook_pairs_all[, 2]]

  # For the pairs where both cells are alive, pull the "from" cell’s position
  # in alive-space. These are the neighbor contributions we’ll count.
  pos_in_alive <- alive_pos[rook_pairs_all[both_alive, 1]]

  # Degree (0..4) of alive neighbors per alive cell. This tabulate call is
  # O(#adjacency_pairs), not O(#cells * 4), and there are no R-level loops.
  deg_alive <- tabulate(pos_in_alive, nbins = length(alive_idx))

  # Edge cells (the "frontier") are alive cells that do *not* have all 4
  # neighbors alive. Interior cells are ignored in this pruning step.
  edge_idx <- alive_idx[deg_alive < 4L]

  # If we cannot find at least n_remove edge cells, we declare the frontier
  # exhausted for this step. We skip all later work (scoring, updates, etc.),
  # which saves a lot of time when the landscape is nearly gone.
  if (length(edge_idx) < n_remove) {
    return(list(
      patch_dt            = patch_dt,  # unchanged
      state_env           = state_env, # unchanged
      count_alive         = count_alive,
      removed_indices     = integer(0L),
      changed_patch_areas = data.table(species = character(), patch_id = integer())
    ))
  }

  # Snapshot of cell occupancy *before* the step. We use this at the end to
  # identify which cells truly became empty (for removed_indices).
  count_before <- count_alive

  # ------------------------------------------------------------------
  # 2) PU areas + mapping
  # ------------------------------------------------------------------
  # For each (species, pu_id), compute its current total area by summing
  # its patch areas. This is the input to the marginal value function.
  pu_dt <- patch_dt[
    ,
    .(pu_area_km2 = sum(patch_area_km2)),
    by = .(species, pu_id)
  ]

  # Stable mapping from (species, patch_id) -> pu_id at the *start* of this step.
  # We keep this separate because patch_dt will be modified later; this snapshot
  # is needed for:
  #   - mapping patch_id -> PU marginal value
  #   - reconstructing which PUs changed later.
  patch_map_before <- patch_dt[, .(species, patch_id, pu_id)]

  # ------------------------------------------------------------------
  # 3) Score edge cells (multi-species log-sum-exp)
  # ------------------------------------------------------------------
  # Compute per-PU log-marginal values (log ∂S/∂A) for all PUs and species,
  # using species-level parameters. This is the core scoring for the algorithm.
  pu_val_dt <- .compute_log_val(pu_dt, params)

  # Attach PU log values to each patch through (species, pu_id), then reduce
  # to (species, patch_id, score). This gives us a patch-level score that
  # we can use to score cells via their patch IDs.
  patch2score_dt <- patch_map_before[
    pu_val_dt,
    on = .(species, pu_id),
    nomatch = 0L
  ][
    ,
    .(species, patch_id, score = log_val)
  ]

  # For each species, pack its patch_ids and corresponding scores into a small
  # list. This avoids repeated joins in the cell loop and lets us use fastmatch
  # for quick lookups: patch_id -> score.
  val_map <- lapply(
    split(patch2score_dt, patch2score_dt$species),
    function(d) list(pid = d$patch_id, score = d$score)
  )

  # Number of edge cells we need to score.
  edge_n <- length(edge_idx)

  # For each edge cell we maintain:
  #   m    = running max over species' log-values (for numerical stability)
  #   S    = sum exp(x - m) over species
  #   have = did this cell see at least one valid species score?
  # scores is filled at the end; initial -Inf serves as a sentinel.
  scores <- m <- rep(-Inf, edge_n)
  S      <- numeric(edge_n)
  have   <- logical(edge_n)

  # Loop over species that have scoring info.
  # This is the main multi-species accumulation of log-sum-exp.
  for (sp in names(val_map)) {
    # For species sp, get the patch ID at each edge cell. This is a simple
    # array lookup because vals_cache is indexed by cell.
    v       <- get(sp, envir = vals_env, inherits = FALSE)
    pid_vec <- v[edge_idx]
    msp     <- val_map[[sp]]

    # Fast map patch_id -> row index in that species' scoring table.
    # fastmatch::fmatch is significantly faster than base::match.
    idx <- fastmatch::fmatch(pid_vec, msp$pid)

    # Look up log-marginal values for those patch IDs.
    x  <- msp$score[idx]
    ok <- is.finite(x)  # we only use finite entries

    if (any(ok)) {
      # io: indices of edge cells where this species contributes
      io <- which(ok)
      xo <- x[io]
      mo <- m[io]

      # "better" marks cells where this new species has a larger log-value
      # than the current max; we must rescale S in those cells.
      better <- xo > mo

      if (any(better)) {
        ib    <- io[better]
        # Rescale S to new max xo: S_new = S_old * exp(old_m - xo) + 1
        # (the "+1" is exp(xo - xo)).
        S[ib] <- S[ib] * exp(mo[better] - xo[better]) + 1
        m[ib] <- xo[better]
      }

      if (any(!better)) {
        inb <- io[!better]
        # For cells where xo <= current max, we just add exp(xo - mo).
        S[inb] <- S[inb] + exp(xo[!better] - mo[!better])
      }

      # Mark that these edge cells have at least one valid species
      # contribution; needed so we don't log(0) below.
      have[io] <- TRUE
    }
  }

  # Convert accumulated (m, S) into final multi-species scores:
  #
  #   log_sum_exp = m + log(S)
  #   score       = - log_sum_exp  (we minimize "penalty", so more negative
  #                                 log_sum_exp = larger score)
  #
  # Only apply where have == TRUE; under your assumptions, every edge cell
  # should have have == TRUE, but this mask keeps the math safe and cheap.
  scores[have] <- -(m[have] + log(S[have]))

  # We now have one score per edge cell. Because we already checked that
  # length(edge_idx) >= n_remove, we can safely request the top n_remove
  # scores without any further guards.
  s_sub <- scores
  n_sel <- n_remove

  # Find the cutoff score corresponding to the top n_sel (largest) entries
  # without fully sorting the vector. Rfast::nth is O(n), so this is much
  # cheaper than a full sort for large grids.
  cutoff <- Rfast::nth(
    s_sub,
    k            = n_sel,
    descending   = TRUE,
    index.return = FALSE
  )

  # Take all indices whose score >= cutoff. This may include more than n_sel
  # indices if there are ties at the cutoff.
  pick <- which(s_sub >= cutoff)

  # If we have more than n_sel candidates because of ties, we break ties
  # deterministically using:
  #   1) higher score first
  #   2) then smaller cell index (via edge_idx) as a stable tie-breaker.
  if (length(pick) > n_sel) {
    o    <- order(-s_sub[pick], edge_idx[pick])
    pick <- pick[o][seq_len(n_sel)]
  }

  # Translate picked positions in the edge list back to global cell indices.
  sel_idx <- edge_idx[pick]

  # ------------------------------------------------------------------
  # 4) Kill selected cells
  # ------------------------------------------------------------------
  # Removing all species from these cells is represented simply by setting
  # count_alive to 0. This is the cheapest way to keep the "alive" mask
  # in sync without touching per-species rasters here.
  count_alive[sel_idx] <- 0L

  # ------------------------------------------------------------------
  # 5) Attribute removed area to patches
  # ------------------------------------------------------------------
  # Extract cell areas of the removed cells. These are the amounts we’ll
  # subtract from patch areas.
  removed_cells_area <- cs_vals[sel_idx]

  # For each species, we:
  #   - get the patch_id at each removed cell
  #   - sum removed area per patch_id using rowsum() (fast C-level group by)
  #   - stack results across species.
  #
  # This uses only the removed cells and precomputed vals_cache, so it avoids
  # scanning the full grid and keeps the aggregation O(#removed_cells).
  removed_area_by_patch <- rbindlist(
    lapply(species_layers, function(sp) {
      v   <- get(sp, envir = vals_env, inherits = FALSE)
      pid <- v[sel_idx]
      ok  <- !is.na(pid)
      if (!any(ok)) return(NULL)

      a <- rowsum(removed_cells_area[ok], pid[ok], reorder = FALSE)

      data.table(
        species      = sp,
        patch_id     = as.integer(rownames(a)),
        area_removed = as.numeric(a[, 1])
      )
    }),
    use.names = TRUE,
    fill      = TRUE
  )

  # ------------------------------------------------------------
  # Step C: clear selected cells from ALL species caches
  # (must happen AFTER removed_area_by_patch is computed)
  # ------------------------------------------------------------
  for (sp in species_layers) {
    v <- get(sp, envir = vals_env, inherits = FALSE)
    v[sel_idx] <- NA_integer_
    assign(sp, v, envir = vals_env)
  }
  
  # ------------------------------------------------------------------
  # 6) Update patch areas & drop sub-viable patches (patch-level)
  # ------------------------------------------------------------------
  # Attach pu_id to removed-area data using the stable pre-step mapping.
  # We need pu_id to update patch_dt in a single in-place operation.
  dec <- removed_area_by_patch[
    patch_map_before,
    on = .(species, patch_id),
    nomatch = 0L
  ][
    ,
    .(species, patch_id, pu_id, area_removed)
  ]

  # Subtract removed area from each affected patch directly in patch_dt.
  # The i. prefix is standard data.table syntax for columns from "dec".
  patch_dt[dec,
           patch_area_km2 := patch_area_km2 - i.area_removed,
           on = .(species, patch_id, pu_id)]

  # Track which (species, patch_id) changed area. This lets us restrict
  # threshold checks to only those patches instead of re-scanning patch_dt.
  changed_patch_ids_step <- unique(dec[, .(species, patch_id)])

  # Drop patches whose area fell below the species-specific minimum
  # patch size. Because min_patch_size > 0, this also catches the patches
  # whose area went to zero or slightly negative (floating point noise).
  dropped_patches_all <- patch_dt[
    changed_patch_ids_step,
    on = .(species, patch_id)
  ][
    params,
    on = .(species)
  ][
    patch_area_km2 < min_patch_size,
    .(species, patch_id)
  ]

  # Remove those patches from patch_dt; they no longer exist in the system.
  patch_dt <- patch_dt[!dropped_patches_all, on = .(species, patch_id)]

  # ------------------------------------------------------------------
  # 7) Update PU components & accumulate patch drops for cells
  # ------------------------------------------------------------------
  # pending_drop[sp] will hold patch_ids of species sp that should be
  # removed from the cell-level representation at the end of the step.
  pending_drop <- setNames(vector("list", length(species_layers)), species_layers)

  # Initialize pending_drop with all patches dropped at the patch level.
  dp <- split(dropped_patches_all$patch_id, dropped_patches_all$species)
  for (sp in names(dp)) {
    pending_drop[[sp]] <- c(pending_drop[[sp]], dp[[sp]])
  }

  # Only PUs that lost at least one patch need their connectivity recomputed.
  # We find those PUs by merging dropped_patches_all with the stable
  # pre-step mapping patch_map_before.
  aff_pairs <- merge(
    dropped_patches_all,
    patch_map_before,
    by = c("species", "patch_id")
  )

  # For each species, update PUs that lost patches.
  for (sp in unique(aff_pairs$species)) {
    sp_rows <- aff_pairs$species == sp
    by_pu   <- split(aff_pairs$patch_id[sp_rows], aff_pairs$pu_id[sp_rows])

    # New components (if PUs split) get pu_id values starting after the
    # current maximum pu_id for that species.
    next_pu_id <- if (any(patch_dt$species == sp)) {
      max(patch_dt$pu_id[patch_dt$species == sp])
    } else {
      0L
    }

    # Species-specific PU area threshold for components.
    thr_pu <- params[.(sp), min_patch_size500]
    # Patch -> area map for this species, used to build per-PU vectors quickly.
    pa_map_sp <- patch_dt[species == sp, .(patch_id, patch_area_km2)]

    for (pu in names(by_pu)) {
      key  <- paste0(sp, "|", pu)
      conn <- state_env[[key]]
      if (is.null(conn)) next

      id2patch <- conn$id2patch
      dead_ids <- by_pu[[pu]]
      N        <- length(id2patch)

      # alive_nodes marks which nodes (patches) remain in this PU.
      alive_nodes <- rep(TRUE, N)
      alive_nodes[id2patch %in% dead_ids] <- FALSE

      # Build patch_area vector aligned with id2patch indices.
      pa  <- numeric(N)
      idx <- fastmatch::fmatch(id2patch, pa_map_sp$patch_id)
      ok  <- !is.na(idx)
      pa[ok] <- pa_map_sp$patch_area_km2[idx[ok]]

      # Let .update_pu_components:
      #   - split the PU into connected components
      #   - drop components with area < thr_pu
      #   - assign new pu_id values to surviving components
      #   - return updated CSR graphs and additional patches to drop.
      res <- .update_pu_components(
        conn        = conn,
        alive_nodes = alive_nodes,
        patch_area  = pa,
        thr         = thr_pu,
        next_pu_id  = next_pu_id
      )
      next_pu_id <- res$next_pu_id

      # Any patches belonging to sub-threshold components must be dropped.
      drop_ids_comp <- res$drop_patches
      if (length(drop_ids_comp)) {
        pending_drop[[sp]] <- c(pending_drop[[sp]], drop_ids_comp)
        patch_dt <- patch_dt[!(species == sp & patch_id %in% drop_ids_comp)]
      }

      # Replace the original PU CSR object with the new component graphs.
      csr_list <- res$csr_list
      if (!length(csr_list)) {
        # Entire PU disappeared.
        state_env[[key]] <- NULL
      } else {
        for (j in seq_along(csr_list)) {
          cobj <- csr_list[[j]]

          if (j == 1L) {
            # First component reuses the original key.
            state_env[[key]] <- list(
              species  = sp,
              pu_id    = cobj$pu_id,
              id2patch = cobj$id2patch,
              row_ptr  = cobj$row_ptr,
              col_idx  = cobj$col_idx
            )
          } else {
            # Additional components get new keys.
            new_key <- paste0(sp, "|", cobj$pu_id)
            state_env[[new_key]] <- list(
              species  = sp,
              pu_id    = cobj$pu_id,
              id2patch = cobj$id2patch,
              row_ptr  = cobj$row_ptr,
              col_idx  = cobj$col_idx
            )
          }

          # Update patch_dt so patches in this component now reference
          # the correct (possibly new) pu_id.
          patch_dt[species == sp & patch_id %in% cobj$id2patch,
                   pu_id := cobj$pu_id]
        }
      }
    }
  }

  # ------------------------------------------------------------------
  # 8) Drop sub-viable PUs (min_patch_size500, PU-level)
  # ------------------------------------------------------------------
  # At PU level, we only need to check PUs that:
  #   - contain patches that lost area, or
  #   - contained patches dropped entirely.
  cand_patches <- unique(
    rbindlist(
      list(
        removed_area_by_patch[, .(species, patch_id)],
        dropped_patches_all
      ),
      use.names = TRUE,
      fill      = TRUE
    ),
    by = c("species", "patch_id")
  )

  # PUs (before this step) that contained any of those candidate patches.
  aff_pus_before <- unique(
    patch_map_before[
      cand_patches,
      on = .(species, patch_id),
      nomatch = 0L
    ][
      ,
      .(species, pu_id)
    ],
    by = c("species", "pu_id")
  )

  # All patches (before) that belonged to those PUs.
  aff_patches_all <- patch_map_before[
    aff_pus_before,
    on = .(species, pu_id),
    nomatch = 0L
  ][
    ,
    .(species, patch_id)
  ]

  # Surviving patches (after this step) from that set.
  aff_patches_after <- patch_dt[
    aff_patches_all,
    on = .(species, patch_id),
    nomatch = 0L
  ]

  # PUs that still exist after patch-level pruning.
  cand_pus_after <- unique(
    aff_patches_after[, .(species, pu_id)],
    by = c("species", "pu_id")
  )

  # Sum remaining patch areas within those PUs.
  pu_agg <- patch_dt[
    cand_pus_after,
    .(pu_area_km2 = sum(patch_area_km2)),
    on  = .(species, pu_id),
    by  = .EACHI
  ]

  # Join min_patch_size500 and drop PUs whose total area is below threshold.
  pu_check   <- params[pu_agg, on = .(species)]
  dropped_pu <- pu_check[pu_area_km2 < min_patch_size500,
                         .(species, pu_id)]

  # Any PU that fails the PU threshold is removed entirely:
  #   - enqueue its patches for cell-level cleanup
  #   - remove its CSR entry
  #   - remove its patches from patch_dt.
  for (i in seq_len(nrow(dropped_pu))) {
    sp  <- dropped_pu$species[i]
    pu  <- dropped_pu$pu_id[i]
    key <- paste0(sp, "|", pu)

    pat_ids <- patch_dt[species == sp & pu_id == pu, patch_id]
    if (length(pat_ids)) {
      pending_drop[[sp]] <- c(pending_drop[[sp]], pat_ids)
    }

    state_env[[key]] <- NULL
    patch_dt <- patch_dt[!(species == sp & pu_id == pu)]
  }

  # ------------------------------------------------------------------
  # 9) Apply all pending patch drops to count_alive
  # ------------------------------------------------------------------
  # Drop all patches that were removed at patch/PU level from the cell-level
  # occupancy representation by decrementing count_alive at their cells.
  # We use patch_cells mappings to avoid scanning the entire grid.
  # Step B: use compact per-species index (pid/cell vectors) instead of patch_cells lists.
  # Step C: apply pending drops to count_alive AND clear footprints in vals_env
  for (sp in names(pending_drop)) {
    ids <- unique(pending_drop[[sp]])  # prevents double-decrement
    if (!length(ids)) next

    index <- get(sp, envir = index_env, inherits = FALSE)
    if (is.null(index)) next

    v <- get(sp, envir = vals_env, inherits = FALSE)

    for (pid in ids) {
      cells <- .get_cells_for_pid(index, as.integer(pid))
      if (!length(cells)) next

      # decrement count_alive where that species is still contributing
      hit <- cells[count_alive[cells] > 0L]
      if (length(hit)) {
        count_alive[hit] <- count_alive[hit] - 1L
      }

      # IMPORTANT (Step C): remove the species footprint from the cache
      v[cells] <- NA_integer_
    }

    assign(sp, v, envir = vals_env)
  }

  # ------------------------------------------------------------------
  # 10) Final bookkeeping
  # ------------------------------------------------------------------
  # Cells that were alive before and are now empty are counted as fully
  # removed this step. This is the summary the orchestrator likely cares about.
  removed_indices <- which(count_before > 0L & count_alive == 0L)

  # Patches whose area changed this step:
  #   - patches that lost some area (even if they survived)
  #   - patches that were dropped entirely.
  # This is useful for any downstream bookkeeping or diagnostics.
  changed_patch_areas <- unique(
    rbindlist(
      list(
        removed_area_by_patch[, .(species, patch_id)],
        dropped_patches_all
      ),
      use.names = TRUE,
      fill      = TRUE
    ),
    by = c("species", "patch_id")
  )

  # Lightweight log: uses values already computed, so cost is negligible.
  .log_console(
    "prune_step",
    "iter=%d, edge=%d, selected=%d, removed_cells=%d, changed_patches=%d, dropped_patches=%d, dropped_pus=%d",
    as.integer(iter),
    length(edge_idx),
    length(sel_idx),
    length(removed_indices),
    nrow(changed_patch_areas),
    nrow(dropped_patches_all),
    nrow(dropped_pu)
  )

  list(
    patch_dt            = patch_dt,
    state_env           = state_env,
    count_alive         = count_alive,
    removed_indices     = removed_indices,
    changed_patch_areas = changed_patch_areas
  )
}
```

# run_pruning_orchestrator

```{r}
.write_stack_incremental <- function(
  template,              # single-layer SpatRaster used for geometry
  species_layers,        # character vector of layer names
  get_values,            # function(sp) -> integer vector length ncell(template)
  filename,              # output .tif (multi-layer)
  dead_mask = NULL,      # optional logical length ncell, TRUE => force NA
  datatype = "INT4S"     # patch IDs fit in signed 32-bit
) {
  dir.create(dirname(filename), recursive = TRUE, showWarnings = FALSE)

  # Final output options (compressed, tiled, BigTIFF)
  wopt_final <- list(gdal = c("COMPRESS=LZW", "TILED=YES", "BIGTIFF=YES"))

  # Temp layer options (often faster uncompressed; still tiled for speed)
  wopt_tmp <- list(gdal = c("TILED=YES", "BIGTIFF=YES"))

  # Temp directory beside final output (keeps I/O local to target filesystem)
  tmp_dir <- file.path(dirname(filename), paste0(".tmp_layers_", Sys.getpid(), "_", format(Sys.time(), "%Y%m%d%H%M%S")))
  dir.create(tmp_dir, recursive = TRUE, showWarnings = FALSE)

  # Safe filenames for layers
  safe_name <- function(x) {
    x <- gsub("[^A-Za-z0-9_\\-]+", "_", x)
    substr(x, 1, 80)
  }

  tmp_files <- file.path(
    tmp_dir,
    sprintf("%03d_%s.tif", seq_along(species_layers), vapply(species_layers, safe_name, character(1)))
  )

  # Always clean up temp files on exit (even if you error mid-write)
  on.exit({
    suppressWarnings(unlink(tmp_files))
    suppressWarnings(unlink(tmp_dir, recursive = TRUE, force = TRUE))
  }, add = TRUE)

  # --- Write each layer as a single-band raster (free memory each time)
  for (i in seq_along(species_layers)) {
    sp <- species_layers[i]

    v <- as.integer(get_values(sp))
    if (!is.null(dead_mask) && any(dead_mask)) {
      v[dead_mask] <- NA_integer_
    }

    lyr <- terra::setValues(template, v)
    names(lyr) <- sp

    terra::writeRaster(
      lyr, tmp_files[i],
      overwrite = TRUE,
      datatype  = datatype,
      wopt      = wopt_tmp
    )

    rm(v, lyr)
    gc(FALSE)
  }

  # --- Combine into a multi-layer SpatRaster and write final file
  s <- terra::rast(tmp_files)
  names(s) <- species_layers

  terra::writeRaster(
    s, filename,
    overwrite = TRUE,
    datatype  = datatype,
    wopt      = wopt_final
  )

  terra::rast(filename)
}
```

```{r}
# ------------------------------------------------------------
# Orchestrator for repeated pruning iterations
# ------------------------------------------------------------
run_pruning_orchestrator <- function(
  k,
  n_remove,
  patch_dt,
  state_env,
  count_alive,
  patch_stack,
  cs_vals,
  rook_pairs_all,
  params,
  output_dir,
  stage_iter
) {
  # Stage-level log: cheap scalar summary of this pruning stage,
  # including basic state info for patch_dt, state_env, and count_alive.
  n_patches_dt   <- nrow(patch_dt)
  n_species_dt   <- if (n_patches_dt) data.table::uniqueN(patch_dt$species) else 0L
  n_pus_dt       <- if (n_patches_dt) data.table::uniqueN(patch_dt[, .(species, pu_id)])    else 0L
  n_pus_stateenv <- length(state_env)
  n_alive_cells  <- sum(count_alive > 0L)
  max_sp_cell    <- if (length(count_alive)) max(count_alive) else 0L

  .log_console(
    "pruning_stage",
    paste(
      "Pruning stage_%04d start:",
      "k=%d, n_remove=%d, n_species_layers=%d,",
      "n_patches_dt=%d, n_species_dt=%d, n_pus_dt=%d, n_pus_stateenv=%d,",
      "alive_cells=%d, max_sp_per_cell=%d"
    ),
    as.integer(stage_iter),
    as.integer(k),
    as.integer(n_remove),
    length(names(patch_stack)),
    as.integer(n_patches_dt),
    as.integer(n_species_dt),
    as.integer(n_pus_dt),
    as.integer(n_pus_stateenv),
    as.integer(n_alive_cells),
    as.integer(max_sp_cell)
  )

  # ------------------------------------------------------------------
  # 1) Precompute static cell → patch mappings for this stage
  # ------------------------------------------------------------------

  species_layers <- names(patch_stack)

  # Step A: store per-layer values in a mutable environment (no dense matrix).
  # vals_env is the authoritative per-cell patch_id cache during this stage.
  # Step C updates vals_env as pruning proceeds; Step D writes it back to patch_stack.
  vals_env <- new.env(parent = emptyenv())

  for (j in seq_along(species_layers)) {
    sp <- species_layers[j]
    v  <- as.integer(terra::values(patch_stack[[sp]], mat = FALSE))
    assign(sp, v, envir = vals_env)
    rm(v)
  }
  gc()

  # Step B: build compact per-species patch->cells index in an environment.
  # Each species stores two parallel vectors:
  #   - pid  : patch_id per occupied cell, sorted ascending
  #   - cell : the corresponding cell indices, permuted the same way
  # This supports fast binary-search range lookup for a given patch_id.
  index_env <- new.env(parent = emptyenv())

  for (sp in species_layers) {
    v <- get(sp, envir = vals_env, inherits = FALSE)

    idx <- which(!is.na(v))
    if (!length(idx)) {
      assign(sp, NULL, envir = index_env)
      next
    }

    pid <- v[idx]
    o   <- order(pid)

    assign(
      sp,
      list(pid = pid[o], cell = idx[o]),
      envir = index_env
    )
  }

  # ------------------------------------------------------------------
  # 2) Accumulators across iterations
  #
  # We want to return:
  #   - the union of all removed cells across iterations,
  #   - the union of all patches whose area changed at least once.
  #
  # We therefore keep per-iteration outputs and merge them at the end.
  # Preallocating lists of length k is slightly more efficient (and
  # simpler) than growing them dynamically.
  # ------------------------------------------------------------------
  removed_list <- vector("list", k)  # per-iteration removed cell indices
  changed_list <- vector("list", k)  # per-iteration changed (species, patch_id)
  n_iter_run   <- 0L                # number of iterations actually executed

  # ------------------------------------------------------------------
  # 3) Main pruning loop
  #
  # At each iteration:
  #   - call prune_step_minimal() with the current state,
  #   - record which cells were removed and which patches changed,
  #   - write a per-iteration removed-cell mask (if anything changed),
  #   - update the shared state (patch_dt, state_env, count_alive),
  #   - stop early if no cells were removed (frontier exhausted).
  #
  # This loop is the driver for the core pruning behaviour.
  # ------------------------------------------------------------------
  for (iter in seq_len(k)) {
    # One pruning step: does all heavy lifting (edge detection, scoring,
    # patch/PU updates, CSR updates, count_alive updates).
    step_out <- prune_step_minimal(
      iter           = iter,
      n_remove       = n_remove,
      patch_dt       = patch_dt,
      state_env      = state_env,
      count_alive    = count_alive,
      cs_vals        = cs_vals,
      params         = params,
      vals_env       = vals_env,
      index_env      = index_env,
      rook_pairs_all = rook_pairs_all
    )

    # Record that this iteration ran, and store its outputs
    n_iter_run <- n_iter_run + 1L
    removed_list[[n_iter_run]] <- step_out$removed_indices
    changed_list[[n_iter_run]] <- step_out$changed_patch_areas

    # Per-iteration removal mask:
    #   - Only written if any cells were removed, to avoid useless I/O.
    #   - This is an important behavioural output for diagnostics /
    #     visualization of the pruning trajectory, but the check itself
    #     also reduces runtime by skipping empty rasters.
    if (length(step_out$removed_indices) > 0L) {
      # Use the first patch_stack layer as a geometry template.
      mask <- terra::setValues(patch_stack[[1]], NA_integer_)
      mask[step_out$removed_indices] <- 1L

      fn <- file.path(
        output_dir,
        sprintf(
          "removed_mask_pruning_stage_%04d_iter_%03d.tif",
          stage_iter,
          iter
        )
      )
      terra::writeRaster(mask, filename = fn, overwrite = TRUE)
    }

    # Update shared state so the next iteration starts from the new
    # configuration. This is essential for correct behaviour: each
    # iteration must "see" the results of all previous pruning.
    patch_dt    <- step_out$patch_dt
    state_env   <- step_out$state_env
    count_alive <- step_out$count_alive

    # Early stop condition:
    #   If prune_step_minimal removes zero cells but n_remove > 0
    #   (assumed), then the edge frontier is exhausted and there’s no
    #   point in continuing further iterations. Stopping here saves
    #   runtime while preserving the intended behaviour (stop when
    #   nothing more can be pruned).
    if (!length(step_out$removed_indices)) {
      break
    }
  }

  # ------------------------------------------------------------------
  # 4) Consolidate results across iterations
  #
  # We now collapse per-iteration records into:
  #   - a single vector of all removed cell indices,
  #   - a single table of all patches that changed area.
  #
  # Both unions are part of the intended API behaviour.
  # ------------------------------------------------------------------
  # All cells removed in any iteration, deduplicated
  removed_indices_all <- unique(
    unlist(removed_list[seq_len(n_iter_run)], use.names = FALSE)
  )

  # All patches that changed area in any iteration:
  #   - rbindlist() stacks per-iteration tables,
  #   - unique(by = ...) ensures we return each (species, patch_id) once.
  changed_patch_areas_all <- unique(
    data.table::rbindlist(
      changed_list[seq_len(n_iter_run)],
      use.names = TRUE
    ),
    by = c("species", "patch_id")
  )
  
  # Enforce: candidates must still exist in the final patch_dt
  changed_patch_areas_all <- changed_patch_areas_all[
    patch_dt[, .(species, patch_id)],
    on = .(species, patch_id),
    nomatch = 0L
  ]

  # ------------------------------------------------------------------
  # 5) Frontier status & final "alive" mask
  #
  # Definition:
  #   - Frontier is considered exhausted if the last iteration removed
  #     no cells (length == 0).
  #
  # Behaviour:
  #   - When exhausted, we also write a final mask summarising which
  #     cells are still alive (count_alive > 0) after the last step.
  #
  # The alive mask is a high-value summary output, and computing it is
  # cheap since count_alive is already in memory.
  # ------------------------------------------------------------------
  frontier_exhausted <- !length(removed_list[[n_iter_run]])

  if (frontier_exhausted) {
    # Build a final "alive" mask:
    #   - NA where dead,
    #   - 1 where count_alive > 0.
    alive_mask  <- terra::setValues(patch_stack[[1]], NA_integer_)
    alive_cells <- which(count_alive > 0L)
    alive_mask[alive_cells] <- 1L

    fn_alive <- file.path(
      output_dir,
      sprintf(
        "alive_mask_pruning_stage_%04d_iter_%03d_final.tif",
        stage_iter,
        n_iter_run
      )
    )
    terra::writeRaster(alive_mask, filename = fn_alive, overwrite = TRUE)
  }
  
  # ------------------------------------------------------------
  # Step D: materialize vals_env back into patch_stack (STREAM TO DISK)
  # ------------------------------------------------------------
  
  template  <- patch_stack[[1]]
  dead_mask <- (count_alive == 0L)
  
  # Drop the big multi-layer stack pointer before writing (headroom)
  rm(patch_stack)
  gc(FALSE)
  
  out_file <- file.path(
    output_dir,
    sprintf("patch_stack_pruning_stage_%04d.tif", stage_iter)
  )
  
  patch_stack <- .write_stack_incremental(
    template       = template,
    species_layers = species_layers,
  
    # Pull values from vals_env; free each vector immediately after use
    get_values = function(sp) {
      v <- get(sp, envir = vals_env, inherits = FALSE)
      rm(list = sp, envir = vals_env)
      v
    },
  
    filename  = out_file,
    dead_mask = dead_mask,
    datatype  = "INT4S"
  )
  
  # Cleanup
  rm(vals_env, index_env)
  gc(FALSE)

  # Final state + bookkeeping that upstream code may need:
  #   - patch_dt / state_env / count_alive: updated system state,
  #   - removed_indices_all: all cells that ever became empty,
  #   - changed_patch_areas_all: all patches whose area was modified,
  #   - frontier_exhausted: whether pruning terminated because nothing
  #     more could be removed.
  list(
    patch_stack         = patch_stack,   # NEW
    patch_dt            = patch_dt,
    state_env           = state_env,
    count_alive         = count_alive,
    removed_indices     = removed_indices_all,
    changed_patch_areas = changed_patch_areas_all,
    frontier_exhausted  = frontier_exhausted
  )
}
```

# apply_patch_fragmentation_updates

```{r}
# apply_patch_fragmentation_updates
# 
# High-level role in the pipeline:
# --------------------------------
# Given:
#   - patch_stack: per-species patch-ID rasters *after* pruning,
#   - patch_dt: table of patches (species, patch_id, pu_id, area),
#   - state_env: per-(species, PU) connectivity graphs (CSR),
#   - changed_patch_areas: patches whose area changed in pruning,
#   - cs_vals: per-cell area,
#   - params: species-specific thresholds,
#   - count_alive: number of species present per cell,
#
# This function:
#   1. Detects fragmentation of patches whose area changed.
#   2. Applies patch-level thresholds (min_patch_size).
#   3. Applies PU-level thresholds (min_patch_size500).
#   4. Updates:
#       - patch_stack (rasters),
#       - patch_dt (patch table),
#       - state_env (CSR graphs),
#       - count_alive (per-cell species count),
#       - list of patch_ids needing distance-based recheck.
#
# Design goals:
#   - Correctly reflect pruning-induced fragmentation.
#   - Restrict expensive operations (clump, CSR rebuild) to *only*
#     affected species, patches, and PUs.
#   - Avoid repeated deep copies of rasters.
#   - Avoid building huge intermediate tables if possible.
#   - Emit only cheap-but-useful summary logs for Pass 1 and Pass 3.

apply_patch_fragmentation_updates <- function(
  patch_stack,         # SpatRaster AFTER pruning (patch IDs per species)
  patch_dt,            # data.table: (species, patch_id, pu_id, patch_area_km2), keyed on (species, patch_id)
  state_env,           # named list of CSR objects per PU ("species|pu_id")
  changed_patch_areas, # data.table / data.frame: (species, patch_id) whose area changed in pruning
  cs_vals,             # numeric: per-cell area (km^2), aligned to global cell index
  params,              # data.table keyed by species, with min_patch_size, min_patch_size500
  count_alive          # integer vector: per-cell alive-species count (after pruning)
) {
  ## ==========================================================
  ## GLOBAL SETUP
  ## ==========================================================

  # Species names / layer names in the raster stack.
  species_layers <- names(patch_stack)

  # Precompute species-specific thresholds as named vectors.
  # This makes threshold lookup O(1) by 'sp' (no joins inside loops).
  min_patch_by_species    <- setNames(params$min_patch_size,    params$species)
  min_patch500_by_species <- setNames(params$min_patch_size500, params$species)

  # Alive-cell mask: TRUE where at least one species is present.
  # We use this to:
  #   - avoid clump() work in totally empty areas,
  #   - ensure we don't waste time clumping dead cells.
  alive_flag <- !is.na(count_alive) & count_alive > 0L

  # Working copy of count_alive. We mutate this when patches/PUs disappear.
  # This lets callers keep the original count_alive if needed.
  count_work <- count_alive

  # Candidate patches: only those whose area changed in pruning.
  # This is the key shortcut: we *only* do fragmentation checks and
  # CSR work for these patches, not for all patches.
  cand_dt <- data.table::as.data.table(changed_patch_areas)[, .(species, patch_id)]

  # Per-species containers for everything that later passes need.
  # Using lists keeps memory light and avoids repeated joins.
  species_updates         <- vector("list", length(species_layers))
  names(species_updates)  <- species_layers
  area_updates_list       <- setNames(vector("list", length(species_layers)), species_layers)
  pu_threshold_check_list <- setNames(vector("list", length(species_layers)), species_layers)
  
    ## ==========================================================
  ## HELPERS: CSR connected components + PU split + thresholding
  ## ==========================================================

  # Return comp_id (1..ncomp) for each node in a CSR graph.
  # Assumes:
  #   - row_ptr is 0-based offsets (length n+1)
  #   - col_idx contains 1..n node indices
  .csr_components <- function(row_ptr, col_idx, n) {
    comp_id <- integer(n)
    comp <- 0L

    for (start in seq_len(n)) {
      if (comp_id[start] != 0L) next
      comp <- comp + 1L
      comp_id[start] <- comp

      stack <- start
      while (length(stack)) {
        v <- stack[[length(stack)]]
        stack <- stack[-length(stack)]

        s <- row_ptr[v] + 1L
        e <- row_ptr[v + 1L]
        if (e < s) next

        nbr <- col_idx[s:e]
        if (!length(nbr)) next

        new_nodes <- nbr[comp_id[nbr] == 0L]
        if (length(new_nodes)) {
          comp_id[new_nodes] <- comp
          stack <- c(stack, new_nodes)
        }
      }
    }
    comp_id
  }

  # Given a PU graph (conn_mod) and patch_area_vec aligned to conn_mod$id2patch,
  # split into connected components, DROP components with area <= thr_pu,
  # and assign:
  #   - largest kept component keeps pu_old
  #   - other kept components get fresh pu_ids from next_pu_id
  #
  # Returns:
  #   - conns: list of per-component CSR objects (each becomes its own PU)
  #   - drop_patch_ids: patch IDs to remove from raster + patch_dt
  #   - next_pu_id: updated next available PU id
  .split_pu_apply_threshold <- function(conn_mod, patch_area_vec, sp, pu_old, thr_pu, next_pu_id) {
    K <- length(conn_mod$id2patch)

    # Component labeling
    comp_id <- .csr_components(conn_mod$row_ptr, conn_mod$col_idx, K)
    comp_nodes <- split(seq_len(K), comp_id)

    comp_area <- vapply(
      comp_nodes,
      function(idx) sum(patch_area_vec[idx], na.rm = TRUE),
      numeric(1L)
    )

    # IMPORTANT: use strictness that guarantees A > thr_pu survives
    keep_mask <- (comp_area > thr_pu)

    drop_nodes <- if (any(!keep_mask)) {
      unlist(comp_nodes[!keep_mask], use.names = FALSE)
    } else integer(0L)

    drop_patch_ids <- if (length(drop_nodes)) {
      as.integer(conn_mod$id2patch[drop_nodes])
    } else integer(0L)

    keep_nodes <- comp_nodes[keep_mask]
    keep_area  <- comp_area[keep_mask]

    if (!length(keep_nodes)) {
      return(list(conns = list(), drop_patch_ids = drop_patch_ids, next_pu_id = next_pu_id))
    }

    # Largest kept component retains old pu id
    ord <- order(-keep_area)
    keep_nodes <- keep_nodes[ord]
    keep_area  <- keep_area[ord]

    pu_ids_new <- integer(length(keep_nodes))
    pu_ids_new[1L] <- as.integer(pu_old)
    if (length(pu_ids_new) > 1L) {
      pu_ids_new[-1L] <- seq.int(as.integer(next_pu_id), length.out = length(pu_ids_new) - 1L)
      next_pu_id <- as.integer(next_pu_id) + (length(pu_ids_new) - 1L)
    }

    out_conns <- vector("list", length(keep_nodes))

    for (k in seq_along(keep_nodes)) {
      keep_idx <- keep_nodes[[k]]

      if (length(keep_idx) == K) {
        # Use the full graph as-is
        row_ptr2 <- conn_mod$row_ptr
        col_idx2 <- conn_mod$col_idx
        id2patch2 <- conn_mod$id2patch
        pa2 <- patch_area_vec
      } else {
        # Restrict CSR to this component's nodes
        g <- .rebuild_csr(conn_mod$row_ptr, conn_mod$col_idx, keep_idx)
        row_ptr2 <- g$row_ptr
        col_idx2 <- g$col_idx
        id2patch2 <- conn_mod$id2patch[keep_idx]
        pa2 <- patch_area_vec[keep_idx]
      }

      out_conns[[k]] <- list(
        species  = sp,
        pu_id    = as.integer(pu_ids_new[k]),
        id2patch = as.integer(id2patch2),
        patch2id = as.integer(seq_along(id2patch2)),
        row_ptr  = as.integer(row_ptr2),
        col_idx  = as.integer(col_idx2),
        alive    = rep(TRUE, length(id2patch2)),
        comp_id  = rep(1L, length(id2patch2))
        # NOTE: patch_area/comp_area removed; derive from patch_dt when needed
      )
    }

    list(conns = out_conns, drop_patch_ids = drop_patch_ids, next_pu_id = next_pu_id)
  }

  ## ==========================================================
  ## PASS 1: PER-SPECIES FRAGMENTATION ON RASTERS
  ##
  ## For each species:
  ##   - Restrict raster to alive cells.
  ##   - Compute a single clump() on a cropped sub-raster containing
  ##     only candidate patches (not the full landscape).
  ##   - For each candidate patch:
  ##       * Detect whether it fragmented (>= 2 clumps).
  ##       * Drop small fragments (< min_patch_size).
  ##       * Create new patch IDs for surviving fragments.
  ##       * Track which PUs lost area (for PU-level threshold checks).
  ##       * Track patches needing distance-based recheck.
  ##
  ## Performance highlights:
  ##   - Exactly one clump() per species (no per-patch clump()).
  ##   - Clump computed on a cropped sub-raster (smaller extent).
  ##   - All downstream work is vectorized where possible.
  ## ==========================================================

  for (sp in species_layers) {
    # Candidate patch IDs for this species.
    cand_ids <- cand_dt[species == sp, unique(patch_id)]

    # If pruning didn't touch this species' patches, we skip all raster work.
    if (!length(cand_ids)) {
      # NEW: for unchanged species, capture the original single-layer SpatRaster
      # in layer_sp_final so PASS 4 can rebuild the stack purely from
      # species_updates and we don't depend on the original multi-layer stack.
      species_updates[[sp]] <- list(
        patches_to_drop = integer(0L),
        new_patch_rows  = NULL,
        desc_rows       = NULL,
        removed_only    = NULL,
        recheck_ids     = integer(0L),
        layer_sp_final  = patch_stack[[sp]]  # NEW
      )
      next
    }

    # Original patch-ID layer for this species.
    lyr0  <- patch_stack[[sp]]
    # Extract cell values once into a vector (fast to mutate in R).
    vals0 <- terra::values(lyr0, mat = FALSE)

    # Restrict to alive cells only: dead cells can't contribute to
    # any surviving patches, so we treat them as NA.
    # This reduces the area that clump() has to process.
    vals0[!alive_flag] <- NA_integer_
    lyr0_alive <- terra::setValues(lyr0, vals0)

    # Working copy of patch IDs; we'll overwrite this as fragments are
    # assigned new IDs or removed.
    vals_new <- vals0

    # Per-species buffers that will eventually become small data.tables.
    # Keeping them as lists of small pieces avoids repeated rbinds
    # inside the heavy loops.
    new_rows_buf          <- list()          # new patch_dt rows for new fragments
    desc_buf              <- list()          # (pu, old_patch, new_patch) mapping
    removed_only_buf      <- list()          # (pu, old_patch) that vanished
    drop_lookup_ids       <- integer(0L)     # patch IDs to remove from patch_dt
    recheck_ids           <- integer(0L)     # patch IDs needing distance recheck
    area_updates_sp       <- list()          # (species, patch_id, area_km2)
    pu_threshold_check_sp <- list()          # (species, pu_id) that lost area

    # Next available patch_id for this species (for new fragments).
    # We compute this once so we can assign new IDs without repeated
    # max() calls or lookups.
    sp_pids <- patch_dt[species == sp, patch_id]
    max_pid <- if (length(sp_pids)) max(sp_pids) else 0L

    # Species-specific minimum patch area threshold.
    th_patch <- min_patch_by_species[[sp]]

    # Map candidate patches to the indices of their cells.
    #   - idx_all: indices of all cells belonging to any candidate patch.
    #   - pid_idx: named list mapping patch_id -> vector of cell indices.
    idx_all <- which(!is.na(vals0) & vals0 %in% cand_ids)
    pid_idx <- split(idx_all, vals0[idx_all], drop = TRUE)

    # Compute a single clump() on a cropped sub-raster containing only
    # those cells. This massively reduces both memory and time compared
    # to clumping the entire species layer.
    all_cells <- unlist(pid_idx, use.names = FALSE)
    ext_sub   <- terra::ext(lyr0_alive, cells = all_cells)
    lyr_sub   <- terra::crop(lyr0_alive, ext_sub, snap = "near")

    cl_sub      <- terra::rast(
      fasterRaster::clump(fasterRaster::fast(lyr_sub), diagonal = FALSE)
    )
    cl_sub_vals <- terra::values(cl_sub, mat = FALSE)

    # Build a mapping:
    #   global cell index (in lyr0_alive) -> cell index in cl_sub
    # so we can get clump IDs for any set of patch cells with a simple
    # vector lookup instead of rerunning raster operations.
    xy_all        <- terra::xyFromCell(lyr0_alive, all_cells)
    sub_cells_all <- terra::cellFromXY(cl_sub, xy_all)
    names(sub_cells_all) <- as.character(all_cells)

    # Helper: fetch clump IDs for a vector of global cell indices.
    clump_fetch <- function(pid_cells) {
      cl_sub_vals[sub_cells_all[as.character(pid_cells)]]
    }

    # -------------------------
    # Per-patch fragmentation
    # -------------------------
    for (pid in cand_ids) {
      # PU containing this patch (cheap keyed lookup in patch_dt).
      pu_id_old <- patch_dt[.(sp, pid), pu_id]

      # Cells for this patch ID (within alive geometry).
      pid_cells <- pid_idx[[as.character(pid)]]

      # Clump labels for these cells (in the cropped clump raster).
      subc  <- clump_fetch(pid_cells)
      ucomp <- unique(subc[!is.na(subc)])

      # Case A: patch remained a single clump.
      #   - Geometry might have changed (shape), but it's still contiguous.
      #   - We mark it for distance-based recheck and skip all fragmentation logic.
      if (length(ucomp) <= 1L) {
        recheck_ids <- c(recheck_ids, as.integer(pid))
        next
      }

      # Case B: true fragmentation (>= 2 clumps).
      # We compute area per clump using cs_vals (per-cell area).
      ok <- !is.na(subc)
      area_tab <- rowsum(
        cs_vals[pid_cells][ok],
        subc[ok],
        reorder = FALSE
      )

      # keep_tab: table of (clump_label, area) sorted by area descending.
      keep_tab <- data.frame(
        comp_raw  = as.integer(rownames(area_tab)),
        area      = as.numeric(area_tab[, 1]),
        row.names = NULL
      )
      keep_tab <- keep_tab[order(-keep_tab$area), , drop = FALSE]

      # Apply minimum patch size threshold: only clumps above th_patch survive.
      keep_tab <- keep_tab[keep_tab$area >= th_patch, , drop = FALSE]

      # Wipe the original patch label from all cells of this patch.
      # Surviving clumps will be assigned new (or reused) patch IDs below.
      vals_new[pid_cells] <- NA_integer_

      # If no clump survives, the patch disappears entirely.
      if (!nrow(keep_tab)) {
        drop_lookup_ids <- c(drop_lookup_ids, pid)

        if (!is.na(pu_id_old)) {
          # Record that this (pu, patch) vanished completely.
          removed_only_buf[[length(removed_only_buf) + 1L]] <-
            data.table::data.table(
              pu_id        = pu_id_old,
              old_patch_id = as.integer(pid)
            )

          # This PU lost area; we will recheck its PU-area threshold in Pass 2b.
          pu_threshold_check_sp[[length(pu_threshold_check_sp) + 1L]] <-
            data.table::data.table(species = sp, pu_id = pu_id_old)
        }

        # Species removed from these cells entirely → decrement count_work.
        hit <- pid_cells[count_work[pid_cells] > 0L]
        count_work[hit] <- count_work[hit] - 1L
        next
      }

      # If some clumps survive:
      #   - keep_ids_raw: clumps we keep as patches.
      #   - drop_ids_raw: clumps we drop (< threshold).
      keep_ids_raw <- keep_tab$comp_raw
      drop_ids_raw <- setdiff(ucomp, keep_ids_raw)

      # For dropped clumps:
      #   - species disappears from those cells,
      #   - PU loses some area (trigger PU recheck later).
      if (length(drop_ids_raw)) {
        drop_cells <- pid_cells[subc %in% drop_ids_raw]
        hit <- drop_cells[count_work[drop_cells] > 0L]
        count_work[hit] <- count_work[hit] - 1L

        if (!is.na(pu_id_old)) {
          pu_threshold_check_sp[[length(pu_threshold_check_sp) + 1L]] <-
            data.table::data.table(species = sp, pu_id = pu_id_old)
        }
      }

      # Assign patch IDs to surviving clumps:
      #   - largest fragment keeps old patch_id,
      #   - additional fragments get fresh patch IDs.
      if (nrow(keep_tab) > 1L) {
        new_ids <- c(pid, seq(max_pid + 1L, length.out = nrow(keep_tab) - 1L))
        max_pid <- max_pid + (length(new_ids) - 1L)
      } else {
        new_ids <- pid
      }

      # Map clump labels -> patch IDs and write them back into vals_new.
      comp_to_new <- setNames(as.integer(new_ids), as.character(keep_tab$comp_raw))
      keep_mask   <- subc %in% keep_tab$comp_raw
      vals_new[pid_cells[keep_mask]] <-
        unname(comp_to_new[as.character(subc[keep_mask])])

      # Record updated areas for surviving fragments.
      area_updates_sp[[length(area_updates_sp) + 1L]] <-
        data.table::data.table(
          species        = sp,
          patch_id       = as.integer(new_ids),
          patch_area_km2 = as.numeric(keep_tab$area)
        )

      # If the patch lives in a PU and produced *new* fragments, we need
      # new rows in patch_dt for those extra fragments, inheriting pu_id.
      if (!is.na(pu_id_old) && length(new_ids) >= 2L) {
        new_rows_buf[[length(new_rows_buf) + 1L]] <-
          data.table::data.table(
            species        = sp,
            patch_id       = as.integer(new_ids[-1]),
            pu_id          = pu_id_old,
            patch_area_km2 = as.numeric(keep_tab$area[-1])
          )
      }

      # Descendant mapping (for CSR rebuild in Pass 3):
      #   (pu_id, old_patch_id) → new_patch_id(s).
      if (!is.na(pu_id_old)) {
        desc_buf[[length(desc_buf) + 1L]] <-
          data.table::data.table(
            pu_id        = pu_id_old,
            old_patch_id = as.integer(pid),
            new_patch_id = as.integer(new_ids)
          )
      }

      # All surviving fragments (including the old ID) need distance-based rechecks.
      recheck_ids <- c(recheck_ids, as.integer(new_ids))
    } # end per-patch loop for species sp
    
    # NEW: drop per-species clump objects as soon as we're done with them
    # to reduce memory pressure before the next species.
    rm(cl_sub_vals, sub_cells_all)
    gc()

    # Collapse per-species buffers into compact tables (or NULL).
    new_patch_rows <- if (length(new_rows_buf)) {
      data.table::rbindlist(new_rows_buf, use.names = TRUE)
    } else NULL

    desc_rows <- if (length(desc_buf)) {
      data.table::rbindlist(desc_buf, use.names = TRUE)
    } else NULL

    removed_only <- if (length(removed_only_buf)) {
      data.table::rbindlist(removed_only_buf, use.names = TRUE)
    } else NULL

    area_updates_list[[sp]] <- if (length(area_updates_sp)) {
      data.table::rbindlist(area_updates_sp, use.names = TRUE, fill = TRUE)
    } else NULL

    pu_threshold_check_list[[sp]] <- if (length(pu_threshold_check_sp)) {
      data.table::rbindlist(pu_threshold_check_sp, use.names = TRUE, fill = TRUE)
    } else NULL

    # Record all updates for this species; later passes will consume this.
    species_updates[[sp]] <- list(
      patches_to_drop = unique(as.integer(drop_lookup_ids)),
      new_patch_rows  = new_patch_rows,
      desc_rows       = desc_rows,
      removed_only    = removed_only,
      recheck_ids     = unique(as.integer(recheck_ids)),
      layer_sp_final  = terra::setValues(lyr0_alive, vals_new)
    )
    
    # NEW: immediately free per-species big objects (alive copy, value
    # vectors, and indexing structures) for species that were actually
    # processed, to keep the working set small.
    rm(lyr0_alive, vals0, vals_new, idx_all, pid_idx, all_cells)
    gc()
  } # end PASS 1 species loop

  ## ==========================================================
  ## PASS 1 CONSOLIDATION + SUMMARY LOG
  ##
  ## Here we:
  ##   - Combine per-species area updates and PU flags into single tables.
  ##   - Emit a single summary log using cheap scalar summaries.
  ## ==========================================================

  # NEW: at this point, every species has its final layer stored in
  # species_updates[[sp]]$layer_sp_final (either modified or original).
  # The original multi-layer patch_stack object is no longer needed
  # structurally and can be dropped to simplify the object graph before
  # we rebuild the stack in PASS 4.
  rm(patch_stack)  # NEW
  gc()             # NEW

  # Combine per-species area updates into one table (if any).
  area_updates_pieces <- Filter(Negate(is.null), area_updates_list)
  area_updates <- if (length(area_updates_pieces)) {
    data.table::rbindlist(area_updates_pieces, use.names = TRUE, fill = TRUE)
  } else NULL

  # Combine per-species PU threshold flags into one table (if any).
  pu_threshold_pieces <- Filter(Negate(is.null), pu_threshold_check_list)
  pu_threshold_check <- if (length(pu_threshold_pieces)) {
    data.table::rbindlist(pu_threshold_pieces, use.names = TRUE, fill = TRUE)
  } else NULL

  # Cheap scalar summaries for logging:
  n_species_touched <- sum(vapply(
    species_updates,
    function(su) !is.null(su$layer_sp_final),
    logical(1L)
  ))

  total_cand_patches <- nrow(cand_dt)
  
  # NEW: we no longer need cand_dt beyond this point; keep only the
  # scalar summary to free its memory early.
  rm(cand_dt)
  gc()

  total_dropped_patches <- sum(vapply(
    species_updates,
    function(su) length(su$patches_to_drop),
    integer(1L)
  ))

  total_new_fragments <- sum(vapply(
    species_updates,
    function(su) if (is.null(su$new_patch_rows)) 0L else nrow(su$new_patch_rows),
    integer(1L)
  ))

  total_recheck_patches <- sum(vapply(
    species_updates,
    function(su) length(su$recheck_ids),
    integer(1L)
  ))

  n_pu_flagged_total <- if (!is.null(pu_threshold_check)) {
    data.table::uniqueN(pu_threshold_check$pu_id)
  } else 0L

  # PASS 1 summary log: describes how many patches were considered,
  # how many died, how many fragments were created, and how many PUs
  # will need PU-level rechecks. All quantities are derived from
  # already-built objects (no extra heavy work).
  .log_console(
    "fragmentation_pass1",
    "[%s] Frag PASS1 complete: species_touched=%d, cand_patches=%d, dropped_patches=%d, new_fragments=%d, recheck_patches=%d, pu_flagged=%d.",
    format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
    n_species_touched,
    total_cand_patches,
    total_dropped_patches,
    total_new_fragments,
    total_recheck_patches,
    n_pu_flagged_total
  )

  ## ==========================================================
  ## PASS 2: patch_dt UPDATES (PATCH-LEVEL)
  ##
  ## This is pure table work:
  ##   - Remove vanished patches.
  ##   - Update areas for surviving fragments.
  ##   - Append new rows for newly created fragment IDs.
  ##   All raster work has already been done in Pass 1.
  ## ==========================================================

  # Remove patches that disappeared during fragmentation.
  for (sp in names(species_updates)) {
    rid <- species_updates[[sp]]$patches_to_drop
    if (length(rid)) {
      patch_dt <- patch_dt[!(species == sp & patch_id %in% rid)]
    }
  }

  # Apply area updates for surviving fragments.
  if (!is.null(area_updates)) {
    patch_dt[area_updates,
             patch_area_km2 := i.patch_area_km2,
             on = .(species, patch_id)]
  }

  # Append new patch rows for additional fragments.
  new_rows_components <- Filter(
    Negate(is.null),
    lapply(species_updates, `[[`, "new_patch_rows")
  )
  if (length(new_rows_components)) {
    new_rows_all <- data.table::rbindlist(new_rows_components, use.names = TRUE, fill = TRUE)
    # unique() guards against any accidental duplication (cheap at this scale).
    patch_dt <- data.table::rbindlist(
      list(patch_dt, unique(new_rows_all)),
      use.names = TRUE,
      fill      = TRUE
    )
  }

  ## ==========================================================
  ## PASS 2b: PU-LEVEL THRESHOLD CHECKS (min_patch_size500)
  ##
  ## Only PUs that actually lost area (due to dropped clumps or fully
  ## vanished patches) are rechecked. If a PU's total area falls below
  ## its threshold:
  ##   - remove its patches from the raster and patch_dt,
  ##   - remove its CSR object,
  ##   - decrement count_work where species vanished.
  ##
  ## This avoids rescanning all PUs and keeps work proportional to change.
  ## ==========================================================

  # NOTE (2026-02-17):
  # PU threshold enforcement (min_patch_size500) is now handled in PASS 3
  # after CSR updates, using component-based splitting + thresholding.
  # This avoids dropping whole PUs based only on total area and ensures
  # disconnected graphs are split into new PUs consistently.


  ## ==========================================================
  ## PASS 3: CSR REBUILD FOR PUs THAT CHANGED MEMBERSHIP
  ##
  ## For PUs where:
  ##   - patches fragmented (old_id → new_id(s)), or
  ##   - patches vanished entirely,
  ## we rebuild or adjust their CSR graphs so that:
  ##   - topology remains consistent with new patch IDs,
  ##   - PUs with 0 or 1 patch get trivial CSR representations,
  ##   - fragmentation creates a "clique" among fragments of a patch,
  ##   - edges between old patches are inherited by their descendants.
  ##
  ## Optimization strategy:
  ##   - "Cheap path" when there are no new IDs in the PU:
  ##        * Only areas changed: update patch_area and comp_area in place.
  ##        * Some patches removed: restrict the CSR using .rebuild_csr().
  ##   - "Full path" only when new patch IDs appear in the PU.
  ##   - We build adjacency using integer vectors and deduplicate once,
  ##     avoiding heavy data.table joins.
  ## ==========================================================

  # PASS 3 summary counters
  total_species_with_pu_updates <- 0L
  total_pu_touched              <- 0L
  total_pu_cheap                <- 0L
  total_pu_full                 <- 0L
  total_pu_drop                 <- 0L
  total_components_dropped       <- 0L
  total_new_pus_created          <- 0L

  # Next PU id per species (for new components created during splitting)
  next_pu_id_by_sp <- setNames(integer(length(species_layers)), species_layers)
  for (sp0 in species_layers) {
    pu_ids0 <- patch_dt[species == sp0 & !is.na(pu_id), pu_id]
    next_pu_id_by_sp[[sp0]] <- if (length(pu_ids0)) (max(as.integer(pu_ids0)) + 1L) else 1L
  }

  for (sp in names(species_updates)) {
    su <- species_updates[[sp]]

    # PUs touched for this species due to membership change:
    pu_ids_membership <- unique(c(
      if (!is.null(su$desc_rows))    su$desc_rows$pu_id,
      if (!is.null(su$removed_only)) su$removed_only$pu_id
    ))
    pu_ids_membership <- pu_ids_membership[!is.na(pu_ids_membership)]

    # PLUS PUs flagged because they lost area (dropped clumps / vanished patches)
    pu_ids_threshold <- if (!is.null(pu_threshold_check)) {
      pu_threshold_check[species == sp, unique(pu_id)]
    } else integer(0L)
    pu_ids_threshold <- pu_ids_threshold[!is.na(pu_ids_threshold)]

    pu_ids <- unique(c(pu_ids_membership, pu_ids_threshold))
    n_pu_touched <- length(pu_ids)

    if (!n_pu_touched) next

    total_species_with_pu_updates <- total_species_with_pu_updates + 1L
    total_pu_touched              <- total_pu_touched + n_pu_touched

    # Species-wide patch-area map (after Pass 2)
    pa_map_sp <- patch_dt[species == sp, .(patch_id, patch_area_km2)]

    # Pull raster values ONCE per species; mutate as we drop components/patches
    vals_sp_final <- terra::values(su$layer_sp_final, mat = TRUE)[, 1]

    thr_pu <- min_patch500_by_species[[sp]]
    next_pu_id <- next_pu_id_by_sp[[sp]]

    for (pu in pu_ids) {
      key_old  <- paste0(sp, "|", pu)
      conn_old <- state_env[[key_old]]
      if (is.null(conn_old)) next

      id2patch_old <- as.integer(conn_old$id2patch)
      row_ptr_old  <- as.integer(conn_old$row_ptr)
      col_idx_old  <- as.integer(conn_old$col_idx)

      # Current patch IDs in this PU after Pass 2 (and any prior PU splits in this Pass 3 loop)
      pu_patch_now <- patch_dt[species == sp & pu_id == pu, patch_id]

      # PU lost all patches
      if (!length(pu_patch_now)) {
        state_env[[key_old]] <- NULL
        total_pu_drop <- total_pu_drop + 1L
        next
      }

      removed_ids <- setdiff(id2patch_old, pu_patch_now)
      has_new_ids <- any(!(pu_patch_now %in% id2patch_old))

      # ----------------------------------------------------------
      # Build conn_mod for the *current* node set in this PU
      # ----------------------------------------------------------
      if (length(pu_patch_now) == 1L) {
        # Trivial 1-node CSR
        pid_final <- as.integer(pu_patch_now[1L])
        idx_area  <- fastmatch::fmatch(pid_final, pa_map_sp$patch_id)
        pa_final  <- pa_map_sp$patch_area_km2[idx_area]

        conn_mod <- list(
          id2patch = pid_final,
          row_ptr  = c(0L, 0L),
          col_idx  = integer(0L)
        )
        patch_area_vec <- as.numeric(pa_final)

        # cheap path
        total_pu_cheap <- total_pu_cheap + 1L

      } else if (!has_new_ids) {
        # No new patch IDs: either topology unchanged (only areas changed),
        # or nodes removed (restrict CSR)
        if (!length(removed_ids)) {
          # Topology unchanged; use existing CSR as-is
          idx <- fastmatch::fmatch(id2patch_old, pa_map_sp$patch_id)
          patch_area_vec <- as.numeric(pa_map_sp$patch_area_km2[idx])

          conn_mod <- list(
            id2patch = id2patch_old,
            row_ptr  = row_ptr_old,
            col_idx  = col_idx_old
          )
          total_pu_cheap <- total_pu_cheap + 1L

        } else {
          # Nodes removed: restrict CSR
          keep_idx <- which(!(id2patch_old %in% removed_ids))
          g <- .rebuild_csr(row_ptr_old, col_idx_old, keep_idx)

          id2patch_new <- as.integer(id2patch_old[keep_idx])
          idx <- fastmatch::fmatch(id2patch_new, pa_map_sp$patch_id)
          patch_area_vec <- as.numeric(pa_map_sp$patch_area_km2[idx])

          conn_mod <- list(
            id2patch = id2patch_new,
            row_ptr  = as.integer(g$row_ptr),
            col_idx  = as.integer(g$col_idx)
          )
          total_pu_cheap <- total_pu_cheap + 1L
        }

      } else {
        # ----------------------------------------------------------
        # Full rebuild: PU contains new patch IDs (fragments)
        # (your existing full-rebuild logic, but we store into conn_mod)
        # ----------------------------------------------------------
        total_pu_full <- total_pu_full + 1L
        N <- length(id2patch_old)

        desc_pu <- if (!is.null(su$desc_rows)) su$desc_rows[pu_id == pu] else NULL
        desc_split <- if (!is.null(desc_pu) && nrow(desc_pu) > 0L) {
          split(desc_pu$new_patch_id, desc_pu$old_patch_id)
        } else list()

        present_now <- !is.na(fastmatch::fmatch(id2patch_old, pu_patch_now))

        D_map <- vector("list", N)
        names(D_map) <- as.character(id2patch_old)

        for (i in seq_len(N)) {
          pid0 <- id2patch_old[i]
          if (!present_now[i]) {
            D_map[[i]] <- integer(0L)
            next
          }
          d_i <- if (length(desc_split)) desc_split[[as.character(pid0)]] else NULL
          if (is.null(d_i) || !length(d_i)) {
            D_map[[i]] <- as.integer(pid0)
          } else {
            D_map[[i]] <- as.integer(d_i)
          }
        }

        patches_final <- sort(unique(unlist(D_map, use.names = FALSE)))
        K <- length(patches_final)
        pid_to_idx <- setNames(seq_len(K), as.character(patches_final))

        # --- sibling edges ---
        sib_u_list <- vector("list", N)
        sib_v_list <- vector("list", N)
        ks <- 0L
        for (i in seq_len(N)) {
          d <- D_map[[i]]
          if (length(d) > 1L) {
            nodes <- unname(pid_to_idx[as.character(d)])
            if (length(nodes) == 2L) {
              ks <- ks + 1L
              sib_u_list[[ks]] <- nodes[1L]
              sib_v_list[[ks]] <- nodes[2L]
            } else {
              comb <- utils::combn(nodes, 2L)
              ks <- ks + 1L
              sib_u_list[[ks]] <- comb[1L, ]
              sib_v_list[[ks]] <- comb[2L, ]
            }
          }
        }
        if (ks > 0L) {
          u_sib <- unlist(sib_u_list[seq_len(ks)], use.names = FALSE)
          v_sib <- unlist(sib_v_list[seq_len(ks)], use.names = FALSE)
        } else {
          u_sib <- v_sib <- integer(0L)
        }

        # --- inherited edges ---
        inh_u_list <- vector("list", N)
        inh_v_list <- vector("list", N)
        ke <- 0L

        for (i in seq_len(N)) {
          di <- D_map[[i]]
          if (!length(di)) next

          s <- row_ptr_old[i] + 1L
          e <- row_ptr_old[i + 1L]
          if (e < s) next

          nbrs <- col_idx_old[s:e]
          nbrs <- nbrs[nbrs > i]
          if (!length(nbrs)) next

          di_idx <- unname(pid_to_idx[as.character(di)])

          for (j in nbrs) {
            dj <- D_map[[j]]
            if (!length(dj)) next
            dj_idx <- unname(pid_to_idx[as.character(dj)])

            ni <- length(di_idx)
            nj <- length(dj_idx)

            ke <- ke + 1L
            inh_u_list[[ke]] <- rep.int(di_idx, nj)
            inh_v_list[[ke]] <- rep(dj_idx, each = ni)
          }
        }

        if (ke > 0L) {
          u_inh <- unlist(inh_u_list[seq_len(ke)], use.names = FALSE)
          v_inh <- unlist(inh_v_list[seq_len(ke)], use.names = FALSE)
        } else {
          u_inh <- v_inh <- integer(0L)
        }

        if (length(u_sib) || length(u_inh)) {
          u_all <- c(u_sib, u_inh)
          v_all <- c(v_sib, v_inh)
        } else {
          u_all <- v_all <- integer(0L)
        }

        # --- dedupe + build CSR ---
        if (length(u_all)) {
          u_can <- pmin(u_all, v_all)
          v_can <- pmax(u_all, v_all)

          keep_nv <- (u_can != v_can)
          u_can <- u_can[keep_nv]
          v_can <- v_can[keep_nv]

          if (length(u_can)) {
            key_int <- u_can + (v_can - 1L) * K
            ord <- order(key_int)
            key_int <- key_int[ord]
            u_can <- u_can[ord]
            v_can <- v_can[ord]

            uniq <- !duplicated(key_int)
            u_can <- u_can[uniq]
            v_can <- v_can[uniq]

            u_sym <- c(u_can, v_can)
            v_sym <- c(v_can, u_can)

            adj_new <- split(v_sym, u_sym)
            adj_full <- vector("list", K)
            if (length(adj_new)) {
              for (nm in names(adj_new)) {
                adj_full[[as.integer(nm)]] <- adj_new[[nm]]
              }
            }

            lens <- integer(K)
            for (kk in seq_len(K)) {
              nb <- adj_full[[kk]]
              if (length(nb)) {
                nb <- sort(unique(nb))
                adj_full[[kk]] <- nb
                lens[kk] <- length(nb)
              } else {
                adj_full[[kk]] <- integer(0L)
                lens[kk] <- 0L
              }
            }

            row_ptr_new <- c(0L, cumsum(lens))
            col_idx_new <- if (sum(lens) > 0L) {
              as.integer(unlist(adj_full, use.names = FALSE))
            } else integer(0L)
          } else {
            row_ptr_new <- rep(0L, K + 1L)
            col_idx_new <- integer(0L)
          }
        } else {
          row_ptr_new <- rep(0L, K + 1L)
          col_idx_new <- integer(0L)
        }

        idx_area <- fastmatch::fmatch(patches_final, pa_map_sp$patch_id)
        patch_area_vec <- as.numeric(pa_map_sp$patch_area_km2[idx_area])

        conn_mod <- list(
          id2patch = as.integer(patches_final),
          row_ptr  = as.integer(row_ptr_new),
          col_idx  = as.integer(col_idx_new)
        )
      }

      # ----------------------------------------------------------
      # Split into components + apply min_patch_size500 per component
      # ----------------------------------------------------------
      res <- .split_pu_apply_threshold(
        conn_mod        = conn_mod,
        patch_area_vec  = patch_area_vec,
        sp              = sp,
        pu_old          = pu,
        thr_pu          = thr_pu,
        next_pu_id      = next_pu_id
      )
      next_pu_id <- res$next_pu_id

      # Remove the old PU entry; we will recreate 0..K PU entries from res$conns
      state_env[[key_old]] <- NULL

      # Drop components that failed threshold
      if (length(res$drop_patch_ids)) {
        total_components_dropped <- total_components_dropped + 1L

        # Remove species from those cells
        idx <- which(!is.na(vals_sp_final) & vals_sp_final %in% res$drop_patch_ids)
        if (length(idx)) {
          hit <- idx[count_work[idx] > 0L]
          count_work[hit] <- count_work[hit] - 1L
          vals_sp_final[idx] <- NA_integer_
        }

        # Drop from patch_dt
        patch_dt <- patch_dt[!(species == sp & patch_id %in% res$drop_patch_ids)]
      }

      # If nothing survived, PU is gone
      if (!length(res$conns)) {
        total_pu_drop <- total_pu_drop + 1L
        next
      }

      # Update patch_dt pu_id assignments + write state_env entries
      if (length(res$conns) > 1L) {
        total_new_pus_created <- total_new_pus_created + (length(res$conns) - 1L)
      }

      for (cc in res$conns) {
        pu_new <- cc$pu_id
        patch_ids_cc <- cc$id2patch

        # Update patch_dt pu_id for these patches (including new PUs)
        patch_dt[species == sp & patch_id %in% patch_ids_cc, pu_id := pu_new]

        # Store CSR under its new key
        key_new <- paste0(sp, "|", pu_new)
        state_env[[key_new]] <- cc
      }
    } # end PU loop

    # Write back raster for this species after all PU/component drops
    su$layer_sp_final <- terra::setValues(su$layer_sp_final, vals_sp_final)
    species_updates[[sp]] <- su

    # Save next pu id for this species
    next_pu_id_by_sp[[sp]] <- next_pu_id
  } # end species loop

  # PASS 3 summary log: cheap scalar counts summarising CSR rebuild work.
  .log_console(
    "fragmentation_pass3",
    "[%s] Frag PASS3 complete: species_with_PU_updates=%d, PUs_touched=%d, PUs_cheap=%d, PUs_full=%d, PUs_dropped=%d, components_dropped=%d, new_PUs_created=%d.",
    format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
    total_species_with_pu_updates,
    total_pu_touched,
    total_pu_cheap,
    total_pu_full,
    total_pu_drop,
    total_components_dropped,
    total_new_pus_created
  )

  ## ==========================================================
  ## PASS 4: REBUILD patch_stack ONCE (RASTER)
  ##
  ## To avoid deep-copy behaviour from repeated [[<- on a SpatRaster,
  ## we:
  ##   - assemble per-species layers in a plain list,
  ##   - build a new SpatRaster stack with a single terra::rast() call.
  ##
  ## We also drop large intermediates and call gc() to reduce memory
  ## pressure before the big allocation.
  ## ==========================================================

  rm(area_updates_list, pu_threshold_check_list, area_updates_pieces, pu_threshold_pieces)
  gc()

  # PASS 4: write final stack incrementally (no rast(new_layers))

  out_file <- file.path(
    tempdir(),
    sprintf("patch_stack_frag_%s.tif", format(Sys.time(), "%Y%m%d_%H%M%S"))
  )
  
  template <- species_updates[[species_layers[1]]]$layer_sp_final
  
  patch_stack <- .write_stack_incremental(
    template       = template,
    species_layers = species_layers,
    get_values     = function(sp) terra::values(species_updates[[sp]]$layer_sp_final, mat = FALSE),
    filename       = out_file,
    dead_mask      = NULL,
    datatype       = "INT4S"
  )
  
  # Optional but recommended: drop the per-species layer objects now that the stack is written
  for (sp in species_layers) {
    species_updates[[sp]]$layer_sp_final <- NULL
  }
  gc(FALSE)

  # Cells that went from "at least one species present" to "no species".
  # These are useful for downstream bookkeeping in the pipeline.
  removed_idx <- which(count_alive > 0L & count_work == 0L)

  ## ==========================================================
  ## PASS 5: COLLECT patch_ids_to_recheck FOR DISTANCE STAGE
  ##
  ## Gather all patches whose geometry changed (or were created)
  ## to pass to the distance-based connectivity stage.
  ##
  ## We intersect with patch_dt to ensure we don't include IDs that
  ## were removed by PU-level pruning.
  ## ==========================================================

  recheck_all <- data.table::rbindlist(
    lapply(names(species_updates), function(sp) {
      data.table::data.table(
        species  = sp,
        patch_id = as.integer(species_updates[[sp]]$recheck_ids)
      )
    }),
    use.names = TRUE,
    fill      = TRUE
  )

  data.table::setkey(recheck_all, species, patch_id)
  recheck_all <- unique(
    recheck_all[
      patch_dt[, .(species, patch_id)],
      on = .(species, patch_id),
      nomatch = 0L
    ]
  )

  .log_console(
    "fragmentation_stage",
    "[%s] Frag stage complete: pass1_cand=%d, pass1_dropped=%d, pass1_new_frag=%d, pass1_recheck=%d, pass1_pu_flagged=%d, pass3_pu_touched=%d, pass3_pu_cheap=%d, pass3_pu_full=%d, pass3_pu_drop=%d, removed_cells=%d, recheck_patches=%d.",
    format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
    total_cand_patches,
    total_dropped_patches,
    total_new_fragments,
    total_recheck_patches,
    n_pu_flagged_total,
    total_pu_touched,
    total_pu_cheap,
    total_pu_full,
    total_pu_drop,
    length(removed_idx),
    nrow(recheck_all)
  )
  
  ## ==========================================================
  ## FINAL RETURN
  ##
  ## We return all updated structures required by downstream steps.
  ## ==========================================================

  list(
    patch_stack          = patch_stack,
    patch_dt             = patch_dt,
    state_env            = state_env,
    count_alive          = count_work,
    patch_ids_to_recheck = recheck_all,
    removed_indices      = removed_idx
  )
}
```

# update_connectivity_after_distance

```{r}
# ------------------------------------------------------------
# 5. Distance-based Connectivity Update (minimal, no alive01)
#   Assumes:
#     • sf::sf_use_s2(TRUE) was set once elsewhere;
#     • patch_stack layers are already in a geographic CRS
#       compatible with sf::st_distance (e.g. lon/lat).
#
# Goal of this stage:
#   • Enforce species-specific maximum dispersal distances between patches.
#   • If distance breaks connectivity within a PU, split it into components
#     and drop small components below the min_patch_size500 threshold.
#   • Keep patch_dt, state_env and count_alive consistent with these changes.
#
# Design goals:
#   • Only touch patches whose geometry / IDs changed (and their neighbours).
#   • Reuse raster values per species (cache) to avoid repeated terra::values().
#   • Restrict polygon building to a tight bounding box around candidate cells.
#   • Update existing CSR graphs in-place instead of rebuilding everything.
#   • Emit a single cheap global log summarising the distance stage.
# ------------------------------------------------------------
update_connectivity_after_distance <- function(
  patch_stack,          # SpatRaster: patch IDs per species (after fragmentation)
  patch_dt,             # data.table: species, patch_id, pu_id, patch_area_km2
  state_env,            # list of CSR graphs per PU (key: "species|pu_id")
  patch_ids_to_recheck, # data.table: (species, patch_id) whose geometry/ID changed
  params,               # data.table: species, dispersal_dist (km), min_patch_size500
  count_alive           # integer: per-cell count of species present (before distance step)
) {
  ## ----------------------------------------------------------
  ## 1. Pre-compute indices, thresholds, and helpers
  ## ----------------------------------------------------------

  # Key and index patch_dt for fast joins by (species, patch_id) and (species, pu_id).
  # This supports:
  #   - fast mapping from patches to PUs,
  #   - fast PU-area lookups when rebuilding CSR components.
  data.table::setkey(patch_dt, species, patch_id)
  data.table::setindex(patch_dt, species, pu_id)

  # Working copy of per-cell alive-species counts.
  # We decrement this as patches are dropped so that:
  #   • behaviour: final count_alive reflects distance-induced removals;
  #   • memory/runtime: we avoid recomputing counts from scratch.
  count_work <- as.integer(count_alive)

  # Per-species dispersal distances (km -> m) and PU min-area thresholds.
  # These are used in the distance test and when dropping small components.
  disp_m_by_species <- setNames(params$dispersal_dist * 1000, params$species)
  min_pu_by_species <- setNames(params$min_patch_size500,    params$species)

  # Normalise patch_ids_to_recheck to a clean (species, patch_id) table
  # and key it by the same columns as patch_dt.
  # This is the minimal set of patches whose geometry changed and thus may
  # affect distance connectivity.
  recheck_dt <- data.table::as.data.table(patch_ids_to_recheck)[, .(species, patch_id)]
  data.table::setkey(recheck_dt, species, patch_id)

  # Per-species raster-value cache:
  #   • behaviour: we always read the same layer values used in fragmentation;
  #   • runtime: we avoid repeated terra::values() calls inside loops;
  #   • memory: each species' values are stored once, not rebuilt per PU.
  vals_cache <- new.env(parent = emptyenv())
  get_layer_vals <- function(sp) {
    key <- paste0("vals__", sp)
    if (!exists(key, envir = vals_cache, inherits = FALSE)) {
      v <- terra::values(patch_stack[[sp]], mat = FALSE)
      assign(key, as.integer(v), envir = vals_cache)
    }
    get(key, envir = vals_cache, inherits = FALSE)
  }

  # PUs that contain patches needing distance re-check:
  #   • behaviour: we only operate on PUs where something changed;
  #   • runtime: dramatically reduces work in late stages when most PUs are stable;
  #   • memory: fewer polygons and CSR structures need to be touched.
  recheck_pus <- patch_dt[
    recheck_dt,
    on = .(species, patch_id)
  ][
    !is.na(pu_id),
    .(species, pu_id)
  ]
  recheck_pus <- unique(recheck_pus)

  # We mutate a working copy of the CSR environment, leaving the input list
  # conceptually unchanged outside this function.
  state_env_work <- state_env

  # Global counters for a single, cheap summary log.
  # All of these are built from existing per-species scalars and require
  # only integer additions (no extra passes over large data):
  #   • Stage 1 (candidate selection): species_touched, PUs_touched,
  #     changed_patches, cand_patches.
  #   • Stage 3 (graph update): edges_checked, edges_dropped,
  #     dropped_patches, removed_PUs.
  #   • Overall effect: alive_cells_before/after and total cells_lost.
  total_species_touched    <- 0L
  total_pus_touched        <- 0L
  total_changed_patches    <- 0L
  total_candidate_patches  <- 0L
  total_edges_checked      <- 0L
  total_edges_dropped      <- 0L
  total_patches_dropped    <- 0L
  total_pus_removed        <- 0L

  dirty_species <- character(0L)
  
  for (sp in unique(recheck_pus$species)) {
    pu_ids_sp      <- unique(recheck_pus[species == sp, pu_id])
    changed_ids_sp <- unique(recheck_dt[species == sp, patch_id])

    # If this species has no relevant PUs or no changed patches, skip it.
    if (!length(pu_ids_sp) || !length(changed_ids_sp)) next

    # --- Cheap stats for later global logging (all either free or very cheap) ----
    # These are per-species scalars that we will accumulate into the global
    # counters once we know this species actually went through the distance
    # update pipeline (i.e. had at least one candidate patch).
    n_pu_sp      <- length(pu_ids_sp)
    n_changed_sp <- length(changed_ids_sp)

    # Per-species counters (used only for the global summary log).
    cand_patch_ids_sp  <- integer(0L)
    edges_checked_sp   <- 0L
    edges_dropped_sp   <- 0L
    dropped_patches_sp <- 0L
    pus_removed_sp     <- 0L

    ## ------------------------------------------------------
    ## Step 1: Candidate patch IDs (changed + neighbours)
    ##
    ## We don’t need to re-evaluate all edges:
    ##   • Only edges incident to changed patches can change distance.
    ##   • We also need the neighbour patches to compute those distances.
    ## This keeps complexity closer to "changed boundary size" than
    ## "total graph size".
    ## ------------------------------------------------------
    cand_list <- vector("list", length(pu_ids_sp))
    li        <- 0L

    for (pu in pu_ids_sp) {
      key  <- paste0(sp, "|", pu)
      conn <- state_env_work[[key]]
      if (is.null(conn)) next  # PU may have been removed earlier in this function

      id2patch <- as.integer(conn$id2patch)
      row_ptr  <- as.integer(conn$row_ptr)
      col_idx  <- as.integer(conn$col_idx)

      # Patches in this PU that changed geometry / ID
      changed_ids_pu <- intersect(changed_ids_sp, id2patch)
      if (!length(changed_ids_pu)) next

      changed_idx <- match(changed_ids_pu, id2patch)

      # Neighbours of changed nodes (using CSR row_ptr/col_idx)
      nbr_idx <- unique(unlist(lapply(changed_idx, function(u) {
        s <- row_ptr[u] + 1L
        e <- row_ptr[u + 1L]
        if (e >= s) as.integer(col_idx[s:e]) else integer(0L)
      })))

      # Candidate nodes = changed nodes + their neighbours
      cand_nodes <- sort(unique(c(changed_idx, nbr_idx)))
      if (length(cand_nodes)) {
        li <- li + 1L
        cand_list[[li]] <- id2patch[cand_nodes]
      }
    }

    # If no candidates exist for this species, there is nothing to do for
    # distance connectivity; skip without touching the global counters.
    if (!li) next
    
    layer_dirty <- FALSE   # <--- ADD THIS (per-species flag)


    cand_patch_ids_sp <- sort(unique(
      unlist(cand_list[seq_len(li)], use.names = FALSE)
    ))

    ## ------------------------------------------------------
    ## Step 2: Build polygons for candidate patches
    ##
    ## We:
    ##   • mask the species raster to only the candidate patch IDs;
    ##   • restrict to a bounding box over cells that contain those IDs;
    ##   • convert that sub-raster into polygons;
    ##
    ## This reduces:
    ##   • runtime: fewer cells fed into terra::as.polygons();
    ##   • memory: smaller intermediate rasters and sf objects.
    ## ------------------------------------------------------
    lv_full <- get_layer_vals(sp)

    # Keep only cells belonging to candidate patches
    idx_match   <- match(lv_full, cand_patch_ids_sp, nomatch = 0L)
    masked_vals <- rep(NA_integer_, length(lv_full))
    masked_vals[idx_match > 0L] <- lv_full[idx_match > 0L]

    # If no cells belong to candidates (defensive), skip species
    idx_all <- which(!is.na(masked_vals))
    if (!length(idx_all)) next

    base_rast   <- patch_stack[[sp]]
    masked_rast <- terra::setValues(base_rast, masked_vals)

    # Tight extent around candidate cells → smaller polygonisation window.
    ext_sub     <- terra::ext(base_rast, cells = idx_all)
    masked_sub  <- terra::crop(masked_rast, ext_sub, snap = "near")

    # Build polygons of candidate patches; we assume raster is already in
    # an appropriate geographic CRS for sf::st_distance().
    poly       <- terra::as.polygons(masked_sub, values = TRUE, dissolve = TRUE)
    poly_sf_sp <- sf::st_as_sf(poly)
    
    # NEW: masked raster objects no longer needed
    rm(masked_rast, masked_sub)
    gc()
    
    if (!nrow(poly_sf_sp)) next  # Nothing to do if no candidate polygons

    # Identify non-geometry column with patch IDs and standardise its name
    gcol <- attr(poly_sf_sp, "sf_column")
    pidc <- setdiff(names(poly_sf_sp), gcol)[1]
    data.table::setnames(poly_sf_sp, pidc, "patch_id")

    # Drop artefacts with missing patch_id
    poly_sf_sp <- poly_sf_sp[!is.na(poly_sf_sp$patch_id), ]
    
    # NEW: immediately pull out just what we need and drop the heavy sf object
    geom_sp <- sf::st_geometry(poly_sf_sp)
    pid_vec <- as.integer(poly_sf_sp$patch_id)
    pid_to_poly_sp <- setNames(
      seq_len(length(pid_vec)),
      as.character(pid_vec)
    )
    
    # Drop data frame + original SpatVector, keep only geometry + mapping
    poly_sf_sp$patch_id <- NULL
    rm(poly_sf_sp, poly, pid_vec)
    gc()

    # Species-specific dispersal distance in meters
    disp_m <- disp_m_by_species[[sp]]

    # Next available PU id for this species (for new components created
    # by splitting disconnected PUs); 0 fallback handles degenerate cases.
    next_pu_id_sp <- max(patch_dt[species == sp, pu_id], na.rm = TRUE)
    if (!is.finite(next_pu_id_sp)) next_pu_id_sp <- 0L

    ## ------------------------------------------------------
    ## Step 3: Per-PU distance filtering and PU splitting
    ##
    ## For each PU:
    ##   • identify edges incident to changed patches;
    ##   • drop edges that exceed dispersal distance;
    ##   • recompute connected components and drop sub-threshold PUs;
    ##   • update CSR graphs and patch_dt accordingly.
    ##
    ## This preserves the original behaviour while touching only the
    ## subgraph affected by geometry changes.
    ## ------------------------------------------------------
    for (pu in pu_ids_sp) {
      key  <- paste0(sp, "|", pu)
      conn <- state_env_work[[key]]
      if (is.null(conn)) next

      id2patch <- as.integer(conn$id2patch)
      N        <- length(id2patch)
      row_ptr  <- as.integer(conn$row_ptr)
      col_idx  <- as.integer(conn$col_idx)

      # Changed patches that belong to this PU
      changed_ids_pu <- intersect(changed_ids_sp, id2patch)
      if (!length(changed_ids_pu)) next

      changed_idx <- match(changed_ids_pu, id2patch)

      # Build adjacency list from CSR representation
      adj <- vector("list", N)
      for (i in seq_len(N)) {
        s <- row_ptr[i] + 1L
        e <- row_ptr[i + 1L]
        adj[[i]] <- if (e >= s) as.integer(col_idx[s:e]) else integer(0L)
      }

      # Collect directed edges (i, j) incident to changed nodes
      pi_list <- vector("list", length(changed_idx))
      pj_list <- vector("list", length(changed_idx))
      ei      <- 0L

      for (idx_u in seq_along(changed_idx)) {
        u  <- changed_idx[idx_u]
        nb <- adj[[u]]
        if (length(nb)) {
          ei <- ei + 1L
          pi_list[[ei]] <- rep.int(u, length(nb))
          pj_list[[ei]] <- nb
        }
      }

      # If no edges touch changed patches, PU connectivity is unaffected
      if (!ei) next

      pairs_i <- unlist(pi_list[seq_len(ei)], use.names = FALSE)
      pairs_j <- unlist(pj_list[seq_len(ei)], use.names = FALSE)

      # Unique directed edges (i, j) to test
      pairs <- data.table::data.table(i = pairs_i, j = pairs_j)
      pairs <- unique(pairs)

      # Count edges we actually examined for this species (for logging).
      edges_checked_sp <- edges_checked_sp + nrow(pairs)

      # Distance filter flags for each edge (TRUE = keep, FALSE = drop)
      keep_flag <- rep(TRUE, nrow(pairs))

      # Group edges by origin node i to reuse geometry lookups
      idx_by_i  <- split(seq_len(nrow(pairs)), pairs$i)

      for (i_chr in names(idx_by_i)) {
        idxs  <- idx_by_i[[i_chr]]
        u_idx <- as.integer(i_chr)

        pid_i <- id2patch[u_idx]
        pid_j <- id2patch[pairs$j[idxs]]

        # Look up polygon rows for the origin and targets
        poly_i <- pid_to_poly_sp[as.character(pid_i)]
        rows_j <- unname(pid_to_poly_sp[as.character(pid_j)])

        # Compute distances from patch i to all neighbour patches j
        # using great-circle distance on the sf geometries.
        dists     <- sf::st_distance(geom_sp[poly_i], geom_sp[rows_j])
        dists_num <- as.numeric(dists)

        # Treat NAs as 0 → conservatively keep those edges
        if (anyNA(dists_num)) {
          dists_num[is.na(dists_num)] <- 0
        }

        # Mark edges that exceed the dispersal distance for removal
        keep_flag[idxs] <- dists_num <= disp_m
      }

      # If all edges survive, PU connectivity is unaffected by distance
      if (all(keep_flag)) next

      # Drop edges that fail the distance test from both directions
      drop_idx <- which(!keep_flag)
      edges_dropped_sp <- edges_dropped_sp + length(drop_idx)

      for (k_edge in drop_idx) {
        u <- pairs$i[k_edge]
        v <- pairs$j[k_edge]

        if (length(adj[[u]])) {
          adj[[u]] <- adj[[u]][adj[[u]] != v]
        }
        if (length(adj[[v]])) {
          adj[[v]] <- adj[[v]][adj[[v]] != u]
        }
      }

      # Rebuild CSR from updated adjacency lists
      lens_new    <- vapply(adj, length, integer(1L))
      row_ptr_new <- as.integer(c(0L, cumsum(lens_new)))
      col_idx_new <- as.integer(unlist(adj, use.names = FALSE))
      if (!length(col_idx_new)) col_idx_new <- integer(0L)

      # Current patch areas for this PU, via (species, pu_id) index:
      #   • behaviour: ensures components get correct area sums;
      #   • runtime: index avoids scanning the whole patch_dt.
      pu_rows_now <- patch_dt[
        .(sp, pu),
        .(patch_id, patch_area_km2),
        on = .(species, pu_id)
      ]

      patch_area_vec <- pu_rows_now$patch_area_km2[
        match(id2patch, pu_rows_now$patch_id)
      ]
      patch_area_vec[is.na(patch_area_vec)] <- 0

      # Minimal CSR object passed into .update_pu_components().
      # That helper:
      #   • finds connected components after edge removals,
      #   • drops components whose PU area < species threshold,
      #   • assigns new PU IDs to surviving components,
      #   • returns new CSR objects and IDs to drop.
      conn_mod <- list(
        pu_id    = pu,
        id2patch = id2patch,
        row_ptr  = row_ptr_new,
        col_idx  = col_idx_new
      )

      res <- .update_pu_components(
        conn        = conn_mod,
        alive_nodes = rep(TRUE, length(id2patch)),
        patch_area  = patch_area_vec,
        thr         = min_pu_by_species[[sp]],
        next_pu_id  = next_pu_id_sp
      )

      next_pu_id_sp  <- res$next_pu_id
      drop_patch_ids <- res$drop_patches

      ## ----------------------------------------------------
      ## Step 3f: Drop patches in sub-threshold components
      ##
      ## Behaviour:
      ##   • Removes PU fragments too small to be viable for this species.
      ## Runtime + memory:
      ##   • Shrinks patch_dt, rasters, and graphs as PUs vanish.
      ## ----------------------------------------------------
      if (length(drop_patch_ids)) {
        dropped_patches_sp <- dropped_patches_sp + length(drop_patch_ids)

        # Remove dropped patches from patch_dt for this PU/species
        patch_dt <- patch_dt[
          !(species == sp & pu_id == pu & patch_id %in% drop_patch_ids)
        ]

        # Clear dropped patch IDs from raster values and decrement
        # per-cell species counts where necessary.
        lv       <- get_layer_vals(sp)
        cell_idx <- which(!is.na(lv) & (lv %in% drop_patch_ids))
        
        if (length(cell_idx)) {
          hit <- cell_idx[count_work[cell_idx] > 0L]
          if (length(hit)) {
            count_work[hit] <- count_work[hit] - 1L
          }
        
          lv[cell_idx] <- NA_integer_
          layer_dirty <- TRUE
          assign(paste0("vals__", sp), lv, envir = vals_cache)
        }
      }

      ## ----------------------------------------------------
      ## Step 3g: Update CSR entries for surviving components
      ##
      ## Behaviour:
      ##   • state_env_work reflects new PU structure and IDs.
      ##   • patch_dt is updated so each patch points to its
      ##     new PU ID.
      ## ----------------------------------------------------
      csr_list <- res$csr_list
      state_env_work[[key]] <- NULL  # remove original PU graph

      if (!length(csr_list)) {
        # Entire PU disappeared (all components sub-threshold).
        pus_removed_sp <- pus_removed_sp + 1L
      } else {
        for (j in seq_along(csr_list)) {
          cobj    <- csr_list[[j]]
          new_pu  <- cobj$pu_id
          new_key <- paste0(sp, "|", new_pu)

          # Patch areas for this component’s patches, using (species, pu_id) index
          areas_map <- patch_dt[
            .(sp, new_pu),
            .(patch_id, patch_area_km2),
            on = .(species, pu_id)
          ]
          patch_area_vec2 <- areas_map$patch_area_km2[
            match(cobj$id2patch, areas_map$patch_id)
          ]

          # Reconstruct CSR graph object for this component
          state_env_work[[new_key]] <- list(
            species  = sp,
            pu_id    = new_pu,
            id2patch = cobj$id2patch,
            patch2id = as.integer(seq_along(cobj$id2patch)),
            row_ptr  = cobj$row_ptr,
            col_idx  = cobj$col_idx,
            alive    = rep(TRUE, length(cobj$id2patch)),
            comp_id  = rep(1L, length(cobj$id2patch))
            # patch_area/comp_area removed
          )

          # Ensure patch_dt records the new PU ID for all patches in this component
          patch_dt[species == sp & patch_id %in% cobj$id2patch,
                   pu_id := new_pu]
        }
      }
    } # end PU loop

    ## ------------------------------------------------------
    ## 3h. Accumulate per-species statistics for final log
    ##
    ## All quantities are either already computed or extremely cheap:
    ##   • n_pu_sp, n_changed_sp, length(cand_patch_ids_sp)
    ##   • edges_checked_sp, edges_dropped_sp
    ##   • dropped_patches_sp, pus_removed_sp
    ##   • n_alive_before_sp, n_alive_after_sp
    ##
    ## We aggregate them into global counters so that only a single,
    ## pipeline-wide log is emitted after all species are processed.
    ## This keeps logging overhead minimal while still giving a
    ## detailed view of each stage.
    ## ------------------------------------------------------
    total_species_touched    <- total_species_touched + 1L
    total_pus_touched        <- total_pus_touched + n_pu_sp
    total_changed_patches    <- total_changed_patches + n_changed_sp
    total_candidate_patches  <- total_candidate_patches + length(cand_patch_ids_sp)
    total_edges_checked      <- total_edges_checked + edges_checked_sp
    total_edges_dropped      <- total_edges_dropped + edges_dropped_sp
    total_patches_dropped    <- total_patches_dropped + dropped_patches_sp
    total_pus_removed        <- total_pus_removed + pus_removed_sp
    
    # keep your RAM cleanup
    if (layer_dirty) {
      dirty_species <- c(dirty_species, sp)
    } else {
      # safe to drop cache for untouched species
      rm(list = paste0("vals__", sp), envir = vals_cache)
    }
    gc(FALSE)
  }   # end species loop

  ## ----------------------------------------------------------
  ## 4. Remove CSR entries for PUs that no longer exist
  ##
  ## Behaviour:
  ##   • Keeps state_env_work in sync with patch_dt.
  ## Runtime/memory:
  ##   • Avoids carrying dead PUs in later stages, keeping graphs small.
  ## ----------------------------------------------------------
  pu_dt_refined <- patch_dt[
    ,
    .(pu_area_km2 = sum(patch_area_km2, na.rm = TRUE)),
    by = .(species, pu_id)
  ]

  keep_keys <- paste0(pu_dt_refined$species, "|", as.integer(pu_dt_refined$pu_id))
  drop_keys <- setdiff(names(state_env_work), keep_keys)
  for (k in drop_keys) state_env_work[[k]] <- NULL

  ## ----------------------------------------------------------
  ## 5. Cells that lost their last species in this distance step
  ##
  ## Behaviour:
  ##   • removed_indices flags cells that transitioned from >=1 species
  ##     to 0 species purely because of the distance stage.
  ##   • orchestrator uses this to build diagnostic masks / logs.
  ## ----------------------------------------------------------
  removed_idx <- which(count_alive > 0L & count_work == 0L)

  ## ----------------------------------------------------------
  ## 6. Single distance-stage summary log
  ##
  ## All values are derived from cheap per-species scalars:
  ##   • Stage 1 (candidate selection): species_touched, PUs_touched,
  ##     changed_patches, cand_patches.
  ##   • Stage 3 (graph updates): edges_checked, edges_dropped,
  ##     dropped_patches, removed_PUs.
  ##   • Overall effect: alive_cells_before/after and cells_lost.
  ##
  ## No additional raster or sf work is performed here; only integer
  ## arithmetic on counters accumulated above.
  ## ----------------------------------------------------------

  .log_console(
    "connectivity",
    "[%s] Distance stage complete: species_touched=%d, PUs_touched=%d, changed_patches=%d, cand_patches=%d, edges_checked=%d, edges_dropped=%d, dropped_patches=%d, removed_PUs=%d.",
    format(Sys.time(), "%Y-%m-%d %H:%M:%S"),
    total_species_touched,
    total_pus_touched,
    total_changed_patches,
    total_candidate_patches,
    total_edges_checked,
    total_edges_dropped,
    total_patches_dropped,
    total_pus_removed
  )

  # ----------------------------------------------------------
  # 7b. Rebuild patch_stack once on disk (no [[<- deep copies)
  # ----------------------------------------------------------
  out_file <- file.path(
    tempdir(),
    sprintf("patch_stack_dist_%s.tif", format(Sys.time(), "%Y%m%d_%H%M%S"))
  )
  
  template  <- patch_stack[[1]]
  dead_mask <- (count_work == 0L)
  
  patch_stack <- .write_stack_incremental(
    template       = template,
    species_layers = names(patch_stack),
    get_values     = function(sp) {
      key <- paste0("vals__", sp)
      if (exists(key, envir = vals_cache, inherits = FALSE)) {
        get(key, envir = vals_cache, inherits = FALSE)
      } else {
        as.integer(terra::values(patch_stack[[sp]], mat = FALSE))
      }
    },
    filename  = out_file,
    dead_mask = dead_mask,
    datatype  = "INT4S"
  )
  
  rm(recheck_dt, recheck_pus, vals_cache)
  gc(FALSE)
  
  list(
    patch_stack     = patch_stack,
    patch_dt        = patch_dt,
    state_env       = state_env_work,
    count_alive     = count_work,
    removed_indices = removed_idx
  )
}
```

# run_global_orchestrator_simplified

```{r}
# ------------------------------------------------------------
# 6. Global Orchestrator (ultra-minimal: prune → frag → distance)
#
# Role in the pipeline
# --------------------
# This function runs the three main spatial stages in order:
#   1) Pruning      – remove edge cells from patches.
#   2) Fragmentation – update patch IDs / PUs when patches are broken apart.
#   3) Distance     – enforce species-specific dispersal limits between patches.
#
# Design goals
# ------------
# • Achieve desired behaviour:
#     - Apply all three stages in the correct order.
#     - Pass updated state objects between stages.
#     - Write diagnostic rasters for removed cells at each stage.
#     - Save enough state to resume from the end of the last completed stage.
#
# • Reduce runtime:
#     - Only call each stage once per global "stage_iter".
#     - Avoid any redundant recomputation or checks here; delegate work to the
#       specialised orchestrators (pruning, fragmentation, distance).
#
# • Reduce memory usage:
#     - Reuse the same objects (patch_dt, state_env, count_alive, patch_stack)
#       in-place across iterations instead of creating new copies.
#     - Save only the minimal required resume state to disk (no static params).
# ------------------------------------------------------------
run_global_orchestrator_simplified <- function(
  n_remove,                    # edge cells to remove per pruning iteration
  k,                           # pruning iterations per stage
  patch_dt,                    # data.table: species, patch_id, pu_id, patch_area_km2
  state_env,                   # list: connectivity per PU (CSR), keys "species|pu_id"
  count_alive,                 # integer vector: per-cell count of species present
  patch_stack,                 # SpatRaster: one layer per species with patch IDs per cell
  cs_vals,                     # numeric vector: per-cell area (km^2)
  rook_pairs_all,              # integer matrix: rook-adjacent cell index pairs
  params,                      # data.table: species parameters (min_patch_size, dispersal, etc.)
  output_dir       = "Spatial/Outputs",
  max_stages       = 1000L,
  start_stage_iter = 1L
) {

  # Global loop over "stages":
  #   • Each iteration performs pruning → fragmentation → distance on the
  #     current state.
  #   • We stop when pruning reports that its frontier is exhausted
  #     (no more edge cells to remove).
  for (stage_iter in seq(from = start_stage_iter, to = max_stages)) {

    # ========================================================
    # 1) PRUNING STAGE
    #
    # Behaviour:
    #   • Removes up to n_remove edge cells per patch per iteration,
    #     repeated k times.
    #   • Updates:
    #       - patch_dt    (patch areas / IDs)
    #       - state_env   (CSR connectivity structures)
    #       - count_alive (per-cell species-counts)
    #   • Returns:
    #       - changed_patch_areas: patches whose shapes/areas changed
    #       - frontier_exhausted: TRUE when no more cells can be pruned
    #
    # Runtime/memory:
    #   • All heavy spatial work is encapsulated in run_pruning_orchestrator.
    #   • We only reassign returned objects (no extra copies).
    # ========================================================
    # --- PRUNING ---
    prune_out <- run_pruning_orchestrator(
      k              = k,
      n_remove       = n_remove,
      patch_dt       = patch_dt,
      state_env      = state_env,
      count_alive    = count_alive,
      patch_stack    = patch_stack,
      cs_vals        = cs_vals,
      rook_pairs_all = rook_pairs_all,
      params         = params,
      output_dir     = output_dir,
      stage_iter     = stage_iter
    )
    
    patch_stack        <- prune_out$patch_stack
    patch_dt           <- prune_out$patch_dt
    state_env          <- prune_out$state_env
    count_alive        <- prune_out$count_alive
    changed_patches    <- prune_out$changed_patch_areas
    frontier_exhausted <- prune_out$frontier_exhausted
    
    # --- FRAGMENTATION ---
    frag_out <- apply_patch_fragmentation_updates(
      patch_stack         = patch_stack,
      patch_dt            = patch_dt,
      state_env           = state_env,
      changed_patch_areas = changed_patches,
      cs_vals             = cs_vals,
      params              = params,
      count_alive         = count_alive
    )
    
    patch_stack <- frag_out$patch_stack
    patch_dt    <- frag_out$patch_dt
    state_env   <- frag_out$state_env
    count_alive <- frag_out$count_alive
    
    removed_frag <- frag_out$removed_indices
    
    if (length(removed_frag) > 0L) {
      mask_frag <- terra::setValues(patch_stack[[1]], NA_integer_)
      mask_frag[removed_frag] <- 1L
      fn_frag <- file.path(
        output_dir,
        sprintf("removed_mask_fragmentation_stage_%04d.tif", stage_iter)
      )
      terra::writeRaster(mask_frag, filename = fn_frag, overwrite = TRUE)
    }
    
    recheck_ids <- data.table::as.data.table(frag_out$patch_ids_to_recheck)
    if (!nrow(recheck_ids)) {
      recheck_ids <- data.table::data.table(species = character(), patch_id = integer())
    }
    
    # --- DISTANCE ---
    dist_out <- update_connectivity_after_distance(
      patch_stack          = patch_stack,
      patch_dt             = patch_dt,
      state_env            = state_env,
      patch_ids_to_recheck = recheck_ids,
      params               = params,
      count_alive          = count_alive
    )
    
    patch_stack <- dist_out$patch_stack
    patch_dt    <- dist_out$patch_dt
    state_env   <- dist_out$state_env
    count_alive <- dist_out$count_alive
    
    removed_dist <- dist_out$removed_indices

    # --------------------------------------------------------
    # Diagnostic raster: cells removed by distance step
    #
    # Behaviour:
    #   • Records which cells were lost at the distance stage.
    # Runtime/memory:
    #   • Only written if any cells were removed.
    #   • Reuses existing raster geometry (patch_stack[[1]]).
    # --------------------------------------------------------
    if (length(removed_dist) > 0L) {
      mask_dist <- terra::setValues(patch_stack[[1]], NA_integer_)
      mask_dist[removed_dist] <- 1L
      fn_dist <- file.path(
        output_dir,
        sprintf("removed_mask_distance_stage_%04d.tif", stage_iter)
      )
      terra::writeRaster(mask_dist, filename = fn_dist, overwrite = TRUE)
    }

    # ========================================================
    # 4) SAVE PER-STAGE CHECKPOINT (RESUME INFO)
    #
    # Behaviour:
    #   • Allows the entire pipeline to be resumed from the end of the
    #     last completed stage without rerunning earlier stages.
    #   • We save:
    #       - patch_dt: current patch-to-PU mapping and areas.
    #       - state_env: current CSR graphs for PUs.
    #       - count_alive: current per-cell species counts.
    #       - patch_stack_file: where to reload the current patch_stack.
    #
    # Runtime/memory:
    #   • Writes patch_stack once per stage to disk (needed anyway for
    #     downstream spatial analyses).
    #   • The RDS only holds the minimal evolving state needed to resume.
    # ========================================================
    patch_stack_file <- file.path(
      output_dir,
      sprintf("patch_stack_stage_%04d.tif", stage_iter)
    )
    terra::writeRaster(patch_stack, patch_stack_file, overwrite = TRUE)

    resume_state <- list(
      patch_dt         = patch_dt,
      state_env        = state_env,
      count_alive      = count_alive,
      patch_stack_file = patch_stack_file
    )

    state_file <- file.path(
      output_dir,
      sprintf("global_state_stage_%04d.rds", stage_iter)
    )
    saveRDS(resume_state, state_file)

    # ========================================================
    # 5) STOP CONDITION
    #
    # Behaviour:
    #   • The global loop ends when pruning reports that the frontier is
    #     exhausted — i.e., there are no edge cells left to prune.
    #
    # Runtime:
    #   • Avoids unnecessary extra global stages once the process can
    #     no longer change the configuration.
    # ========================================================
    if (frontier_exhausted) break
  }

  # The orchestrator's purpose is side effects (writing rasters + RDS),
  # not returning objects to the caller. invisible(NULL) prevents large
  # objects from being printed to the console and keeps memory overhead low.
  invisible(NULL)
}
```

# DIAGNOSTIC CHUNK B (run AFTER run_global_orchestrator_simplified is defined)

```{r eval=FALSE, include=FALSE}
# ============================================================
# DIAGNOSTIC CHUNK B (run AFTER run_global_orchestrator_simplified is defined)
# Purpose:
#   - Execute a small, reproducible smoke-test of:
#       prune_step_minimal (via run_pruning_orchestrator),
#       apply_patch_fragmentation_updates,
#       update_connectivity_after_distance,
#       run_global_orchestrator_simplified.
#   - Validate key invariants after each stage.
# ============================================================

diag_assert <- function(ok, msg) if (!isTRUE(ok)) stop(msg, call. = FALSE)

# ---------------------------
# Diagnostic configuration
# ---------------------------
DIAG <- list(
  # Keep this small to reduce runtime/memory; use >=2 to exercise multi-species scoring
  n_species_keep        = 5L,

  # Crop window in "cell radius" around a random alive cell (reduces ncell dramatically)
  do_crop               = TRUE,
  crop_halfwindow_cells = 100L,   # window side ~ (2*200+1)^2 ~ 160k cells

  # Pruning smoke-test parameters
  pruning_k             = 10L,
  pruning_n_remove      = 100L,

  # Global orchestrator smoke-test parameters (1 stage only)
  run_global_smoke      = TRUE,
  global_k              = 10L,
  global_n_remove       = 100L,
  global_max_stages     = 2L,

  # Behaviour: stop on any detected inconsistency (recommended TRUE)
  strict                = TRUE
)

# ---------------------------
# Required packages
# ---------------------------
pkgs_needed <- c("data.table", "terra", "sf", "fasterRaster", "fastmatch", "Rfast")
pkgs_missing <- pkgs_needed[!vapply(pkgs_needed, requireNamespace, logical(1), quietly = TRUE)]
diag_assert(length(pkgs_missing) == 0, paste0("Missing required package(s): ", paste(pkgs_missing, collapse = ", ")))

suppressPackageStartupMessages({
  library(data.table)
  library(terra)
  library(sf)
})
sf::sf_use_s2(TRUE)

# ---------------------------
# Load fresh initializer state
# ---------------------------
init_path <- file.path("Spatial", "global_orchestrator_init.rds")
diag_assert(file.exists(init_path), paste0("Missing initializer RDS: ", init_path))

init <- readRDS(init_path)

patch_stack_full <- terra::rast(init$patch_stack_file)
patch_dt_full    <- data.table::copy(data.table::as.data.table(init$patch_dt))
state_env_full   <- init$state_env
params_full      <- data.table::copy(data.table::as.data.table(init$params))

# Note: we will recompute count_alive / cs_vals / rook_pairs_all if we crop/subset.
# This lets the smoke-test run on a tiny window without relying on full-grid objects.

diag_assert(terra::nlyr(patch_stack_full) >= 1L, "patch_stack has zero layers.")
diag_assert(nrow(params_full) >= 1L, "params is empty.")
data.table::setkey(params_full, species)

# ---------------------------
# Subset species for faster smoke-testing
# (UPDATED: supports auto-expansion later if needed)
# ---------------------------
sp_all <- names(patch_stack_full)
diag_assert(length(sp_all) >= 1L, "patch_stack has no layer names.")

# Helper to (re)build the subset objects for a given n_keep
.reload_subset <- function(n_keep) {
  n_keep <- as.integer(n_keep)
  diag_assert(n_keep >= 1L, "n_keep must be >= 1.")

  keep_species <- sp_all[seq_len(min(n_keep, length(sp_all)))]

  patch_stack <- patch_stack_full[[keep_species]]
  params      <- params_full[species %in% keep_species]
  patch_dt    <- patch_dt_full[species %in% keep_species]

  # Filter state_env by species prefix before '|'
  sp_in_state <- sub("\\|.*$", "", names(state_env_full))
  state_env   <- state_env_full[sp_in_state %in% keep_species]

  diag_assert(terra::nlyr(patch_stack) == length(keep_species), "Species subset failed for patch_stack.")
  diag_assert(nrow(params) > 0L, "params is empty after species subsetting.")
  diag_assert(nrow(patch_dt) > 0L, "patch_dt is empty after species subsetting.")
  diag_assert(length(state_env) > 0L, "state_env is empty after species subsetting.")

  # Keying (caller can re-key after final selection too, but keep it consistent here)
  params <- data.table::copy(params)
  patch_dt <- data.table::copy(patch_dt)
  data.table::setkey(params, species)
  data.table::setkey(patch_dt, species, patch_id)

  list(
    n_keep       = length(keep_species),
    keep_species = keep_species,
    patch_stack  = patch_stack,
    params       = params,
    patch_dt     = patch_dt,
    state_env    = state_env
  )
}

# Start with the requested number of species (but at least 2 is required for a ">=2 species cell")
n_keep <- min(as.integer(DIAG$n_species_keep), length(sp_all))
n_keep <- max(n_keep, 2L)

sub <- .reload_subset(n_keep)

keep_species <- sub$keep_species
patch_stack  <- sub$patch_stack
params       <- sub$params
patch_dt     <- sub$patch_dt
state_env    <- sub$state_env


# ---------------------------
# Optional crop for speed
# (UPDATED: guarantees cropped area contains ≥2-species cell)
# ---------------------------
if (isTRUE(DIAG$do_crop)) {
  template_full <- patch_stack[[1]]

  # We will ensure there exists at least one cell with >=2 alive species
  # in the current subset; if not, we expand the species subset until it does.
  repeat {
    v0 <- terra::values(patch_stack, mat = TRUE)
    count_alive_fullsubset <- rowSums(!is.na(v0))
    rm(v0); gc()

    multi_cells <- which(count_alive_fullsubset >= 2L)

    if (length(multi_cells) > 0L) break

    # If we already included all species and still no >=2 cells, we cannot satisfy the guarantee.
    if (sub$n_keep >= length(sp_all)) {
      diag_assert(
        FALSE,
        paste0(
          "Cannot guarantee crop contains a ≥2-species cell: ",
          "even using ALL species layers, there are zero cells with >=2 non-NA layers."
        )
      )
    }

    # Expand deterministically by adding more species until we find >=2-species cells.
    sub$n_keep <- min(length(sp_all), sub$n_keep + 1L)
    sub2 <- .reload_subset(sub$n_keep)

    keep_species <- sub2$keep_species
    patch_stack  <- sub2$patch_stack
    params       <- sub2$params
    patch_dt     <- sub2$patch_dt
    state_env    <- sub2$state_env
    sub          <- sub2

    cat(sprintf(
      "DIAG: expanded species subset to %d layers to obtain ≥2-species cells.\n",
      sub$n_keep
    ))
  }

  # Now pick crop center *only* from cells with >=2 alive species.
  set.seed(1)
  center_cell <- sample(multi_cells, 1L)

  rc <- terra::rowColFromCell(template_full, center_cell)
  r0 <- rc[1]; c0 <- rc[2]

  half <- as.integer(DIAG$crop_halfwindow_cells)
  rr <- seq.int(max(1L, r0 - half), min(terra::nrow(template_full), r0 + half))
  cc <- seq.int(max(1L, c0 - half), min(terra::ncol(template_full), c0 + half))

  # Build cell indices for window
  grid_cells <- as.vector(sapply(rr, function(r) terra::cellFromRowCol(template_full, r, cc)))
  ext_sub    <- terra::ext(template_full, cells = grid_cells)

  patch_stack <- terra::crop(patch_stack, ext_sub, snap = "near")
  diag_assert(terra::ncell(patch_stack) > 0L, "Crop produced empty raster.")

  # Strong post-check: cropped area truly contains >=2-species cell
  pv_crop <- terra::values(patch_stack, mat = TRUE)
  ca_crop <- rowSums(!is.na(pv_crop))
  rm(pv_crop); gc()

  diag_assert(
    any(ca_crop >= 2L),
    "Crop post-check failed: cropped raster contains no cells with >=2 alive species."
  )

  cat(sprintf(
    "DIAG: cropped raster to %d cells (%d x %d); verified ≥2-species cell exists in crop.\n",
    terra::ncell(patch_stack), terra::nrow(patch_stack), terra::ncol(patch_stack)
  ))
}

template <- patch_stack[[1]]
ncell    <- terra::ncell(template)

# Recompute cs_vals and rook_pairs_all for the (possibly) cropped raster
cs_vals <- as.numeric(terra::values(terra::cellSize(template, unit = "km"), mat = TRUE)[, 1])
rook_pairs_all <- terra::adjacent(
  template,
  cells      = seq_len(ncell),
  directions = 4,
  pairs      = TRUE
)

# Recompute count_alive (for the subset/crop)
pv <- terra::values(patch_stack, mat = TRUE)
count_alive <- as.integer(rowSums(!is.na(pv)))
rm(pv); gc()

diag_assert(length(cs_vals) == ncell, "cs_vals length mismatch after crop.")
diag_assert(length(count_alive) == ncell, "count_alive length mismatch after crop.")
diag_assert(nrow(rook_pairs_all) > 0L, "rook_pairs_all is empty after crop.")


# ---------------------------
# Diagnostics directory
# ---------------------------
diag_dir <- file.path("Spatial", "Diagnostics")
dir.create(diag_dir, recursive = TRUE, showWarnings = FALSE)

# ---------------------------
# Helper: CSR entry validator (post-stage)
# ---------------------------
.csr_neighbors <- function(row_ptr, col_idx, u) {
  s <- row_ptr[u] + 1L
  e <- row_ptr[u + 1L]
  if (e < s) return(integer(0L))
  as.integer(col_idx[s:e])
}

.check_state_env_subset <- function(state_env_obj, patch_dt_ref, max_keys = 30L) {
  keys <- names(state_env_obj)
  diag_assert(length(keys) > 0L, "state_env is empty.")
  set.seed(1)
  keys <- sample(keys, size = min(length(keys), max_keys))

  for (key in keys) {
    obj <- state_env_obj[[key]]

    parts <- strsplit(key, "\\|", fixed = FALSE)[[1]]
    diag_assert(length(parts) == 2L, paste0("Bad key: ", key))
    sp <- parts[1L]
    pu <- suppressWarnings(as.integer(parts[2L]))
    diag_assert(is.finite(pu), paste0("Bad pu in key: ", key))

    id2patch <- as.integer(obj$id2patch)
    row_ptr  <- as.integer(obj$row_ptr)
    col_idx  <- as.integer(obj$col_idx)

    N <- length(id2patch)
    diag_assert(N >= 1L, paste0("Zero-node CSR: ", key))
    diag_assert(length(row_ptr) == N + 1L, paste0("row_ptr length != N+1: ", key))
    diag_assert(row_ptr[1L] == 0L, paste0("row_ptr[1] != 0: ", key))
    diag_assert(all(diff(row_ptr) >= 0L), paste0("row_ptr not nondecreasing: ", key))
    diag_assert(row_ptr[N + 1L] == length(col_idx), paste0("row_ptr[end] != length(col_idx): ", key))

    if (length(col_idx)) {
      diag_assert(min(col_idx) >= 1L, paste0("col_idx must be 1-based node indices (min<1): ", key))
      diag_assert(max(col_idx) <= N,  paste0("col_idx out of range (>N): ", key))
    }

    # Check patch_dt contains same patches for (sp, pu)
    pid_dt <- patch_dt_ref[species == sp & pu_id == pu, as.integer(patch_id)]
    diag_assert(length(pid_dt) > 0L, paste0("patch_dt missing PU: ", key))
    diag_assert(setequal(pid_dt, id2patch), paste0("patch_dt PU patches != id2patch for ", key))

    # Light symmetry check
    a <- find_first_asymmetry(row_ptr, col_idx)
    diag_assert(is.null(a),
      paste0("CSR asymmetry in ", key, " (", a["u"], "->", a["v"], " not symmetric)")
    )
  }

  TRUE
}

# Helper: patch_stack vs patch_dt consistency check (sampled)
.check_patch_stack_matches_patch_dt <- function(patch_stack_obj, patch_dt_ref, sample_cells = 20000L) {
  sp_layers <- names(patch_stack_obj)
  diag_assert(length(sp_layers) > 0L, "patch_stack has no layers.")

  # Sample cells to avoid pulling full vectors for huge rasters
  ncell <- terra::ncell(patch_stack_obj)
  set.seed(1)
  samp <- if (ncell <= sample_cells) seq_len(ncell) else sample.int(ncell, sample_cells)

  for (sp in sp_layers) {
    vals <- terra::values(patch_stack_obj[[sp]], mat = TRUE)[, 1]
    vals <- vals[samp]
    vals <- vals[!is.na(vals)]
    if (!length(vals)) next

    # Patch IDs in raster sample must exist in patch_dt for that species
    pid_dt <- patch_dt_ref[species == sp, unique(as.integer(patch_id))]
    bad <- setdiff(unique(as.integer(vals)), pid_dt)

    if (length(bad)) {
      msg <- paste0(
        "patch_stack contains patch_id(s) that are not present in patch_dt for species '", sp, "'.\n",
        "Example bad patch IDs: ", paste(head(bad, 20), collapse = ", ")
      )
      if (isTRUE(DIAG$strict)) stop(msg, call. = FALSE) else warning(msg)
    }
  }
  TRUE
}

# ============================================================
# 1) PRUNING SMOKE-TEST (tests prune_step_minimal + run_pruning_orchestrator)
# ============================================================
cat("\n=== DIAG: PRUNING SMOKE-TEST ===\n")

# --- deterministic asymmetry locator for one CSR ---
.csr_neighbors <- function(row_ptr, col_idx, u) {
  s <- row_ptr[u] + 1L
  e <- row_ptr[u + 1L]
  if (e < s) return(integer(0L))
  as.integer(col_idx[s:e])
}

find_first_asymmetry <- function(row_ptr, col_idx) {
  N <- length(row_ptr) - 1L
  for (u in seq_len(N)) {
    nb_u <- .csr_neighbors(row_ptr, col_idx, u)
    if (!length(nb_u)) next
    for (v in nb_u) {
      nb_v <- .csr_neighbors(row_ptr, col_idx, v)
      if (!(u %in% nb_v)) return(c(u = u, v = v))
    }
  }
  NULL
}

key <- "Cheirogaleus_medius|1019"
obj <- init$state_env[[key]]
a <- find_first_asymmetry(as.integer(obj$row_ptr), as.integer(obj$col_idx))
print(a)

if (!is.null(a)) {
  u <- a["u"]; v <- a["v"]
  cat("ASYMMETRY in", key, "\n")
  cat("u=", u, "patch_id=", obj$id2patch[u], "\n")
  cat("v=", v, "patch_id=", obj$id2patch[v], "\n")
  cat("nbr(u)=", paste(.csr_neighbors(obj$row_ptr, obj$col_idx, u), collapse=","), "\n")
  cat("nbr(v)=", paste(.csr_neighbors(obj$row_ptr, obj$col_idx, v), collapse=","), "\n")
}

prune_out <- run_pruning_orchestrator(
  k              = as.integer(DIAG$pruning_k),
  n_remove       = as.integer(DIAG$pruning_n_remove),
  patch_dt       = data.table::copy(patch_dt),
  state_env      = state_env,
  count_alive    = as.integer(count_alive),
  patch_stack    = patch_stack,
  cs_vals        = cs_vals,
  rook_pairs_all = rook_pairs_all,
  params         = params,
  output_dir     = diag_dir,
  stage_iter     = 9001L
)

if (length(prune_out$removed_indices)) { # If pruning removes habitat globally, clearing all layers is correct: 
  patch_stack[prune_out$removed_indices] <- NA }

# (optional but recommended) sanity check on a small random sample
set.seed(1)
samp <- sample.int(terra::ncell(patch_stack), min(50000L, terra::ncell(patch_stack)))
ca_from_raster <- rowSums(!is.na(terra::values(patch_stack, mat = TRUE)[samp, , drop=FALSE]))
stopifnot(identical(as.integer(ca_from_raster), as.integer(prune_out$count_alive[samp])))

diag_assert(is.list(prune_out), "run_pruning_orchestrator did not return a list.")
diag_assert(all(c("patch_dt","state_env","count_alive","removed_indices","changed_patch_areas","frontier_exhausted") %in% names(prune_out)),
            "run_pruning_orchestrator output missing expected fields.")

diag_assert(all(prune_out$count_alive >= 0L), "Pruning produced negative count_alive values.")
diag_assert(max(prune_out$count_alive) <= terra::nlyr(patch_stack), "Pruning count_alive exceeds #species layers.")

# The pruning stage does not modify patch_stack; still, patch_dt/state_env should remain consistent.
.check_state_env_subset(prune_out$state_env, prune_out$patch_dt, max_keys = 30L)

cat(sprintf("DIAG: pruning removed %d cells across %d iteration(s).\n",
            length(prune_out$removed_indices), as.integer(DIAG$pruning_k)))

# ============================================================
# 2) FRAGMENTATION SMOKE-TEST
# ============================================================
cat("\n=== DIAG: FRAGMENTATION SMOKE-TEST ===\n")

frag_out <- apply_patch_fragmentation_updates(
  patch_stack         = patch_stack,
  patch_dt            = data.table::copy(prune_out$patch_dt),
  state_env           = prune_out$state_env,
  changed_patch_areas = prune_out$changed_patch_areas,
  cs_vals             = cs_vals,
  params              = params,
  count_alive         = prune_out$count_alive
)

diag_assert(all(c("patch_stack","patch_dt","state_env","count_alive","patch_ids_to_recheck","removed_indices") %in% names(frag_out)),
            "apply_patch_fragmentation_updates output missing expected fields.")

diag_assert(terra::nlyr(frag_out$patch_stack) == terra::nlyr(patch_stack), "Fragmentation changed number of layers.")
diag_assert(identical(names(frag_out$patch_stack), names(patch_stack)), "Fragmentation changed layer names unexpectedly.")
diag_assert(all(frag_out$count_alive >= 0L), "Fragmentation produced negative count_alive values.")

# After fragmentation, patch_stack SHOULD be aligned with patch_dt (at least on a sample)
.check_patch_stack_matches_patch_dt(frag_out$patch_stack, frag_out$patch_dt, sample_cells = 20000L)
.check_state_env_subset(frag_out$state_env, frag_out$patch_dt, max_keys = 30L)

cat(sprintf("DIAG: fragmentation removed %d cells and flagged %d (species,patch) for distance recheck.\n",
            length(frag_out$removed_indices),
            if (is.data.frame(frag_out$patch_ids_to_recheck)) nrow(frag_out$patch_ids_to_recheck) else length(frag_out$patch_ids_to_recheck)))

# ============================================================
# 3) DISTANCE CONNECTIVITY SMOKE-TEST
# ============================================================
cat("\n=== DIAG: DISTANCE CONNECTIVITY SMOKE-TEST ===\n")

dist_out <- update_connectivity_after_distance(
  patch_stack          = frag_out$patch_stack,
  patch_dt             = data.table::copy(frag_out$patch_dt),
  state_env            = frag_out$state_env,
  patch_ids_to_recheck = frag_out$patch_ids_to_recheck,
  params               = params,
  count_alive          = frag_out$count_alive
)

diag_assert(all(c("patch_dt","state_env","count_alive","removed_indices") %in% names(dist_out)),
            "update_connectivity_after_distance output missing expected fields.")

diag_assert(all(dist_out$count_alive >= 0L), "Distance stage produced negative count_alive values.")
.check_state_env_subset(dist_out$state_env, dist_out$patch_dt, max_keys = 30L)

# IMPORTANT CONSISTENCY CHECK:
# If distance stage drops patches, patch_stack should no longer contain those patch IDs.
# Your current update_connectivity_after_distance implementation ONLY updates an internal
# cached vector, not patch_stack itself. This check will catch that.
#
# If this fails, your pipeline may still "kind of run" (because count_alive masks),
# but checkpoint rasters and resume states will be inconsistent.
cat("DIAG: checking patch_stack vs patch_dt consistency after distance stage...\n")
tryCatch(
  .check_patch_stack_matches_patch_dt(frag_out$patch_stack, dist_out$patch_dt, sample_cells = 20000L),
  error = function(e) {
    msg <- paste0(
      "DIAG FAILURE: patch_stack and patch_dt are inconsistent AFTER distance stage.\n\n",
      conditionMessage(e), "\n\n",
      "This strongly suggests update_connectivity_after_distance dropped patches in patch_dt/state_env\n",
      "but did not write those removals back into patch_stack.\n",
      "If you want checkpoint rasters and resume states to be correct, patch_stack must be updated too."
    )
    if (isTRUE(DIAG$strict)) stop(msg, call. = FALSE) else warning(msg)
  }
)

cat(sprintf("DIAG: distance removed %d cells.\n", length(dist_out$removed_indices)))

# ============================================================
# 4) GLOBAL ORCHESTRATOR SMOKE-TEST (1 stage)
# ============================================================
if (isTRUE(DIAG$run_global_smoke)) {
  cat("\n=== DIAG: GLOBAL ORCHESTRATOR SMOKE-TEST (1 stage) ===\n")

  smoke_dir <- file.path(diag_dir, "global_orchestrator_smoke")
  dir.create(smoke_dir, recursive = TRUE, showWarnings = FALSE)

  # Reload fresh baseline subset (avoid any mutation bleed)
  # Use the post-fragmentation raster so the smoke test exercises the same structure you use.
  patch_dt_smoke    <- data.table::copy(frag_out$patch_dt)
  state_env_smoke   <- frag_out$state_env
  count_alive_smoke <- as.integer(frag_out$count_alive)
  patch_stack_smoke <- frag_out$patch_stack

  run_global_orchestrator_simplified(
    n_remove       = as.integer(DIAG$global_n_remove),
    k              = as.integer(DIAG$global_k),
    patch_dt       = patch_dt_smoke,
    state_env      = state_env_smoke,
    count_alive    = count_alive_smoke,
    patch_stack    = patch_stack_smoke,
    cs_vals        = cs_vals,
    rook_pairs_all = rook_pairs_all,
    params         = params,
    output_dir     = smoke_dir,
    max_stages     = as.integer(DIAG$global_max_stages),
    start_stage_iter = 1L
  )

  # The orchestrator writes a stage checkpoint at stage 1
  state_file_1 <- file.path(smoke_dir, "global_state_stage_0001.rds")
  stack_file_1 <- file.path(smoke_dir, "patch_stack_stage_0001.tif")

  diag_assert(file.exists(state_file_1), paste0("Missing orchestrator checkpoint: ", state_file_1))
  diag_assert(file.exists(stack_file_1), paste0("Missing orchestrator patch_stack: ", stack_file_1))

  resume <- readRDS(state_file_1)
  diag_assert(all(c("patch_dt","state_env","count_alive","patch_stack_file") %in% names(resume)),
              "Checkpoint RDS missing expected fields.")

  # Compare saved count_alive to recomputed count_alive from saved patch_stack
  ps1 <- terra::rast(resume$patch_stack_file)
  vv1 <- terra::values(ps1, mat = TRUE)
  count_from_raster <- as.integer(rowSums(!is.na(vv1)))
  rm(vv1); gc()

  # They should match if patch_stack reflects all removals correctly.
  if (!identical(count_from_raster, as.integer(resume$count_alive))) {
    msg <- paste0(
      "Checkpoint inconsistency: count_alive saved in RDS does NOT match count computed from saved patch_stack.\n",
      "This usually indicates one of the stages updated count_alive/patch_dt/state_env without writing\n",
      "the corresponding removals back into patch_stack before checkpointing."
    )
    if (isTRUE(DIAG$strict)) stop(msg, call. = FALSE) else warning(msg)
  }

  cat("DIAG: global orchestrator smoke-test wrote checkpoint files and passed count_alive consistency.\n")
}

cat("\nALL DIAGNOSTICS COMPLETED.\n")
rm(init, patch_stack_full, patch_dt_full, state_env_full, params_full)
gc(verbose = FALSE)
```

# DIAGNOSTIC CHUNK C (CSR UPDATE AUDIT)

```{r eval=FALSE, include=FALSE}
# ============================================================
# DIAGNOSTIC CHUNK C — CSR UPDATE AUDIT SMOKE TEST (HARDENED)
# Implements:
#  - deterministic + TOUCHED-key auditing (not just random sampling)
#  - stage "no-op" guards (fail if fragmentation/distance did nothing)
#  - ENFORCE: patch_area is NOT stored in state_env CSR objects
#  - more aggressive defaults to force fragmentation/distance code paths
#  - optional distance-forcing recheck set (from pruning/frag touched patches)
#
# Run after all pipeline functions are defined.
# ============================================================

diag_assert <- function(ok, msg) if (!isTRUE(ok)) stop(msg, call. = FALSE)

# ---- CSR helpers (minimal, deterministic) ----
.csr_neighbors <- function(row_ptr, col_idx, u) {
  s <- row_ptr[u] + 1L
  e <- row_ptr[u + 1L]
  if (e < s) return(integer(0L))
  as.integer(col_idx[s:e])
}

find_first_asymmetry <- function(row_ptr, col_idx) {
  N <- length(row_ptr) - 1L
  for (u in seq_len(N)) {
    nb_u <- .csr_neighbors(row_ptr, col_idx, u)
    if (!length(nb_u)) next
    for (v in nb_u) {
      nb_v <- .csr_neighbors(row_ptr, col_idx, v)
      if (!(u %in% nb_v)) return(c(u = u, v = v))
    }
  }
  NULL
}

# ---- small utility: safest unique key builder ----
.make_key <- function(species, pu_id) paste0(as.character(species), "|", as.integer(pu_id))

# ---- touched-key audit builder ----
# Given a patch_dt_ref and a "touched patches" DT with columns (species, patch_id),
# map to PU keys and audit ALL those keys (optionally plus a random sample).
audit_touched_keys <- function(state_env_obj,
                               patch_dt_ref,
                               touched_patches,
                               check_symmetry = TRUE,
                               forbid_patch_area_in_state_env = TRUE,
                               also_sample_n = 0L) {
  diag_assert(is.list(state_env_obj) && length(state_env_obj) > 0L, "state_env is empty / not a list.")
  diag_assert(!is.null(names(state_env_obj)) && all(nzchar(names(state_env_obj))), "state_env must be named.")
  if (anyDuplicated(names(state_env_obj))) {
    dupn <- unique(names(state_env_obj)[duplicated(names(state_env_obj))])
    stop("state_env has duplicate keys. Example: ", paste(head(dupn, 10), collapse = ", "), call. = FALSE)
  }

  # normalize touched_patches
  if (is.null(touched_patches) || !nrow(touched_patches)) {
    keys_touched <- character(0)
  } else {
    touched_patches <- data.table::as.data.table(touched_patches)
    diag_assert(all(c("species", "patch_id") %in% names(touched_patches)),
                "touched_patches must have columns: species, patch_id")

    touched_patches[, `:=`(
      species = as.character(species),
      patch_id = as.integer(patch_id)
    )]
    touched_patches <- unique(touched_patches[!is.na(patch_id) & nzchar(species)])

    # join to get pu_id from patch_dt_ref
    # NOTE: patch_dt_ref must include pu_id for each species/patch_id.
    pu_map <- patch_dt_ref[touched_patches, on = .(species, patch_id), .(species, pu_id)]
    pu_map <- unique(pu_map[!is.na(pu_id)])

    keys_touched <- unique(.make_key(pu_map$species, pu_map$pu_id))
  }

  # Optionally add a deterministic sample of additional keys
  keys <- keys_touched
  if (also_sample_n > 0L) {
    set.seed(1)
    all_keys <- names(state_env_obj)
    extra <- setdiff(all_keys, keys_touched)
    if (length(extra)) {
      extra <- sample(extra, size = min(length(extra), as.integer(also_sample_n)))
      keys <- unique(c(keys, extra))
    }
  }

  # Audit all selected keys
  for (k in keys) {
    csr_audit_one(
      key = k,
      obj = state_env_obj[[k]],
      patch_dt_ref = patch_dt_ref,
      check_symmetry = check_symmetry,
      forbid_patch_area_in_state_env = forbid_patch_area_in_state_env
    )
  }

  invisible(list(n_keys_touched = length(keys_touched), n_keys_total = length(keys)))
}

# ---- Strong single-key CSR check (structural + patch_dt alignment + symmetry proof) ----
csr_audit_one <- function(key,
                          obj,
                          patch_dt_ref,
                          check_symmetry = TRUE,
                          forbid_patch_area_in_state_env = TRUE) {

  parts <- strsplit(key, "\\|", fixed = FALSE)[[1]]
  diag_assert(length(parts) == 2L, paste0("Bad key format: ", key))
  sp <- parts[1L]
  pu <- suppressWarnings(as.integer(parts[2L]))
  diag_assert(is.finite(pu), paste0("Bad pu_id in key: ", key))

  # ENFORCE: patch_area should NOT be stored in state_env CSR objects
  if (isTRUE(forbid_patch_area_in_state_env) && !is.null(obj$patch_area)) {
    stop(
      paste0(
        "state_env CSR object contains $patch_area for key ", key, ".\n",
        "Per new design, patch_area must live only in patch_dt$patch_area_km2.\n",
        "Fix: remove patch_area from the CSR entry builder/updaters (see notes below)."
      ),
      call. = FALSE
    )
  }

  id2patch <- as.integer(obj$id2patch)
  row_ptr  <- as.integer(obj$row_ptr)
  col_idx  <- as.integer(obj$col_idx)

  N <- length(id2patch)
  diag_assert(N >= 1L, paste0("Zero-node CSR: ", key))
  diag_assert(length(row_ptr) == N + 1L, paste0("row_ptr length != N+1: ", key))
  diag_assert(row_ptr[1L] == 0L, paste0("row_ptr[1] must be 0 (0-based): ", key))
  diag_assert(all(diff(row_ptr) >= 0L), paste0("row_ptr not nondecreasing: ", key))
  diag_assert(row_ptr[N + 1L] == length(col_idx), paste0("row_ptr[end] != length(col_idx): ", key))

  if (length(col_idx)) {
    diag_assert(min(col_idx) >= 1L, paste0("col_idx must be 1-based node indices (min<1): ", key))
    diag_assert(max(col_idx) <= N,  paste0("col_idx out of range (>N): ", key))
  }

  # id2patch must match patch_dt's patches in this PU
  pid_dt <- patch_dt_ref[species == sp & pu_id == pu, as.integer(patch_id)]
  diag_assert(length(pid_dt) > 0L, paste0("patch_dt missing PU for key: ", key))
  diag_assert(setequal(pid_dt, id2patch), paste0("patch_dt PU patches != id2patch for ", key))

  # patch_dt must carry patch_area_km2 (now the single source of truth)
  diag_assert("patch_area_km2" %in% names(patch_dt_ref),
              "patch_dt is missing patch_area_km2 (required when patch_area removed from state_env).")

  # Quick sanity on patch_dt areas for these patches
  pa_dt <- patch_dt_ref[species == sp & pu_id == pu, .(patch_id, patch_area_km2)]
  pa_aligned <- pa_dt$patch_area_km2[match(id2patch, pa_dt$patch_id)]
  diag_assert(length(pa_aligned) == N, paste0("patch_dt area alignment failed for ", key))
  diag_assert(all(is.finite(pa_aligned) | is.na(pa_aligned)), paste0("Non-finite patch_area_km2 in patch_dt for ", key))
  diag_assert(all(pa_aligned[!is.na(pa_aligned)] >= 0), paste0("Negative patch_area_km2 in patch_dt for ", key))

  # Symmetry proof
  if (isTRUE(check_symmetry) && length(col_idx)) {
    a <- find_first_asymmetry(row_ptr, col_idx)
    if (!is.null(a)) {
      u <- a["u"]; v <- a["v"]
      cat("\n--- CSR ASYMMETRY PROOF ---\n")
      cat("key:", key, "\n")
      cat("u:", u, "patch_id:", id2patch[u], "\n")
      cat("v:", v, "patch_id:", id2patch[v], "\n")
      cat("nbr(u):", paste(.csr_neighbors(row_ptr, col_idx, u), collapse = ","), "\n")
      cat("nbr(v):", paste(.csr_neighbors(row_ptr, col_idx, v), collapse = ","), "\n")
      stop("CSR asymmetry detected (see proof above).", call. = FALSE)
    }
  }

  TRUE
}

# ---- Sampled audit over a state_env list (kept for quick smoke) ----
csr_audit_state_env <- function(state_env_obj,
                                patch_dt_ref,
                                max_keys = 40L,
                                check_symmetry = TRUE,
                                forbid_patch_area_in_state_env = TRUE) {
  diag_assert(is.list(state_env_obj) && length(state_env_obj) > 0L, "state_env is empty / not a list.")
  diag_assert(!is.null(names(state_env_obj)) && all(nzchar(names(state_env_obj))), "state_env must be named.")
  if (anyDuplicated(names(state_env_obj))) {
    dupn <- unique(names(state_env_obj)[duplicated(names(state_env_obj))])
    stop("state_env has duplicate keys. Example: ", paste(head(dupn, 10), collapse = ", "), call. = FALSE)
  }

  keys <- names(state_env_obj)
  set.seed(1)
  keys <- sample(keys, size = min(length(keys), as.integer(max_keys)))

  for (k in keys) {
    csr_audit_one(k, state_env_obj[[k]], patch_dt_ref,
                  check_symmetry = check_symmetry,
                  forbid_patch_area_in_state_env = forbid_patch_area_in_state_env)
  }
  TRUE
}

# ---- Raster vs patch_dt (sampled) — catches “dt says dropped but raster still has it” ----
audit_patch_stack_matches_patch_dt <- function(patch_stack_obj, patch_dt_ref, sample_cells = 20000L) {
  sp_layers <- names(patch_stack_obj)
  diag_assert(length(sp_layers) > 0L, "patch_stack has no layers.")
  ncell <- terra::ncell(patch_stack_obj)

  set.seed(1)
  samp <- if (ncell <= sample_cells) seq_len(ncell) else sample.int(ncell, sample_cells)

  for (sp in sp_layers) {
    vals <- terra::values(patch_stack_obj[[sp]], mat = TRUE)[, 1]
    vals <- vals[samp]
    vals <- vals[!is.na(vals)]
    if (!length(vals)) next

    pid_dt <- patch_dt_ref[species == sp, unique(as.integer(patch_id))]
    bad <- setdiff(unique(as.integer(vals)), pid_dt)
    diag_assert(
      !length(bad),
      paste0(
        "patch_stack contains patch_id(s) not present in patch_dt for species '", sp, "'. ",
        "Example bad IDs: ", paste(head(bad, 20), collapse = ", ")
      )
    )
  }
  TRUE
}

# ============================================================
# CONFIG (more aggressive defaults to exercise code paths)
# ============================================================
DIAG <- list(
  n_species_keep            = 5L,
  do_crop                   = TRUE,
  crop_halfwindow_cells     = 60L,
  crop_min_alive_species    = 3L,
  pruning_k                 = 30L,
  pruning_n_remove          = 200L,
  strict_symmetry           = TRUE,

  # NEW: enforce that state_env CSR objects DO NOT store patch_area
  forbid_patch_area_in_state_env = TRUE,

  sample_cells_raster_audit  = 20000L,
  sample_keys_smoke          = 40L,
  sample_keys_post           = 20L,
  require_frag_nontrivial    = TRUE,
  require_dist_nontrivial    = TRUE,
  force_distance_recheck_from_pruning = TRUE
)

suppressPackageStartupMessages({
  library(data.table)
  library(terra)
  library(sf)
  library(fastmatch)
  library(Rfast)
})
sf::sf_use_s2(TRUE)

# ============================================================
# LOAD INIT
# ============================================================
init_path <- file.path("Spatial", "global_orchestrator_init.rds")
diag_assert(file.exists(init_path), paste0("Missing initializer RDS: ", init_path))
init <- readRDS(init_path)

patch_stack_full <- terra::rast(init$patch_stack_file)
patch_dt_full    <- data.table::as.data.table(init$patch_dt)
state_env_full   <- init$state_env
params_full      <- data.table::as.data.table(init$params)

data.table::setkey(params_full, species)
data.table::setkey(patch_dt_full, species, patch_id)

sp_all <- names(patch_stack_full)
diag_assert(length(sp_all) >= 2L, "Need at least 2 species layers for this smoke test.")

keep_species <- sp_all[seq_len(min(as.integer(DIAG$n_species_keep), length(sp_all)))]
patch_stack  <- patch_stack_full[[keep_species]]
params       <- params_full[species %in% keep_species]
patch_dt     <- patch_dt_full[species %in% keep_species]

# Filter state_env to kept species
sp_in_state <- sub("\\|.*$", "", names(state_env_full))
state_env   <- state_env_full[sp_in_state %in% keep_species]

# ============================================================
# OPTIONAL CROP (ensures >= crop_min_alive_species alive species in at least one cell)
# ============================================================
if (isTRUE(DIAG$do_crop)) {
  template_full <- patch_stack[[1]]
  v0 <- terra::values(patch_stack, mat = TRUE)
  count_alive_full <- rowSums(!is.na(v0))
  rm(v0); gc(FALSE)

  need <- as.integer(DIAG$crop_min_alive_species)
  multi_cells <- which(count_alive_full >= need)
  diag_assert(length(multi_cells) > 0L,
              paste0("No cells with >=", need, " alive species in chosen subset; increase n_species_keep or lower crop_min_alive_species."))

  set.seed(1)
  center_cell <- sample(multi_cells, 1L)
  rc <- terra::rowColFromCell(template_full, center_cell)
  r0 <- rc[1]; c0 <- rc[2]

  half <- as.integer(DIAG$crop_halfwindow_cells)
  rr <- seq.int(max(1L, r0 - half), min(terra::nrow(template_full), r0 + half))
  cc <- seq.int(max(1L, c0 - half), min(terra::ncol(template_full), c0 + half))

  grid_cells <- as.vector(sapply(rr, function(r) terra::cellFromRowCol(template_full, r, cc)))
  ext_sub <- terra::ext(template_full, cells = grid_cells)

  patch_stack <- terra::crop(patch_stack, ext_sub, snap = "near")
  diag_assert(terra::ncell(patch_stack) > 0L, "Crop produced empty raster.")
  cat(sprintf("CSR DIAG: cropped to %d cells (halfwindow=%d, min_alive=%d).\n",
              terra::ncell(patch_stack), half, need))
}

template <- patch_stack[[1]]
ncell    <- terra::ncell(template)

# Recompute cs_vals, rook_pairs_all, count_alive on the cropped stack
cs_vals <- as.numeric(terra::values(terra::cellSize(template, unit = "km"), mat = TRUE)[, 1])
rook_pairs_all <- terra::adjacent(template, cells = seq_len(ncell), directions = 4, pairs = TRUE)

pv <- terra::values(patch_stack, mat = TRUE)
count_alive <- as.integer(rowSums(!is.na(pv)))
rm(pv); gc(FALSE)

diag_assert(length(cs_vals) == ncell, "cs_vals length mismatch.")
diag_assert(length(count_alive) == ncell, "count_alive length mismatch.")
diag_assert(nrow(rook_pairs_all) > 0L, "rook_pairs_all empty.")

# ============================================================
# AUDIT INIT (random sample + raster/dt)
# ============================================================
cat("\n=== CSR DIAG: INIT STATE_ENV AUDIT (sample) ===\n")
csr_audit_state_env(
  state_env_obj   = state_env,
  patch_dt_ref    = patch_dt,
  max_keys        = as.integer(DIAG$sample_keys_smoke),
  check_symmetry  = isTRUE(DIAG$strict_symmetry),
  forbid_patch_area_in_state_env = isTRUE(DIAG$forbid_patch_area_in_state_env)
)

cat("\n=== AUDIT: INIT raster vs patch_dt ===\n")
audit_patch_stack_matches_patch_dt(patch_stack, patch_dt, sample_cells = as.integer(DIAG$sample_cells_raster_audit))

# ============================================================
# 1) PRUNING
# ============================================================
cat("\n=== CSR DIAG: PRUNING SMOKE ===\n")
diag_dir <- file.path("Spatial", "Diagnostics", "csr_audit_smoke")
dir.create(diag_dir, recursive = TRUE, showWarnings = FALSE)

prune_out <- run_pruning_orchestrator(
  k              = as.integer(DIAG$pruning_k),
  n_remove       = as.integer(DIAG$pruning_n_remove),
  patch_dt       = data.table::copy(patch_dt),
  state_env      = state_env,
  count_alive    = as.integer(count_alive),
  patch_stack    = patch_stack,
  cs_vals        = cs_vals,
  rook_pairs_all = rook_pairs_all,
  params         = params,
  output_dir     = diag_dir,
  stage_iter     = 9101L
)

# Touched patches from pruning: prefer changed_patch_areas if present
touched_prune <- NULL
if (!is.null(prune_out$changed_patch_areas) && nrow(prune_out$changed_patch_areas)) {
  touched_prune <- unique(prune_out$changed_patch_areas[, .(species, patch_id)])
}

cat("\n=== CSR DIAG: AFTER PRUNING (audit touched keys + some sample) ===\n")
audit_touched_keys(
  state_env_obj = prune_out$state_env,
  patch_dt_ref  = prune_out$patch_dt,
  touched_patches = touched_prune,
  check_symmetry = isTRUE(DIAG$strict_symmetry),
  forbid_patch_area_in_state_env = isTRUE(DIAG$forbid_patch_area_in_state_env),
  also_sample_n = as.integer(DIAG$sample_keys_post)
)

cat("\n=== AUDIT: AFTER PRUNING raster vs patch_dt ===\n")
audit_patch_stack_matches_patch_dt(prune_out$patch_stack, prune_out$patch_dt, sample_cells = as.integer(DIAG$sample_cells_raster_audit))

# ============================================================
# 2) FRAGMENTATION
# ============================================================
cat("\n=== CSR DIAG: FRAGMENTATION SMOKE ===\n")
frag_out <- apply_patch_fragmentation_updates(
  patch_stack         = prune_out$patch_stack,
  patch_dt            = data.table::copy(prune_out$patch_dt),
  state_env           = prune_out$state_env,
  changed_patch_areas = prune_out$changed_patch_areas,
  cs_vals             = cs_vals,
  params              = params,
  count_alive         = prune_out$count_alive
)

# Guard: fail fast if fragmentation did nothing (unless you disable)
frag_nontrivial <- FALSE
if (!is.null(frag_out$patch_ids_to_recheck) && nrow(data.table::as.data.table(frag_out$patch_ids_to_recheck))) frag_nontrivial <- TRUE
if (!is.null(frag_out$stats)) {
  st <- frag_out$stats
  cand <- if (!is.null(st$pass1_cand)) as.integer(st$pass1_cand) else NA_integer_
  pu_t <- if (!is.null(st$pass3_pu_touched)) as.integer(st$pass3_pu_touched) else NA_integer_
  if (is.finite(cand) && cand > 0L) frag_nontrivial <- TRUE
  if (is.finite(pu_t) && pu_t > 0L) frag_nontrivial <- TRUE
}
if (isTRUE(DIAG$require_frag_nontrivial)) {
  diag_assert(frag_nontrivial,
              "Fragmentation stage was a no-op in this run; increase pruning intensity, shrink crop, or adjust crop_min_alive_species to force fragmentation.")
}

# Determine fragmentation touched patches
touched_frag <- NULL
if (!is.null(frag_out$patch_ids_to_recheck) && nrow(data.table::as.data.table(frag_out$patch_ids_to_recheck))) {
  touched_frag <- unique(data.table::as.data.table(frag_out$patch_ids_to_recheck)[, .(species, patch_id)])
}

cat("\n=== AUDIT: AFTER FRAG raster vs patch_dt ===\n")
audit_patch_stack_matches_patch_dt(frag_out$patch_stack, frag_out$patch_dt, sample_cells = as.integer(DIAG$sample_cells_raster_audit))

cat("\n=== CSR DIAG: AFTER FRAG (audit touched keys + some sample) ===\n")
audit_touched_keys(
  state_env_obj = frag_out$state_env,
  patch_dt_ref  = frag_out$patch_dt,
  touched_patches = touched_frag,
  check_symmetry = isTRUE(DIAG$strict_symmetry),
  forbid_patch_area_in_state_env = isTRUE(DIAG$forbid_patch_area_in_state_env),
  also_sample_n = as.integer(DIAG$sample_keys_post)
)

# ============================================================
# 3) DISTANCE
# ============================================================
cat("\n=== CSR DIAG: DISTANCE SMOKE ===\n")

# Optionally broaden the recheck set to force distance stage to do work
patch_ids_to_recheck <- frag_out$patch_ids_to_recheck
if (isTRUE(DIAG$force_distance_recheck_from_pruning)) {
  if (is.null(patch_ids_to_recheck) || !nrow(data.table::as.data.table(patch_ids_to_recheck))) {
    if (!is.null(touched_prune) && nrow(touched_prune)) {
      patch_ids_to_recheck <- data.table::copy(touched_prune)
    }
  } else {
    if (!is.null(touched_prune) && nrow(touched_prune)) {
      patch_ids_to_recheck <- unique(rbind(
        data.table::as.data.table(patch_ids_to_recheck)[, .(species, patch_id)],
        touched_prune
      ))
    }
  }
}

dist_out <- update_connectivity_after_distance(
  patch_stack          = frag_out$patch_stack,
  patch_dt             = data.table::copy(frag_out$patch_dt),
  state_env            = frag_out$state_env,
  patch_ids_to_recheck = patch_ids_to_recheck,
  params               = params,
  count_alive          = frag_out$count_alive
)

# Guard: fail fast if distance did nothing (unless disabled)
dist_nontrivial <- FALSE
if (!is.null(dist_out$stats)) {
  st <- dist_out$stats
  ec <- if (!is.null(st$edges_checked)) as.integer(st$edges_checked) else NA_integer_
  pu <- if (!is.null(st$PUs_touched)) as.integer(st$PUs_touched) else NA_integer_
  if (is.finite(ec) && ec > 0L) dist_nontrivial <- TRUE
  if (is.finite(pu) && pu > 0L) dist_nontrivial <- TRUE
}
if (!dist_nontrivial) {
  if (!is.null(patch_ids_to_recheck) && nrow(data.table::as.data.table(patch_ids_to_recheck))) dist_nontrivial <- TRUE
}
if (isTRUE(DIAG$require_dist_nontrivial)) {
  diag_assert(dist_nontrivial,
              "Distance stage appears to be a no-op (no stats + empty/no-op recheck); adjust params or force a larger recheck set.")
}

cat("\n=== AUDIT: AFTER DIST raster vs patch_dt ===\n")
audit_patch_stack_matches_patch_dt(dist_out$patch_stack, dist_out$patch_dt, sample_cells = as.integer(DIAG$sample_cells_raster_audit))

# Distance touched patches: use recheck set (best available proxy)
touched_dist <- NULL
if (!is.null(patch_ids_to_recheck) && nrow(data.table::as.data.table(patch_ids_to_recheck))) {
  touched_dist <- unique(data.table::as.data.table(patch_ids_to_recheck)[, .(species, patch_id)])
}

cat("\n=== CSR DIAG: AFTER DIST (audit touched keys + some sample) ===\n")
audit_touched_keys(
  state_env_obj = dist_out$state_env,
  patch_dt_ref  = dist_out$patch_dt,
  touched_patches = touched_dist,
  check_symmetry = isTRUE(DIAG$strict_symmetry),
  forbid_patch_area_in_state_env = isTRUE(DIAG$forbid_patch_area_in_state_env),
  also_sample_n = as.integer(DIAG$sample_keys_post)
)

cat("\nCSR DIAG: ALL STAGES PASSED (HARDENED, NO patch_area IN state_env).\n")
```

# From-scratch global orchestrator call (using initial inputs)

```{r eval=FALSE, include=FALSE}
orchestrator_init <- readRDS(file.path("Spatial", "global_orchestrator_init.rds"))

patch_dt         <- orchestrator_init$patch_dt
state_env        <- orchestrator_init$state_env
count_alive      <- orchestrator_init$count_alive
patch_stack_file <- orchestrator_init$patch_stack_file

patch_stack <- terra::rast(patch_stack_file)

# Ensure species alignment
stopifnot(all(params$species %in% names(patch_stack)))
patch_stack <- patch_stack[[params$species]]

rm(orchestrator_init, patch_stack_file)
gc(verbose = FALSE)

dir.create("Spatial/Outputs", recursive = TRUE, showWarnings = FALSE)

stopifnot(
  # All species sets must match
  setequal(names(patch_stack), params$species),
  setequal(params$species, unique(patch_dt$species)),

  # count_alive must be bounded by number of layers
  max(count_alive, na.rm = TRUE) <= terra::nlyr(patch_stack),

  # vectors must align to raster geometry
  length(count_alive) == terra::ncell(patch_stack),
  length(cs_vals)     == terra::ncell(patch_stack)
)

run_global_orchestrator_simplified(
  n_remove       = 1000,
  k              = 100,
  patch_dt       = patch_dt,
  state_env      = state_env,
  count_alive    = count_alive,
  patch_stack    = patch_stack,
  cs_vals        = cs_vals,
  rook_pairs_all = rook_pairs_all,
  params         = params,
  output_dir     = "Spatial/Outputs",
  max_stages     = 100L
)
```

# Resume global orchestrator call (starting after stage n)

```{r eval=FALSE, include=FALSE}
stage_n <- 24L

resume_state <- readRDS(
  file.path("Spatial", "Outputs", sprintf("global_state_stage_%04d.rds", stage_n))
)

patch_dt    <- resume_state$patch_dt
state_env   <- resume_state$state_env
count_alive <- resume_state$count_alive
patch_stack <- terra::rast(resume_state$patch_stack_file)

# Ensure species alignment
stopifnot(all(params$species %in% names(patch_stack)))
patch_stack <- patch_stack[[params$species]]

rm(resume_state)
gc(verbose = FALSE)

dir.create("Spatial/Outputs", recursive = TRUE, showWarnings = FALSE)

# Option A: run until absolute stage 50
run_global_orchestrator_simplified(
  n_remove        = 1000,
  k               = 50,
  patch_dt        = patch_dt,
  state_env       = state_env,
  count_alive     = count_alive,
  patch_stack     = patch_stack,
  cs_vals         = cs_vals,
  rook_pairs_all  = rook_pairs_all,
  params          = params,
  output_dir      = "Spatial/Outputs",
  start_stage_iter = stage_n + 1L,
  max_stages      = 50L
)

# Option B: run 50 more stages after stage_n
# n_more <- 50L
# run_global_orchestrator_simplified(
#   ...,
#   start_stage_iter = stage_n + 1L,
#   max_stages       = stage_n + n_more
# )
```

```{r eval=FALSE, include=FALSE}
library(terra)

# 1) Pick any single-layer raster that has the *target grid geometry*
#    (extent / resolution / CRS / ncell). For you, this is usually:
template <- patch_stack[[1]]

# 2) Put count_alive onto that grid
stopifnot(length(count_alive) == ncell(template))
r_count_alive <- setValues(template, as.integer(count_alive))
names(r_count_alive) <- "count_alive"

# (optional) if you prefer "dead" cells to be NA instead of 0:
# r_count_alive[r_count_alive == 0L] <- NA_integer_

# 3) Write to the working directory as a GeoTIFF
writeRaster(
  r_count_alive,
  filename  = file.path(getwd(), "count_alive.tif"),
  overwrite = TRUE,
  datatype  = "INT2U",
  wopt      = list(gdal = c("COMPRESS=LZW", "TILED=YES", "BIGTIFF=YES"))
)
```
